{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "457b35b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import seml\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7310758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5af5d990a5c4da5b6f5324f69b80d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7867033eab34d15ac153407ccc72a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = seml.get_results(\"datasetGPU\", to_data_frame = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9162c0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>config.overwrite</th>\n",
       "      <th>config.db_collection</th>\n",
       "      <th>config.batch_size</th>\n",
       "      <th>config.layerwise</th>\n",
       "      <th>config.model_file</th>\n",
       "      <th>config.number_forward_passes</th>\n",
       "      <th>config.on_GPU</th>\n",
       "      <th>config.params.number_layers</th>\n",
       "      <th>config.seed</th>\n",
       "      <th>result.name</th>\n",
       "      <th>result.power</th>\n",
       "      <th>result.model</th>\n",
       "      <th>result.power_layerwise</th>\n",
       "      <th>result.type</th>\n",
       "      <th>config.params.hidden_size</th>\n",
       "      <th>config.params.model_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>datasetGPU</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>dataset.models.pretrained</td>\n",
       "      <td>10000</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90826286</td>\n",
       "      <td>ResNetRS101</td>\n",
       "      <td>1.240943e-06</td>\n",
       "      <td>{\"class_name\": \"Functional\", \"config\": {\"name\"...</td>\n",
       "      <td>[9.506001814035177e-10, 1.936359064390964e-09,...</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>datasetGPU</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>dataset.models.pretrained</td>\n",
       "      <td>10000</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140526764</td>\n",
       "      <td>ResNetRS50</td>\n",
       "      <td>6.535860e-07</td>\n",
       "      <td>{\"class_name\": \"Functional\", \"config\": {\"name\"...</td>\n",
       "      <td>[9.690616255444419e-10, 2.0114537668823597e-09...</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>datasetGPU</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>dataset.models.pretrained</td>\n",
       "      <td>10000</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166554717</td>\n",
       "      <td>VGG16</td>\n",
       "      <td>1.819014e-07</td>\n",
       "      <td>{\"class_name\": \"Functional\", \"config\": {\"name\"...</td>\n",
       "      <td>[1.0528767679112158e-09, 4.823263512983056e-09...</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>datasetGPU</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>dataset.models.pretrained</td>\n",
       "      <td>10000</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>537085794</td>\n",
       "      <td>VGG19</td>\n",
       "      <td>2.121304e-07</td>\n",
       "      <td>{\"class_name\": \"Functional\", \"config\": {\"name\"...</td>\n",
       "      <td>[1.0896660015224284e-09, 4.831665201369126e-09...</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "      <td>datasetGPU</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>dataset.models.pretrained</td>\n",
       "      <td>10000</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>892222332</td>\n",
       "      <td>Xception</td>\n",
       "      <td>7.870769e-07</td>\n",
       "      <td>{\"class_name\": \"Functional\", \"config\": {\"name\"...</td>\n",
       "      <td>[1.6817995366140147e-09, 4.7364290502746865e-0...</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     _id  config.overwrite config.db_collection  config.batch_size  \\\n",
       "98   112               112           datasetGPU                  1   \n",
       "99   118               118           datasetGPU                  1   \n",
       "100  119               119           datasetGPU                  1   \n",
       "101  120               120           datasetGPU                  1   \n",
       "102  121               121           datasetGPU                  1   \n",
       "\n",
       "     config.layerwise          config.model_file  \\\n",
       "98               True  dataset.models.pretrained   \n",
       "99               True  dataset.models.pretrained   \n",
       "100              True  dataset.models.pretrained   \n",
       "101              True  dataset.models.pretrained   \n",
       "102              True  dataset.models.pretrained   \n",
       "\n",
       "     config.number_forward_passes  config.on_GPU  config.params.number_layers  \\\n",
       "98                          10000           True                          NaN   \n",
       "99                          10000           True                          NaN   \n",
       "100                         10000           True                          NaN   \n",
       "101                         10000           True                          NaN   \n",
       "102                         10000           True                          NaN   \n",
       "\n",
       "     config.seed  result.name  result.power  \\\n",
       "98      90826286  ResNetRS101  1.240943e-06   \n",
       "99     140526764   ResNetRS50  6.535860e-07   \n",
       "100    166554717        VGG16  1.819014e-07   \n",
       "101    537085794        VGG19  2.121304e-07   \n",
       "102    892222332     Xception  7.870769e-07   \n",
       "\n",
       "                                          result.model  \\\n",
       "98   {\"class_name\": \"Functional\", \"config\": {\"name\"...   \n",
       "99   {\"class_name\": \"Functional\", \"config\": {\"name\"...   \n",
       "100  {\"class_name\": \"Functional\", \"config\": {\"name\"...   \n",
       "101  {\"class_name\": \"Functional\", \"config\": {\"name\"...   \n",
       "102  {\"class_name\": \"Functional\", \"config\": {\"name\"...   \n",
       "\n",
       "                                result.power_layerwise result.type  \\\n",
       "98   [9.506001814035177e-10, 1.936359064390964e-09,...  pretrained   \n",
       "99   [9.690616255444419e-10, 2.0114537668823597e-09...  pretrained   \n",
       "100  [1.0528767679112158e-09, 4.823263512983056e-09...  pretrained   \n",
       "101  [1.0896660015224284e-09, 4.831665201369126e-09...  pretrained   \n",
       "102  [1.6817995366140147e-09, 4.7364290502746865e-0...  pretrained   \n",
       "\n",
       "     config.params.hidden_size  config.params.model_index  \n",
       "98                         NaN                       30.0  \n",
       "99                         NaN                       36.0  \n",
       "100                        NaN                       37.0  \n",
       "101                        NaN                       38.0  \n",
       "102                        NaN                       39.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29990237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7af076ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-22 18:47:34.077294: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-22 18:47:36.411555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10410 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "result[\"model\"] = result.apply(lambda x: tf.keras.models.model_from_json(x[\"result.model\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fd8cd2",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb11218f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.violinplot(result[\"result.power\"])\n",
    "plt.ylabel(\"power consumption in kWh\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dee8a5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_dense = result[result.loc[:,\"config.model_file\"] == \"dataset.models.dense\"]\n",
    "result_conv = result[result.loc[:,\"config.model_file\"] == \"dataset.models.conv\"]\n",
    "result_pretrained = result[result.loc[:,\"config.model_file\"] == \"dataset.models.pretrained\"]\n",
    "results = [result_dense, result_conv, result_pretrained]\n",
    "result_names = [\"Dense NNs\", \"Convolutional NNs\", \"Pretrained models\"]\n",
    "for res,name in zip(results, result_names):\n",
    "    plt.violinplot(res[\"result.power\"])\n",
    "    plt.ylabel(\"power consumption in kWh\")\n",
    "    plt.title(name)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4cb45f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot()\n",
    "ax1.violinplot([result_dense[\"result.power\"], result_conv[\"result.power\"], result_pretrained[\"result.power\"]])\n",
    "plt.ylabel(\"power consumption in kWh\")\n",
    "#ax1.set_ylim(0,2e-8)\n",
    "ax1.set_xticks([1,2,3], labels = [\"Dense NNs\", \"Convolutional NNs\", \"Pretrained models\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4726376a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7012392257888938e-08"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(result[\"result.power\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d357123e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4527379637559022e-06"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(result[\"result.power\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d372b793",
   "metadata": {},
   "source": [
    "Our data set consists of many simple models with a relative small energy consumption and some pretrained and more complex models that have an energy consumption up to a 100 times higher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc95eb1d",
   "metadata": {},
   "source": [
    "## Are FLOPs and power consumption correlated?\n",
    "One first baseline for the power consumption of a forwar pass could be the number of floating point operations. The advantage of this metric is that the number of FLOPs can be easily computed by existing tools (without the need of actually running a forward pass)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3c1f053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.profiler.model_analyzer import profile\n",
    "from tensorflow.python.profiler.option_builder import ProfileOptionBuilder\n",
    "\n",
    "def get_flops(model):\n",
    "    \"\"\" Calculates the floating point operations per second for a given model.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        model:\n",
    "            ML model that should be measured (has to be callable on input)\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "        float: FLOPs\n",
    "    \"\"\"\n",
    "    forward_pass = tf.function(\n",
    "        model.call,\n",
    "        input_signature=[tf.TensorSpec(shape=(1,) + model.input_shape[1:])])\n",
    "\n",
    "    graph_info = profile(forward_pass.get_concrete_function().graph,\n",
    "                         options=ProfileOptionBuilder.float_operation())\n",
    "\n",
    "    # The //2 is necessary since `profile` counts multiply and accumulate\n",
    "    # as two flops, here we report the total number of multiply accumulate ops\n",
    "    flops = graph_info.total_float_ops // 2\n",
    "    return flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06dfd9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /nfs/homedirs/kempern/anaconda3/envs/greenML/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:5219: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/368.05m flops)\n",
      "  conv2d/Conv2D (169.87m/169.87m flops)\n",
      "  conv2d_1/Conv2D (113.25m/113.25m flops)\n",
      "  conv2d_2/Conv2D (75.50m/75.50m flops)\n",
      "  conv2d/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_1/BiasAdd (2.10m/2.10m flops)\n",
      "  conv2d_2/BiasAdd (2.10m/2.10m flops)\n",
      "  max_pooling2d/MaxPool (2.10m/2.10m flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/559.94m flops)\n",
      "  conv2d/Conv2D (226.49m/226.49m flops)\n",
      "  conv2d_4/Conv2D (169.87m/169.87m flops)\n",
      "  conv2d_1/Conv2D (75.50m/75.50m flops)\n",
      "  conv2d_3/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_2/Conv2D (18.87m/18.87m flops)\n",
      "  conv2d/BiasAdd (4.19m/4.19m flops)\n",
      "  conv2d_3/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_4/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_1/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_2/BiasAdd (1.05m/1.05m flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/105.12m flops)\n",
      "  conv2d_2/Conv2D (37.75m/37.75m flops)\n",
      "  conv2d_3/Conv2D (37.75m/37.75m flops)\n",
      "  conv2d/Conv2D (14.16m/14.16m flops)\n",
      "  conv2d_1/Conv2D (9.44m/9.44m flops)\n",
      "  max_pooling2d/MaxPool (3.15m/3.15m flops)\n",
      "  conv2d_2/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_1/BiasAdd (524.29k/524.29k flops)\n",
      "  conv2d_3/BiasAdd (524.29k/524.29k flops)\n",
      "  max_pooling2d_1/MaxPool (524.29k/524.29k flops)\n",
      "  conv2d/BiasAdd (262.14k/262.14k flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/127.93m flops)\n",
      "  conv2d/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_2/Conv2D (28.31m/28.31m flops)\n",
      "  conv2d_1/Conv2D (14.16m/14.16m flops)\n",
      "  conv2d_4/Conv2D (14.16m/14.16m flops)\n",
      "  conv2d_3/Conv2D (9.44m/9.44m flops)\n",
      "  conv2d/BiasAdd (1.05m/1.05m flops)\n",
      "  max_pooling2d/MaxPool (1.05m/1.05m flops)\n",
      "  conv2d_1/BiasAdd (786.43k/786.43k flops)\n",
      "  conv2d_4/BiasAdd (786.43k/786.43k flops)\n",
      "  max_pooling2d_1/MaxPool (786.43k/786.43k flops)\n",
      "  conv2d_2/BiasAdd (524.29k/524.29k flops)\n",
      "  conv2d_3/BiasAdd (262.14k/262.14k flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.14b flops)\n",
      "  conv2d_3/Conv2D (226.49m/226.49m flops)\n",
      "  conv2d/Conv2D (169.87m/169.87m flops)\n",
      "  conv2d_1/Conv2D (169.87m/169.87m flops)\n",
      "  conv2d_2/Conv2D (169.87m/169.87m flops)\n",
      "  conv2d_4/Conv2D (150.99m/150.99m flops)\n",
      "  conv2d_5/Conv2D (113.25m/113.25m flops)\n",
      "  conv2d_6/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_7/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_3/BiasAdd (4.19m/4.19m flops)\n",
      "  conv2d/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_1/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_2/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_5/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_7/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_4/BiasAdd (2.10m/2.10m flops)\n",
      "  conv2d_6/BiasAdd (1.05m/1.05m flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/513.54m flops)\n",
      "  conv2d_1/Conv2D (150.99m/150.99m flops)\n",
      "  conv2d_2/Conv2D (150.99m/150.99m flops)\n",
      "  conv2d/Conv2D (113.25m/113.25m flops)\n",
      "  conv2d_3/Conv2D (37.75m/37.75m flops)\n",
      "  conv2d_4/Conv2D (18.87m/18.87m flops)\n",
      "  conv2d_6/Conv2D (18.87m/18.87m flops)\n",
      "  conv2d_5/Conv2D (9.44m/9.44m flops)\n",
      "  conv2d_1/BiasAdd (4.19m/4.19m flops)\n",
      "  conv2d/BiasAdd (2.10m/2.10m flops)\n",
      "  conv2d_2/BiasAdd (2.10m/2.10m flops)\n",
      "  max_pooling2d/MaxPool (2.10m/2.10m flops)\n",
      "  conv2d_3/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_5/BiasAdd (524.29k/524.29k flops)\n",
      "  conv2d_6/BiasAdd (524.29k/524.29k flops)\n",
      "  max_pooling2d_1/MaxPool (524.29k/524.29k flops)\n",
      "  conv2d_4/BiasAdd (262.14k/262.14k flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/114.55m flops)\n",
      "  conv2d_2/Conv2D (42.47m/42.47m flops)\n",
      "  conv2d/Conv2D (28.31m/28.31m flops)\n",
      "  conv2d_1/Conv2D (28.31m/28.31m flops)\n",
      "  conv2d_3/Conv2D (7.08m/7.08m flops)\n",
      "  max_pooling2d/MaxPool (3.15m/3.15m flops)\n",
      "  conv2d_4/Conv2D (1.77m/1.77m flops)\n",
      "  conv2d_1/BiasAdd (786.43k/786.43k flops)\n",
      "  conv2d_2/BiasAdd (786.43k/786.43k flops)\n",
      "  max_pooling2d_1/MaxPool (786.43k/786.43k flops)\n",
      "  conv2d/BiasAdd (524.29k/524.29k flops)\n",
      "  conv2d_5/Conv2D (221.18k/221.18k flops)\n",
      "  conv2d_3/BiasAdd (131.07k/131.07k flops)\n",
      "  max_pooling2d_2/MaxPool (131.07k/131.07k flops)\n",
      "  conv2d_4/BiasAdd (49.15k/49.15k flops)\n",
      "  max_pooling2d_3/MaxPool (49.15k/49.15k flops)\n",
      "  conv2d_5/BiasAdd (4.10k/4.10k flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/796.92m flops)\n",
      "  conv2d_10/Conv2D (150.99m/150.99m flops)\n",
      "  conv2d_6/Conv2D (113.25m/113.25m flops)\n",
      "  conv2d_7/Conv2D (113.25m/113.25m flops)\n",
      "  conv2d_8/Conv2D (75.50m/75.50m flops)\n",
      "  conv2d_9/Conv2D (75.50m/75.50m flops)\n",
      "  conv2d/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_3/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_4/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_5/Conv2D (37.75m/37.75m flops)\n",
      "  conv2d_1/Conv2D (18.87m/18.87m flops)\n",
      "  conv2d_2/Conv2D (18.87m/18.87m flops)\n",
      "  conv2d_10/BiasAdd (4.19m/4.19m flops)\n",
      "  conv2d_3/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_6/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_5/BiasAdd (2.10m/2.10m flops)\n",
      "  conv2d_7/BiasAdd (2.10m/2.10m flops)\n",
      "  conv2d_8/BiasAdd (2.10m/2.10m flops)\n",
      "  conv2d_9/BiasAdd (2.10m/2.10m flops)\n",
      "  conv2d/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_1/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_2/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_4/BiasAdd (1.05m/1.05m flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.38b flops)\n",
      "  conv2d_8/Conv2D (301.99m/301.99m flops)\n",
      "  conv2d/Conv2D (169.87m/169.87m flops)\n",
      "  conv2d_1/Conv2D (169.87m/169.87m flops)\n",
      "  conv2d_7/Conv2D (150.99m/150.99m flops)\n",
      "  conv2d_9/Conv2D (150.99m/150.99m flops)\n",
      "  conv2d_2/Conv2D (113.25m/113.25m flops)\n",
      "  conv2d_6/Conv2D (113.25m/113.25m flops)\n",
      "  conv2d_3/Conv2D (75.50m/75.50m flops)\n",
      "  conv2d_5/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_4/Conv2D (37.75m/37.75m flops)\n",
      "  conv2d_10/Conv2D (9.44m/9.44m flops)\n",
      "  conv2d_7/BiasAdd (4.19m/4.19m flops)\n",
      "  conv2d_8/BiasAdd (4.19m/4.19m flops)\n",
      "  conv2d/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_1/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_5/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_2/BiasAdd (2.10m/2.10m flops)\n",
      "  conv2d_3/BiasAdd (2.10m/2.10m flops)\n",
      "  conv2d_6/BiasAdd (2.10m/2.10m flops)\n",
      "  conv2d_9/BiasAdd (2.10m/2.10m flops)\n",
      "  max_pooling2d/MaxPool (2.10m/2.10m flops)\n",
      "  conv2d_4/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_10/BiasAdd (262.14k/262.14k flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/331.56m flops)\n",
      "  conv2d/Conv2D (113.25m/113.25m flops)\n",
      "  conv2d_7/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_1/Conv2D (37.75m/37.75m flops)\n",
      "  conv2d_6/Conv2D (28.31m/28.31m flops)\n",
      "  conv2d_2/Conv2D (18.87m/18.87m flops)\n",
      "  conv2d_3/Conv2D (18.87m/18.87m flops)\n",
      "  conv2d_4/Conv2D (18.87m/18.87m flops)\n",
      "  conv2d_8/Conv2D (18.87m/18.87m flops)\n",
      "  conv2d_5/Conv2D (9.44m/9.44m flops)\n",
      "  conv2d/BiasAdd (2.10m/2.10m flops)\n",
      "  max_pooling2d/MaxPool (2.10m/2.10m flops)\n",
      "  conv2d_1/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_3/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_7/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_9/Conv2D (884.74k/884.74k flops)\n",
      "  conv2d_6/BiasAdd (786.43k/786.43k flops)\n",
      "  conv2d_5/BiasAdd (524.29k/524.29k flops)\n",
      "  conv2d_2/BiasAdd (262.14k/262.14k flops)\n",
      "  conv2d_4/BiasAdd (262.14k/262.14k flops)\n",
      "  conv2d_8/BiasAdd (262.14k/262.14k flops)\n",
      "  max_pooling2d_1/MaxPool (262.14k/262.14k flops)\n",
      "  max_pooling2d_2/MaxPool (65.54k/65.54k flops)\n",
      "  conv2d_9/BiasAdd (49.15k/49.15k flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/346.73m flops)\n",
      "  conv2d/Conv2D (113.25m/113.25m flops)\n",
      "  conv2d_1/Conv2D (113.25m/113.25m flops)\n",
      "  conv2d_2/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_3/Conv2D (37.75m/37.75m flops)\n",
      "  conv2d_4/Conv2D (9.44m/9.44m flops)\n",
      "  conv2d_5/Conv2D (3.54m/3.54m flops)\n",
      "  conv2d_1/BiasAdd (3.15m/3.15m flops)\n",
      "  max_pooling2d/MaxPool (3.15m/3.15m flops)\n",
      "  conv2d/BiasAdd (2.10m/2.10m flops)\n",
      "  conv2d_2/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_8/Conv2D (589.82k/589.82k flops)\n",
      "  conv2d_9/Conv2D (589.82k/589.82k flops)\n",
      "  conv2d_3/BiasAdd (524.29k/524.29k flops)\n",
      "  conv2d_6/Conv2D (442.37k/442.37k flops)\n",
      "  conv2d_7/Conv2D (294.91k/294.91k flops)\n",
      "  conv2d_4/BiasAdd (262.14k/262.14k flops)\n",
      "  max_pooling2d_1/MaxPool (262.14k/262.14k flops)\n",
      "  conv2d_5/BiasAdd (196.61k/196.61k flops)\n",
      "  max_pooling2d_2/MaxPool (196.61k/196.61k flops)\n",
      "  max_pooling2d_3/MaxPool (49.15k/49.15k flops)\n",
      "  conv2d_8/BiasAdd (16.38k/16.38k flops)\n",
      "  conv2d_6/BiasAdd (8.19k/8.19k flops)\n",
      "  conv2d_7/BiasAdd (8.19k/8.19k flops)\n",
      "  conv2d_9/BiasAdd (8.19k/8.19k flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/195.42m flops)\n",
      "  conv2d/Conv2D (113.25m/113.25m flops)\n",
      "  conv2d_1/Conv2D (37.75m/37.75m flops)\n",
      "  conv2d_2/Conv2D (14.16m/14.16m flops)\n",
      "  conv2d_3/Conv2D (14.16m/14.16m flops)\n",
      "  conv2d_4/Conv2D (4.72m/4.72m flops)\n",
      "  conv2d_5/Conv2D (4.72m/4.72m flops)\n",
      "  conv2d/BiasAdd (2.10m/2.10m flops)\n",
      "  conv2d_1/BiasAdd (1.05m/1.05m flops)\n",
      "  max_pooling2d/MaxPool (1.05m/1.05m flops)\n",
      "  conv2d_2/BiasAdd (786.43k/786.43k flops)\n",
      "  conv2d_3/BiasAdd (262.14k/262.14k flops)\n",
      "  conv2d_4/BiasAdd (262.14k/262.14k flops)\n",
      "  max_pooling2d_1/MaxPool (262.14k/262.14k flops)\n",
      "  conv2d_6/Conv2D (221.18k/221.18k flops)\n",
      "  conv2d_7/Conv2D (221.18k/221.18k flops)\n",
      "  conv2d_8/Conv2D (221.18k/221.18k flops)\n",
      "  conv2d_5/BiasAdd (65.54k/65.54k flops)\n",
      "  max_pooling2d_2/MaxPool (65.54k/65.54k flops)\n",
      "  conv2d_9/Conv2D (55.30k/55.30k flops)\n",
      "  max_pooling2d_3/MaxPool (16.38k/16.38k flops)\n",
      "  conv2d_6/BiasAdd (12.29k/12.29k flops)\n",
      "  conv2d_8/BiasAdd (12.29k/12.29k flops)\n",
      "  max_pooling2d_4/MaxPool (12.29k/12.29k flops)\n",
      "  conv2d_7/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_9/BiasAdd (1.02k/1.02k flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/481.41m flops)\n",
      "  conv2d/Conv2D (226.49m/226.49m flops)\n",
      "  conv2d_1/Conv2D (75.50m/75.50m flops)\n",
      "  conv2d_3/Conv2D (75.50m/75.50m flops)\n",
      "  conv2d_2/Conv2D (37.75m/37.75m flops)\n",
      "  conv2d_4/Conv2D (37.75m/37.75m flops)\n",
      "  conv2d_6/Conv2D (9.44m/9.44m flops)\n",
      "  conv2d_5/Conv2D (4.72m/4.72m flops)\n",
      "  conv2d/BiasAdd (4.19m/4.19m flops)\n",
      "  conv2d_2/BiasAdd (2.10m/2.10m flops)\n",
      "  conv2d_3/BiasAdd (2.10m/2.10m flops)\n",
      "  conv2d_1/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_4/BiasAdd (1.05m/1.05m flops)\n",
      "  max_pooling2d/MaxPool (1.05m/1.05m flops)\n",
      "  conv2d_7/Conv2D (589.82k/589.82k flops)\n",
      "  conv2d_6/BiasAdd (524.29k/524.29k flops)\n",
      "  max_pooling2d_1/MaxPool (524.29k/524.29k flops)\n",
      "  conv2d_8/Conv2D (294.91k/294.91k flops)\n",
      "  conv2d_5/BiasAdd (262.14k/262.14k flops)\n",
      "  conv2d_9/Conv2D (221.18k/221.18k flops)\n",
      "  max_pooling2d_2/MaxPool (131.07k/131.07k flops)\n",
      "  conv2d_10/Conv2D (110.59k/110.59k flops)\n",
      "  max_pooling2d_3/MaxPool (32.77k/32.77k flops)\n",
      "  conv2d_7/BiasAdd (16.38k/16.38k flops)\n",
      "  max_pooling2d_4/MaxPool (16.38k/16.38k flops)\n",
      "  conv2d_8/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_9/BiasAdd (3.07k/3.07k flops)\n",
      "  conv2d_10/BiasAdd (2.05k/2.05k flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/21.97m flops)\n",
      "  conv2d/Conv2D (14.16m/14.16m flops)\n",
      "  max_pooling2d/MaxPool (3.15m/3.15m flops)\n",
      "  conv2d_1/Conv2D (1.18m/1.18m flops)\n",
      "  conv2d_10/Conv2D (884.74k/884.74k flops)\n",
      "  conv2d_9/Conv2D (294.91k/294.91k flops)\n",
      "  conv2d/BiasAdd (262.14k/262.14k flops)\n",
      "  max_pooling2d_1/MaxPool (262.14k/262.14k flops)\n",
      "  conv2d_11/Conv2D (221.18k/221.18k flops)\n",
      "  conv2d_12/Conv2D (221.18k/221.18k flops)\n",
      "  conv2d_5/Conv2D (221.18k/221.18k flops)\n",
      "  conv2d_6/Conv2D (221.18k/221.18k flops)\n",
      "  conv2d_3/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_4/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_7/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_8/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_2/Conv2D (73.73k/73.73k flops)\n",
      "  conv2d_1/BiasAdd (65.54k/65.54k flops)\n",
      "  max_pooling2d_2/MaxPool (65.54k/65.54k flops)\n",
      "  conv2d_9/BiasAdd (16.38k/16.38k flops)\n",
      "  max_pooling2d_3/MaxPool (16.38k/16.38k flops)\n",
      "  conv2d_10/BiasAdd (12.29k/12.29k flops)\n",
      "  conv2d_12/BiasAdd (12.29k/12.29k flops)\n",
      "  conv2d_5/BiasAdd (12.29k/12.29k flops)\n",
      "  conv2d_3/BiasAdd (8.19k/8.19k flops)\n",
      "  conv2d_7/BiasAdd (8.19k/8.19k flops)\n",
      "  conv2d_11/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_2/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_4/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_6/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_8/BiasAdd (4.10k/4.10k flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/112.82m flops)\n",
      "  conv2d_1/Conv2D (14.16m/14.16m flops)\n",
      "  conv2d_2/Conv2D (14.16m/14.16m flops)\n",
      "  conv2d_9/Conv2D (14.16m/14.16m flops)\n",
      "  conv2d/Conv2D (10.62m/10.62m flops)\n",
      "  conv2d_8/Conv2D (9.44m/9.44m flops)\n",
      "  conv2d_10/Conv2D (7.08m/7.08m flops)\n",
      "  conv2d_11/Conv2D (7.08m/7.08m flops)\n",
      "  conv2d_12/Conv2D (7.08m/7.08m flops)\n",
      "  conv2d_7/Conv2D (7.08m/7.08m flops)\n",
      "  conv2d_3/Conv2D (3.54m/3.54m flops)\n",
      "  conv2d_4/Conv2D (3.54m/3.54m flops)\n",
      "  conv2d_5/Conv2D (3.54m/3.54m flops)\n",
      "  conv2d_6/Conv2D (3.54m/3.54m flops)\n",
      "  max_pooling2d/MaxPool (3.15m/3.15m flops)\n",
      "  conv2d_14/Conv2D (884.74k/884.74k flops)\n",
      "  max_pooling2d_1/MaxPool (786.43k/786.43k flops)\n",
      "  conv2d_13/Conv2D (589.82k/589.82k flops)\n",
      "  conv2d_1/BiasAdd (262.14k/262.14k flops)\n",
      "  conv2d_8/BiasAdd (262.14k/262.14k flops)\n",
      "  conv2d/BiasAdd (196.61k/196.61k flops)\n",
      "  conv2d_11/BiasAdd (196.61k/196.61k flops)\n",
      "  conv2d_2/BiasAdd (196.61k/196.61k flops)\n",
      "  conv2d_4/BiasAdd (196.61k/196.61k flops)\n",
      "  conv2d_6/BiasAdd (196.61k/196.61k flops)\n",
      "  conv2d_9/BiasAdd (196.61k/196.61k flops)\n",
      "  conv2d_10/BiasAdd (131.07k/131.07k flops)\n",
      "  conv2d_12/BiasAdd (131.07k/131.07k flops)\n",
      "  conv2d_7/BiasAdd (131.07k/131.07k flops)\n",
      "  max_pooling2d_2/MaxPool (131.07k/131.07k flops)\n",
      "  conv2d_3/BiasAdd (65.54k/65.54k flops)\n",
      "  conv2d_5/BiasAdd (65.54k/65.54k flops)\n",
      "  conv2d_14/BiasAdd (49.15k/49.15k flops)\n",
      "  conv2d_13/BiasAdd (16.38k/16.38k flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/705.76m flops)\n",
      "  conv2d_1/Conv2D (226.49m/226.49m flops)\n",
      "  conv2d/Conv2D (169.87m/169.87m flops)\n",
      "  conv2d_2/Conv2D (75.50m/75.50m flops)\n",
      "  conv2d_4/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_5/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_3/Conv2D (18.87m/18.87m flops)\n",
      "  conv2d_6/Conv2D (18.87m/18.87m flops)\n",
      "  conv2d_7/Conv2D (18.87m/18.87m flops)\n",
      "  conv2d_8/Conv2D (18.87m/18.87m flops)\n",
      "  conv2d_9/Conv2D (14.16m/14.16m flops)\n",
      "  conv2d_10/Conv2D (7.08m/7.08m flops)\n",
      "  conv2d_11/Conv2D (4.72m/4.72m flops)\n",
      "  conv2d_1/BiasAdd (4.19m/4.19m flops)\n",
      "  conv2d/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_12/Conv2D (1.77m/1.77m flops)\n",
      "  conv2d_2/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_3/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_5/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_7/BiasAdd (1.05m/1.05m flops)\n",
      "  max_pooling2d/MaxPool (1.05m/1.05m flops)\n",
      "  conv2d_13/Conv2D (884.74k/884.74k flops)\n",
      "  conv2d_4/BiasAdd (786.43k/786.43k flops)\n",
      "  conv2d_9/BiasAdd (786.43k/786.43k flops)\n",
      "  max_pooling2d_1/MaxPool (786.43k/786.43k flops)\n",
      "  conv2d_14/Conv2D (294.91k/294.91k flops)\n",
      "  conv2d_15/Conv2D (294.91k/294.91k flops)\n",
      "  conv2d_6/BiasAdd (262.14k/262.14k flops)\n",
      "  conv2d_8/BiasAdd (262.14k/262.14k flops)\n",
      "  conv2d_10/BiasAdd (131.07k/131.07k flops)\n",
      "  conv2d_11/BiasAdd (131.07k/131.07k flops)\n",
      "  max_pooling2d_2/MaxPool (131.07k/131.07k flops)\n",
      "  conv2d_12/BiasAdd (49.15k/49.15k flops)\n",
      "  conv2d_13/BiasAdd (16.38k/16.38k flops)\n",
      "  conv2d_14/BiasAdd (16.38k/16.38k flops)\n",
      "  conv2d_15/BiasAdd (16.38k/16.38k flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/458.76m flops)\n",
      "  conv2d_1/Conv2D (75.50m/75.50m flops)\n",
      "  conv2d_2/Conv2D (75.50m/75.50m flops)\n",
      "  conv2d/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_11/Conv2D (37.75m/37.75m flops)\n",
      "  conv2d_12/Conv2D (37.75m/37.75m flops)\n",
      "  conv2d_6/Conv2D (37.75m/37.75m flops)\n",
      "  conv2d_7/Conv2D (37.75m/37.75m flops)\n",
      "  conv2d_10/Conv2D (18.87m/18.87m flops)\n",
      "  conv2d_4/Conv2D (18.87m/18.87m flops)\n",
      "  conv2d_5/Conv2D (18.87m/18.87m flops)\n",
      "  conv2d_3/Conv2D (9.44m/9.44m flops)\n",
      "  conv2d_8/Conv2D (9.44m/9.44m flops)\n",
      "  conv2d_9/Conv2D (4.72m/4.72m flops)\n",
      "  conv2d_1/BiasAdd (4.19m/4.19m flops)\n",
      "  conv2d_13/Conv2D (3.54m/3.54m flops)\n",
      "  conv2d/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_10/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_12/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_2/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_6/BiasAdd (1.05m/1.05m flops)\n",
      "  max_pooling2d/MaxPool (1.05m/1.05m flops)\n",
      "  max_pooling2d_1/MaxPool (1.05m/1.05m flops)\n",
      "  conv2d_14/Conv2D (663.55k/663.55k flops)\n",
      "  conv2d_15/Conv2D (663.55k/663.55k flops)\n",
      "  conv2d_11/BiasAdd (524.29k/524.29k flops)\n",
      "  conv2d_3/BiasAdd (524.29k/524.29k flops)\n",
      "  conv2d_4/BiasAdd (524.29k/524.29k flops)\n",
      "  conv2d_5/BiasAdd (524.29k/524.29k flops)\n",
      "  conv2d_7/BiasAdd (524.29k/524.29k flops)\n",
      "  conv2d_8/BiasAdd (262.14k/262.14k flops)\n",
      "  conv2d_9/BiasAdd (262.14k/262.14k flops)\n",
      "  max_pooling2d_2/MaxPool (262.14k/262.14k flops)\n",
      "  conv2d_13/BiasAdd (49.15k/49.15k flops)\n",
      "  max_pooling2d_3/MaxPool (49.15k/49.15k flops)\n",
      "  conv2d_14/BiasAdd (12.29k/12.29k flops)\n",
      "  conv2d_15/BiasAdd (12.29k/12.29k flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/120.34m flops)\n",
      "  conv2d/Conv2D (113.25m/113.25m flops)\n",
      "  conv2d/BiasAdd (2.10m/2.10m flops)\n",
      "  max_pooling2d/MaxPool (2.10m/2.10m flops)\n",
      "  conv2d_3/Conv2D (884.74k/884.74k flops)\n",
      "  conv2d_2/Conv2D (663.55k/663.55k flops)\n",
      "  max_pooling2d_1/MaxPool (524.29k/524.29k flops)\n",
      "  conv2d_1/Conv2D (442.37k/442.37k flops)\n",
      "  max_pooling2d_2/MaxPool (131.07k/131.07k flops)\n",
      "  conv2d_4/Conv2D (73.73k/73.73k flops)\n",
      "  conv2d_5/Conv2D (73.73k/73.73k flops)\n",
      "  max_pooling2d_3/MaxPool (32.77k/32.77k flops)\n",
      "  conv2d_3/BiasAdd (16.38k/16.38k flops)\n",
      "  max_pooling2d_4/MaxPool (16.38k/16.38k flops)\n",
      "  conv2d_1/BiasAdd (12.29k/12.29k flops)\n",
      "  conv2d_2/BiasAdd (12.29k/12.29k flops)\n",
      "  conv2d_5/BiasAdd (4.10k/4.10k flops)\n",
      "  max_pooling2d_5/MaxPool (4.10k/4.10k flops)\n",
      "  conv2d_6/Conv2D (1.15k/1.15k flops)\n",
      "  conv2d_4/BiasAdd (1.02k/1.02k flops)\n",
      "  max_pooling2d_6/MaxPool (1.02k/1.02k flops)\n",
      "  conv2d_10/Conv2D (864/864 flops)\n",
      "  conv2d_8/Conv2D (864/864 flops)\n",
      "  conv2d_9/Conv2D (864/864 flops)\n",
      "  conv2d_7/Conv2D (288/288 flops)\n",
      "  max_pooling2d_7/MaxPool (256/256 flops)\n",
      "  conv2d_10/BiasAdd (48/48 flops)\n",
      "  conv2d_8/BiasAdd (48/48 flops)\n",
      "  max_pooling2d_8/MaxPool (48/48 flops)\n",
      "  conv2d_6/BiasAdd (16/16 flops)\n",
      "  conv2d_7/BiasAdd (16/16 flops)\n",
      "  conv2d_9/BiasAdd (16/16 flops)\n",
      "  max_pooling2d_9/MaxPool (12/12 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/444.20m flops)\n",
      "  conv2d/Conv2D (113.25m/113.25m flops)\n",
      "  conv2d_2/Conv2D (75.50m/75.50m flops)\n",
      "  conv2d_3/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_1/Conv2D (37.75m/37.75m flops)\n",
      "  conv2d_7/Conv2D (18.87m/18.87m flops)\n",
      "  conv2d_10/Conv2D (14.16m/14.16m flops)\n",
      "  conv2d_6/Conv2D (14.16m/14.16m flops)\n",
      "  conv2d_11/Conv2D (10.62m/10.62m flops)\n",
      "  conv2d_14/Conv2D (10.62m/10.62m flops)\n",
      "  conv2d_4/Conv2D (10.62m/10.62m flops)\n",
      "  conv2d_5/Conv2D (10.62m/10.62m flops)\n",
      "  conv2d_8/Conv2D (9.44m/9.44m flops)\n",
      "  conv2d_9/Conv2D (9.44m/9.44m flops)\n",
      "  conv2d_12/Conv2D (7.08m/7.08m flops)\n",
      "  conv2d_13/Conv2D (7.08m/7.08m flops)\n",
      "  conv2d_18/Conv2D (7.08m/7.08m flops)\n",
      "  conv2d_19/Conv2D (7.08m/7.08m flops)\n",
      "  conv2d_2/BiasAdd (4.19m/4.19m flops)\n",
      "  max_pooling2d/MaxPool (4.19m/4.19m flops)\n",
      "  conv2d_15/Conv2D (3.54m/3.54m flops)\n",
      "  conv2d_17/Conv2D (3.54m/3.54m flops)\n",
      "  conv2d/BiasAdd (2.10m/2.10m flops)\n",
      "  conv2d_16/Conv2D (1.18m/1.18m flops)\n",
      "  conv2d_1/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_3/BiasAdd (786.43k/786.43k flops)\n",
      "  max_pooling2d_1/MaxPool (786.43k/786.43k flops)\n",
      "  conv2d_6/BiasAdd (262.14k/262.14k flops)\n",
      "  conv2d_7/BiasAdd (262.14k/262.14k flops)\n",
      "  conv2d_9/BiasAdd (262.14k/262.14k flops)\n",
      "  conv2d_10/BiasAdd (196.61k/196.61k flops)\n",
      "  conv2d_11/BiasAdd (196.61k/196.61k flops)\n",
      "  conv2d_13/BiasAdd (196.61k/196.61k flops)\n",
      "  conv2d_14/BiasAdd (196.61k/196.61k flops)\n",
      "  conv2d_17/BiasAdd (196.61k/196.61k flops)\n",
      "  conv2d_19/BiasAdd (196.61k/196.61k flops)\n",
      "  conv2d_4/BiasAdd (196.61k/196.61k flops)\n",
      "  conv2d_5/BiasAdd (196.61k/196.61k flops)\n",
      "  conv2d_12/BiasAdd (131.07k/131.07k flops)\n",
      "  conv2d_18/BiasAdd (131.07k/131.07k flops)\n",
      "  conv2d_8/BiasAdd (131.07k/131.07k flops)\n",
      "  conv2d_15/BiasAdd (65.54k/65.54k flops)\n",
      "  conv2d_16/BiasAdd (65.54k/65.54k flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/202.85m flops)\n",
      "  conv2d/Conv2D (169.87m/169.87m flops)\n",
      "  conv2d_1/Conv2D (10.62m/10.62m flops)\n",
      "  conv2d_2/Conv2D (10.62m/10.62m flops)\n",
      "  conv2d_3/Conv2D (3.54m/3.54m flops)\n",
      "  conv2d/BiasAdd (3.15m/3.15m flops)\n",
      "  max_pooling2d/MaxPool (3.15m/3.15m flops)\n",
      "  max_pooling2d_1/MaxPool (786.43k/786.43k flops)\n",
      "  conv2d_1/BiasAdd (196.61k/196.61k flops)\n",
      "  conv2d_2/BiasAdd (196.61k/196.61k flops)\n",
      "  conv2d_7/Conv2D (165.89k/165.89k flops)\n",
      "  conv2d_3/BiasAdd (65.54k/65.54k flops)\n",
      "  max_pooling2d_2/MaxPool (65.54k/65.54k flops)\n",
      "  conv2d_10/Conv2D (55.30k/55.30k flops)\n",
      "  conv2d_11/Conv2D (55.30k/55.30k flops)\n",
      "  conv2d_14/Conv2D (55.30k/55.30k flops)\n",
      "  conv2d_6/Conv2D (55.30k/55.30k flops)\n",
      "  conv2d_8/Conv2D (55.30k/55.30k flops)\n",
      "  conv2d_15/Conv2D (36.86k/36.86k flops)\n",
      "  conv2d_12/Conv2D (18.43k/18.43k flops)\n",
      "  conv2d_4/Conv2D (18.43k/18.43k flops)\n",
      "  conv2d_5/Conv2D (18.43k/18.43k flops)\n",
      "  conv2d_9/Conv2D (18.43k/18.43k flops)\n",
      "  max_pooling2d_3/MaxPool (16.38k/16.38k flops)\n",
      "  conv2d_13/Conv2D (13.82k/13.82k flops)\n",
      "  max_pooling2d_4/MaxPool (4.10k/4.10k flops)\n",
      "  conv2d_6/BiasAdd (3.07k/3.07k flops)\n",
      "  conv2d_7/BiasAdd (3.07k/3.07k flops)\n",
      "  conv2d_11/BiasAdd (1.02k/1.02k flops)\n",
      "  conv2d_14/BiasAdd (1.02k/1.02k flops)\n",
      "  conv2d_4/BiasAdd (1.02k/1.02k flops)\n",
      "  conv2d_5/BiasAdd (1.02k/1.02k flops)\n",
      "  conv2d_8/BiasAdd (1.02k/1.02k flops)\n",
      "  conv2d_9/BiasAdd (1.02k/1.02k flops)\n",
      "  max_pooling2d_5/MaxPool (1.02k/1.02k flops)\n",
      "  conv2d_10/BiasAdd (768/768 flops)\n",
      "  conv2d_13/BiasAdd (768/768 flops)\n",
      "  conv2d_15/BiasAdd (512/512 flops)\n",
      "  max_pooling2d_6/MaxPool (512/512 flops)\n",
      "  conv2d_12/BiasAdd (256/256 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/551.39m flops)\n",
      "  conv2d/Conv2D (226.49m/226.49m flops)\n",
      "  conv2d_1/Conv2D (226.49m/226.49m flops)\n",
      "  conv2d_2/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_3/Conv2D (14.16m/14.16m flops)\n",
      "  conv2d_4/Conv2D (14.16m/14.16m flops)\n",
      "  conv2d/BiasAdd (4.19m/4.19m flops)\n",
      "  conv2d_1/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_5/Conv2D (2.36m/2.36m flops)\n",
      "  conv2d_2/BiasAdd (1.05m/1.05m flops)\n",
      "  max_pooling2d/MaxPool (1.05m/1.05m flops)\n",
      "  conv2d_3/BiasAdd (786.43k/786.43k flops)\n",
      "  conv2d_4/BiasAdd (262.14k/262.14k flops)\n",
      "  max_pooling2d_1/MaxPool (262.14k/262.14k flops)\n",
      "  conv2d_5/BiasAdd (131.07k/131.07k flops)\n",
      "  max_pooling2d_2/MaxPool (131.07k/131.07k flops)\n",
      "  conv2d_6/Conv2D (36.86k/36.86k flops)\n",
      "  max_pooling2d_3/MaxPool (32.77k/32.77k flops)\n",
      "  conv2d_9/Conv2D (9.22k/9.22k flops)\n",
      "  max_pooling2d_4/MaxPool (8.19k/8.19k flops)\n",
      "  conv2d_10/Conv2D (4.61k/4.61k flops)\n",
      "  conv2d_7/Conv2D (4.61k/4.61k flops)\n",
      "  conv2d_8/Conv2D (2.30k/2.30k flops)\n",
      "  conv2d_6/BiasAdd (1.02k/1.02k flops)\n",
      "  max_pooling2d_5/MaxPool (1.02k/1.02k flops)\n",
      "  conv2d_11/Conv2D (864/864 flops)\n",
      "  conv2d_12/Conv2D (864/864 flops)\n",
      "  conv2d_7/BiasAdd (256/256 flops)\n",
      "  conv2d_9/BiasAdd (256/256 flops)\n",
      "  max_pooling2d_6/MaxPool (256/256 flops)\n",
      "  conv2d_13/Conv2D (144/144 flops)\n",
      "  conv2d_14/Conv2D (144/144 flops)\n",
      "  conv2d_8/BiasAdd (128/128 flops)\n",
      "  conv2d_10/BiasAdd (64/64 flops)\n",
      "  max_pooling2d_7/MaxPool (64/64 flops)\n",
      "  conv2d_11/BiasAdd (48/48 flops)\n",
      "  conv2d_12/BiasAdd (16/16 flops)\n",
      "  max_pooling2d_8/MaxPool (16/16 flops)\n",
      "  conv2d_13/BiasAdd (8/8 flops)\n",
      "  conv2d_14/BiasAdd (4/4 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.05b flops)\n",
      "  conv2d_11/Conv2D (301.99m/301.99m flops)\n",
      "  conv2d_10/Conv2D (226.49m/226.49m flops)\n",
      "  conv2d_12/Conv2D (226.49m/226.49m flops)\n",
      "  conv2d_6/Conv2D (226.49m/226.49m flops)\n",
      "  conv2d_7/Conv2D (169.87m/169.87m flops)\n",
      "  conv2d_8/Conv2D (169.87m/169.87m flops)\n",
      "  conv2d_9/Conv2D (169.87m/169.87m flops)\n",
      "  conv2d_5/Conv2D (150.99m/150.99m flops)\n",
      "  conv2d_4/Conv2D (113.25m/113.25m flops)\n",
      "  conv2d/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_13/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_3/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_1/Conv2D (18.87m/18.87m flops)\n",
      "  conv2d_2/Conv2D (18.87m/18.87m flops)\n",
      "  conv2d_16/Conv2D (14.16m/14.16m flops)\n",
      "  conv2d_14/Conv2D (9.44m/9.44m flops)\n",
      "  conv2d_15/Conv2D (9.44m/9.44m flops)\n",
      "  conv2d_17/Conv2D (7.08m/7.08m flops)\n",
      "  conv2d_10/BiasAdd (4.19m/4.19m flops)\n",
      "  conv2d_11/BiasAdd (4.19m/4.19m flops)\n",
      "  conv2d_5/BiasAdd (4.19m/4.19m flops)\n",
      "  conv2d_12/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_3/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_6/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_7/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_8/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_9/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_18/Conv2D (2.36m/2.36m flops)\n",
      "  conv2d_20/Conv2D (2.36m/2.36m flops)\n",
      "  conv2d_4/BiasAdd (2.10m/2.10m flops)\n",
      "  conv2d_21/Conv2D (1.77m/1.77m flops)\n",
      "  conv2d_19/Conv2D (1.18m/1.18m flops)\n",
      "  conv2d/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_1/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_13/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_2/BiasAdd (1.05m/1.05m flops)\n",
      "  max_pooling2d/MaxPool (1.05m/1.05m flops)\n",
      "  conv2d_16/BiasAdd (786.43k/786.43k flops)\n",
      "  max_pooling2d_1/MaxPool (786.43k/786.43k flops)\n",
      "  conv2d_14/BiasAdd (524.29k/524.29k flops)\n",
      "  conv2d_15/BiasAdd (262.14k/262.14k flops)\n",
      "  conv2d_17/BiasAdd (131.07k/131.07k flops)\n",
      "  conv2d_20/BiasAdd (131.07k/131.07k flops)\n",
      "  max_pooling2d_2/MaxPool (131.07k/131.07k flops)\n",
      "  conv2d_18/BiasAdd (65.54k/65.54k flops)\n",
      "  conv2d_19/BiasAdd (65.54k/65.54k flops)\n",
      "  conv2d_21/BiasAdd (49.15k/49.15k flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/127.73m flops)\n",
      "  conv2d_1/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d/Conv2D (42.47m/42.47m flops)\n",
      "  conv2d_2/Conv2D (4.72m/4.72m flops)\n",
      "  conv2d_3/Conv2D (3.54m/3.54m flops)\n",
      "  conv2d_4/Conv2D (3.54m/3.54m flops)\n",
      "  conv2d_7/Conv2D (3.54m/3.54m flops)\n",
      "  max_pooling2d/MaxPool (3.15m/3.15m flops)\n",
      "  conv2d_8/Conv2D (2.65m/2.65m flops)\n",
      "  conv2d_5/Conv2D (1.18m/1.18m flops)\n",
      "  conv2d_6/Conv2D (1.18m/1.18m flops)\n",
      "  conv2d_1/BiasAdd (1.05m/1.05m flops)\n",
      "  max_pooling2d_1/MaxPool (1.05m/1.05m flops)\n",
      "  conv2d/BiasAdd (786.43k/786.43k flops)\n",
      "  conv2d_10/Conv2D (294.91k/294.91k flops)\n",
      "  conv2d_11/Conv2D (221.18k/221.18k flops)\n",
      "  conv2d_12/Conv2D (221.18k/221.18k flops)\n",
      "  conv2d_15/Conv2D (221.18k/221.18k flops)\n",
      "  conv2d_9/Conv2D (221.18k/221.18k flops)\n",
      "  conv2d_3/BiasAdd (196.61k/196.61k flops)\n",
      "  conv2d_13/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_14/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_2/BiasAdd (65.54k/65.54k flops)\n",
      "  conv2d_4/BiasAdd (65.54k/65.54k flops)\n",
      "  conv2d_5/BiasAdd (65.54k/65.54k flops)\n",
      "  conv2d_6/BiasAdd (65.54k/65.54k flops)\n",
      "  max_pooling2d_2/MaxPool (65.54k/65.54k flops)\n",
      "  conv2d_7/BiasAdd (49.15k/49.15k flops)\n",
      "  conv2d_8/BiasAdd (49.15k/49.15k flops)\n",
      "  max_pooling2d_3/MaxPool (49.15k/49.15k flops)\n",
      "  conv2d_16/Conv2D (27.65k/27.65k flops)\n",
      "  conv2d_17/Conv2D (18.43k/18.43k flops)\n",
      "  conv2d_19/Conv2D (13.82k/13.82k flops)\n",
      "  max_pooling2d_4/MaxPool (12.29k/12.29k flops)\n",
      "  conv2d_18/Conv2D (9.22k/9.22k flops)\n",
      "  conv2d_10/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_12/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_14/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_9/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_11/BiasAdd (3.07k/3.07k flops)\n",
      "  conv2d_15/BiasAdd (3.07k/3.07k flops)\n",
      "  max_pooling2d_5/MaxPool (3.07k/3.07k flops)\n",
      "  conv2d_13/BiasAdd (2.05k/2.05k flops)\n",
      "  conv2d_19/BiasAdd (768/768 flops)\n",
      "  conv2d_16/BiasAdd (512/512 flops)\n",
      "  conv2d_17/BiasAdd (512/512 flops)\n",
      "  conv2d_18/BiasAdd (256/256 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/17.56m flops)\n",
      "  conv2d_1/Conv2D (3.54m/3.54m flops)\n",
      "  max_pooling2d/MaxPool (3.15m/3.15m flops)\n",
      "  conv2d/Conv2D (2.65m/2.65m flops)\n",
      "  conv2d_6/Conv2D (2.36m/2.36m flops)\n",
      "  conv2d_2/Conv2D (1.18m/1.18m flops)\n",
      "  conv2d_5/Conv2D (1.18m/1.18m flops)\n",
      "  max_pooling2d_1/MaxPool (786.43k/786.43k flops)\n",
      "  conv2d_3/Conv2D (294.91k/294.91k flops)\n",
      "  conv2d_4/Conv2D (294.91k/294.91k flops)\n",
      "  conv2d_14/Conv2D (221.18k/221.18k flops)\n",
      "  conv2d_15/Conv2D (221.18k/221.18k flops)\n",
      "  conv2d_16/Conv2D (221.18k/221.18k flops)\n",
      "  max_pooling2d_2/MaxPool (196.61k/196.61k flops)\n",
      "  conv2d_10/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_13/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_7/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_8/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_9/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_11/Conv2D (73.73k/73.73k flops)\n",
      "  conv2d_12/Conv2D (73.73k/73.73k flops)\n",
      "  conv2d_1/BiasAdd (65.54k/65.54k flops)\n",
      "  conv2d_5/BiasAdd (65.54k/65.54k flops)\n",
      "  conv2d/BiasAdd (49.15k/49.15k flops)\n",
      "  conv2d_6/BiasAdd (32.77k/32.77k flops)\n",
      "  max_pooling2d_3/MaxPool (32.77k/32.77k flops)\n",
      "  conv2d_18/Conv2D (18.43k/18.43k flops)\n",
      "  conv2d_2/BiasAdd (16.38k/16.38k flops)\n",
      "  conv2d_3/BiasAdd (16.38k/16.38k flops)\n",
      "  conv2d_4/BiasAdd (16.38k/16.38k flops)\n",
      "  conv2d_17/Conv2D (13.82k/13.82k flops)\n",
      "  conv2d_8/BiasAdd (8.19k/8.19k flops)\n",
      "  max_pooling2d_4/MaxPool (8.19k/8.19k flops)\n",
      "  conv2d_13/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_15/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_7/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_9/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_14/BiasAdd (3.07k/3.07k flops)\n",
      "  conv2d_16/BiasAdd (3.07k/3.07k flops)\n",
      "  max_pooling2d_5/MaxPool (3.07k/3.07k flops)\n",
      "  conv2d_10/BiasAdd (2.05k/2.05k flops)\n",
      "  conv2d_11/BiasAdd (2.05k/2.05k flops)\n",
      "  conv2d_12/BiasAdd (2.05k/2.05k flops)\n",
      "  conv2d_18/BiasAdd (1.02k/1.02k flops)\n",
      "  max_pooling2d_6/MaxPool (1.02k/1.02k flops)\n",
      "  conv2d_17/BiasAdd (256/256 flops)\n",
      "  max_pooling2d_7/MaxPool (256/256 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/259.24m flops)\n",
      "  conv2d/Conv2D (113.25m/113.25m flops)\n",
      "  conv2d_1/Conv2D (28.31m/28.31m flops)\n",
      "  conv2d_2/Conv2D (28.31m/28.31m flops)\n",
      "  conv2d_3/Conv2D (18.87m/18.87m flops)\n",
      "  conv2d_4/Conv2D (18.87m/18.87m flops)\n",
      "  conv2d_7/Conv2D (18.87m/18.87m flops)\n",
      "  conv2d_6/Conv2D (14.16m/14.16m flops)\n",
      "  conv2d_5/Conv2D (7.08m/7.08m flops)\n",
      "  conv2d/BiasAdd (2.10m/2.10m flops)\n",
      "  max_pooling2d/MaxPool (2.10m/2.10m flops)\n",
      "  conv2d_10/Conv2D (1.18m/1.18m flops)\n",
      "  conv2d_8/Conv2D (1.18m/1.18m flops)\n",
      "  conv2d_1/BiasAdd (786.43k/786.43k flops)\n",
      "  conv2d_9/Conv2D (589.82k/589.82k flops)\n",
      "  conv2d_2/BiasAdd (524.29k/524.29k flops)\n",
      "  conv2d_3/BiasAdd (524.29k/524.29k flops)\n",
      "  conv2d_4/BiasAdd (524.29k/524.29k flops)\n",
      "  max_pooling2d_1/MaxPool (524.29k/524.29k flops)\n",
      "  conv2d_6/BiasAdd (262.14k/262.14k flops)\n",
      "  conv2d_7/BiasAdd (262.14k/262.14k flops)\n",
      "  max_pooling2d_2/MaxPool (262.14k/262.14k flops)\n",
      "  conv2d_5/BiasAdd (196.61k/196.61k flops)\n",
      "  conv2d_12/Conv2D (165.89k/165.89k flops)\n",
      "  conv2d_11/Conv2D (110.59k/110.59k flops)\n",
      "  conv2d_13/Conv2D (41.47k/41.47k flops)\n",
      "  conv2d_10/BiasAdd (32.77k/32.77k flops)\n",
      "  conv2d_9/BiasAdd (32.77k/32.77k flops)\n",
      "  max_pooling2d_3/MaxPool (32.77k/32.77k flops)\n",
      "  conv2d_8/BiasAdd (16.38k/16.38k flops)\n",
      "  conv2d_15/Conv2D (13.82k/13.82k flops)\n",
      "  conv2d_16/Conv2D (13.82k/13.82k flops)\n",
      "  conv2d_14/Conv2D (10.37k/10.37k flops)\n",
      "  conv2d_17/Conv2D (10.37k/10.37k flops)\n",
      "  max_pooling2d_4/MaxPool (8.19k/8.19k flops)\n",
      "  conv2d_18/Conv2D (3.46k/3.46k flops)\n",
      "  conv2d_11/BiasAdd (3.07k/3.07k flops)\n",
      "  conv2d_12/BiasAdd (3.07k/3.07k flops)\n",
      "  max_pooling2d_5/MaxPool (3.07k/3.07k flops)\n",
      "  conv2d_19/Conv2D (864/864 flops)\n",
      "  conv2d_13/BiasAdd (768/768 flops)\n",
      "  max_pooling2d_6/MaxPool (768/768 flops)\n",
      "  conv2d_15/BiasAdd (256/256 flops)\n",
      "  conv2d_14/BiasAdd (192/192 flops)\n",
      "  conv2d_16/BiasAdd (192/192 flops)\n",
      "  conv2d_17/BiasAdd (192/192 flops)\n",
      "  conv2d_18/BiasAdd (64/64 flops)\n",
      "  max_pooling2d_7/MaxPool (64/64 flops)\n",
      "  conv2d_19/BiasAdd (48/48 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.48b flops)\n",
      "  conv2d_5/Conv2D (301.99m/301.99m flops)\n",
      "  conv2d/Conv2D (226.49m/226.49m flops)\n",
      "  conv2d_1/Conv2D (226.49m/226.49m flops)\n",
      "  conv2d_4/Conv2D (226.49m/226.49m flops)\n",
      "  conv2d_2/Conv2D (169.87m/169.87m flops)\n",
      "  conv2d_3/Conv2D (169.87m/169.87m flops)\n",
      "  conv2d_6/Conv2D (75.50m/75.50m flops)\n",
      "  conv2d_10/Conv2D (18.87m/18.87m flops)\n",
      "  conv2d_11/Conv2D (14.16m/14.16m flops)\n",
      "  conv2d_9/Conv2D (9.44m/9.44m flops)\n",
      "  conv2d_8/Conv2D (7.08m/7.08m flops)\n",
      "  conv2d/BiasAdd (4.19m/4.19m flops)\n",
      "  conv2d_4/BiasAdd (4.19m/4.19m flops)\n",
      "  conv2d_5/BiasAdd (4.19m/4.19m flops)\n",
      "  conv2d_7/Conv2D (3.54m/3.54m flops)\n",
      "  conv2d_1/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_2/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_3/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_6/BiasAdd (1.05m/1.05m flops)\n",
      "  max_pooling2d/MaxPool (1.05m/1.05m flops)\n",
      "  conv2d_10/BiasAdd (262.14k/262.14k flops)\n",
      "  conv2d_9/BiasAdd (262.14k/262.14k flops)\n",
      "  max_pooling2d_1/MaxPool (262.14k/262.14k flops)\n",
      "  conv2d_12/Conv2D (221.18k/221.18k flops)\n",
      "  conv2d_13/Conv2D (221.18k/221.18k flops)\n",
      "  conv2d_11/BiasAdd (196.61k/196.61k flops)\n",
      "  conv2d_7/BiasAdd (196.61k/196.61k flops)\n",
      "  max_pooling2d_2/MaxPool (196.61k/196.61k flops)\n",
      "  conv2d_8/BiasAdd (131.07k/131.07k flops)\n",
      "  conv2d_14/Conv2D (55.30k/55.30k flops)\n",
      "  conv2d_15/Conv2D (55.30k/55.30k flops)\n",
      "  conv2d_17/Conv2D (55.30k/55.30k flops)\n",
      "  max_pooling2d_3/MaxPool (49.15k/49.15k flops)\n",
      "  conv2d_16/Conv2D (41.47k/41.47k flops)\n",
      "  conv2d_21/Conv2D (27.65k/27.65k flops)\n",
      "  conv2d_18/Conv2D (18.43k/18.43k flops)\n",
      "  conv2d_22/Conv2D (13.82k/13.82k flops)\n",
      "  max_pooling2d_4/MaxPool (12.29k/12.29k flops)\n",
      "  conv2d_20/Conv2D (9.22k/9.22k flops)\n",
      "  conv2d_23/Conv2D (9.22k/9.22k flops)\n",
      "  conv2d_19/Conv2D (4.61k/4.61k flops)\n",
      "  conv2d_12/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_13/BiasAdd (3.07k/3.07k flops)\n",
      "  max_pooling2d_5/MaxPool (3.07k/3.07k flops)\n",
      "  conv2d_14/BiasAdd (1.02k/1.02k flops)\n",
      "  conv2d_17/BiasAdd (1.02k/1.02k flops)\n",
      "  conv2d_15/BiasAdd (768/768 flops)\n",
      "  conv2d_16/BiasAdd (768/768 flops)\n",
      "  conv2d_21/BiasAdd (768/768 flops)\n",
      "  conv2d_20/BiasAdd (512/512 flops)\n",
      "  conv2d_23/BiasAdd (512/512 flops)\n",
      "  conv2d_18/BiasAdd (256/256 flops)\n",
      "  conv2d_19/BiasAdd (256/256 flops)\n",
      "  conv2d_22/BiasAdd (256/256 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.80b flops)\n",
      "  conv2d_10/Conv2D (301.99m/301.99m flops)\n",
      "  conv2d_7/Conv2D (301.99m/301.99m flops)\n",
      "  conv2d_8/Conv2D (226.49m/226.49m flops)\n",
      "  conv2d_9/Conv2D (226.49m/226.49m flops)\n",
      "  conv2d_4/Conv2D (150.99m/150.99m flops)\n",
      "  conv2d/Conv2D (113.25m/113.25m flops)\n",
      "  conv2d_1/Conv2D (113.25m/113.25m flops)\n",
      "  conv2d_11/Conv2D (75.50m/75.50m flops)\n",
      "  conv2d_3/Conv2D (75.50m/75.50m flops)\n",
      "  conv2d_6/Conv2D (75.50m/75.50m flops)\n",
      "  conv2d_2/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_5/Conv2D (37.75m/37.75m flops)\n",
      "  conv2d_10/BiasAdd (4.19m/4.19m flops)\n",
      "  conv2d_3/BiasAdd (4.19m/4.19m flops)\n",
      "  conv2d_6/BiasAdd (4.19m/4.19m flops)\n",
      "  conv2d_7/BiasAdd (4.19m/4.19m flops)\n",
      "  conv2d_9/BiasAdd (4.19m/4.19m flops)\n",
      "  conv2d_12/Conv2D (3.54m/3.54m flops)\n",
      "  conv2d_15/Conv2D (3.54m/3.54m flops)\n",
      "  conv2d_1/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_8/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_14/Conv2D (2.36m/2.36m flops)\n",
      "  conv2d/BiasAdd (2.10m/2.10m flops)\n",
      "  conv2d_4/BiasAdd (2.10m/2.10m flops)\n",
      "  conv2d_13/Conv2D (1.77m/1.77m flops)\n",
      "  conv2d_11/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_2/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_5/BiasAdd (1.05m/1.05m flops)\n",
      "  max_pooling2d/MaxPool (1.05m/1.05m flops)\n",
      "  conv2d_17/Conv2D (294.91k/294.91k flops)\n",
      "  max_pooling2d_1/MaxPool (262.14k/262.14k flops)\n",
      "  conv2d_16/Conv2D (221.18k/221.18k flops)\n",
      "  conv2d_18/Conv2D (221.18k/221.18k flops)\n",
      "  conv2d_12/BiasAdd (196.61k/196.61k flops)\n",
      "  max_pooling2d_2/MaxPool (196.61k/196.61k flops)\n",
      "  conv2d_14/BiasAdd (65.54k/65.54k flops)\n",
      "  conv2d_15/BiasAdd (49.15k/49.15k flops)\n",
      "  max_pooling2d_3/MaxPool (49.15k/49.15k flops)\n",
      "  conv2d_13/BiasAdd (32.77k/32.77k flops)\n",
      "  conv2d_19/Conv2D (27.65k/27.65k flops)\n",
      "  conv2d_17/BiasAdd (16.38k/16.38k flops)\n",
      "  max_pooling2d_4/MaxPool (16.38k/16.38k flops)\n",
      "  conv2d_20/Conv2D (9.22k/9.22k flops)\n",
      "  conv2d_21/Conv2D (9.22k/9.22k flops)\n",
      "  conv2d_16/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_18/BiasAdd (3.07k/3.07k flops)\n",
      "  max_pooling2d_5/MaxPool (3.07k/3.07k flops)\n",
      "  conv2d_22/Conv2D (576/576 flops)\n",
      "  conv2d_19/BiasAdd (512/512 flops)\n",
      "  max_pooling2d_6/MaxPool (512/512 flops)\n",
      "  conv2d_20/BiasAdd (256/256 flops)\n",
      "  conv2d_21/BiasAdd (128/128 flops)\n",
      "  max_pooling2d_7/MaxPool (128/128 flops)\n",
      "  conv2d_22/BiasAdd (16/16 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/167.22m flops)\n",
      "  conv2d/Conv2D (28.31m/28.31m flops)\n",
      "  conv2d_10/Conv2D (18.87m/18.87m flops)\n",
      "  conv2d_4/Conv2D (14.16m/14.16m flops)\n",
      "  conv2d_5/Conv2D (14.16m/14.16m flops)\n",
      "  conv2d_6/Conv2D (14.16m/14.16m flops)\n",
      "  conv2d_7/Conv2D (14.16m/14.16m flops)\n",
      "  conv2d_8/Conv2D (14.16m/14.16m flops)\n",
      "  conv2d_9/Conv2D (14.16m/14.16m flops)\n",
      "  conv2d_1/Conv2D (4.72m/4.72m flops)\n",
      "  conv2d_11/Conv2D (4.72m/4.72m flops)\n",
      "  conv2d_12/Conv2D (4.72m/4.72m flops)\n",
      "  conv2d_3/Conv2D (4.72m/4.72m flops)\n",
      "  conv2d_13/Conv2D (3.54m/3.54m flops)\n",
      "  max_pooling2d/MaxPool (3.15m/3.15m flops)\n",
      "  conv2d_2/Conv2D (2.36m/2.36m flops)\n",
      "  conv2d_15/Conv2D (1.18m/1.18m flops)\n",
      "  conv2d_16/Conv2D (1.18m/1.18m flops)\n",
      "  conv2d_14/Conv2D (884.74k/884.74k flops)\n",
      "  conv2d/BiasAdd (524.29k/524.29k flops)\n",
      "  max_pooling2d_1/MaxPool (524.29k/524.29k flops)\n",
      "  conv2d_10/BiasAdd (262.14k/262.14k flops)\n",
      "  conv2d_3/BiasAdd (262.14k/262.14k flops)\n",
      "  conv2d_5/BiasAdd (262.14k/262.14k flops)\n",
      "  conv2d_7/BiasAdd (262.14k/262.14k flops)\n",
      "  conv2d_9/BiasAdd (262.14k/262.14k flops)\n",
      "  max_pooling2d_2/MaxPool (262.14k/262.14k flops)\n",
      "  conv2d_4/BiasAdd (196.61k/196.61k flops)\n",
      "  conv2d_6/BiasAdd (196.61k/196.61k flops)\n",
      "  conv2d_8/BiasAdd (196.61k/196.61k flops)\n",
      "  conv2d_17/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_1/BiasAdd (131.07k/131.07k flops)\n",
      "  conv2d_11/BiasAdd (65.54k/65.54k flops)\n",
      "  conv2d_12/BiasAdd (65.54k/65.54k flops)\n",
      "  conv2d_15/BiasAdd (65.54k/65.54k flops)\n",
      "  conv2d_2/BiasAdd (65.54k/65.54k flops)\n",
      "  max_pooling2d_3/MaxPool (65.54k/65.54k flops)\n",
      "  conv2d_13/BiasAdd (49.15k/49.15k flops)\n",
      "  conv2d_14/BiasAdd (16.38k/16.38k flops)\n",
      "  conv2d_16/BiasAdd (16.38k/16.38k flops)\n",
      "  max_pooling2d_4/MaxPool (16.38k/16.38k flops)\n",
      "  conv2d_18/Conv2D (9.22k/9.22k flops)\n",
      "  conv2d_19/Conv2D (9.22k/9.22k flops)\n",
      "  conv2d_17/BiasAdd (2.05k/2.05k flops)\n",
      "  max_pooling2d_5/MaxPool (2.05k/2.05k flops)\n",
      "  conv2d_20/Conv2D (576/576 flops)\n",
      "  max_pooling2d_6/MaxPool (512/512 flops)\n",
      "  conv2d_18/BiasAdd (256/256 flops)\n",
      "  conv2d_19/BiasAdd (128/128 flops)\n",
      "  max_pooling2d_7/MaxPool (128/128 flops)\n",
      "  conv2d_21/Conv2D (54/54 flops)\n",
      "  conv2d_20/BiasAdd (16/16 flops)\n",
      "  max_pooling2d_8/MaxPool (16/16 flops)\n",
      "  max_pooling2d_9/MaxPool (4/4 flops)\n",
      "  conv2d_21/BiasAdd (3/3 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/741.67m flops)\n",
      "  conv2d_4/Conv2D (226.49m/226.49m flops)\n",
      "  conv2d_5/Conv2D (169.87m/169.87m flops)\n",
      "  conv2d/Conv2D (113.25m/113.25m flops)\n",
      "  conv2d_1/Conv2D (75.50m/75.50m flops)\n",
      "  conv2d_3/Conv2D (75.50m/75.50m flops)\n",
      "  conv2d_2/Conv2D (37.75m/37.75m flops)\n",
      "  conv2d_6/Conv2D (14.16m/14.16m flops)\n",
      "  conv2d_3/BiasAdd (4.19m/4.19m flops)\n",
      "  conv2d_4/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_5/BiasAdd (3.15m/3.15m flops)\n",
      "  max_pooling2d/MaxPool (3.15m/3.15m flops)\n",
      "  conv2d/BiasAdd (2.10m/2.10m flops)\n",
      "  conv2d_1/BiasAdd (2.10m/2.10m flops)\n",
      "  conv2d_11/Conv2D (1.77m/1.77m flops)\n",
      "  conv2d_12/Conv2D (1.18m/1.18m flops)\n",
      "  conv2d_2/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_10/Conv2D (884.74k/884.74k flops)\n",
      "  conv2d_16/Conv2D (884.74k/884.74k flops)\n",
      "  conv2d_17/Conv2D (663.55k/663.55k flops)\n",
      "  conv2d_15/Conv2D (589.82k/589.82k flops)\n",
      "  conv2d_7/Conv2D (589.82k/589.82k flops)\n",
      "  conv2d_8/Conv2D (589.82k/589.82k flops)\n",
      "  conv2d_13/Conv2D (442.37k/442.37k flops)\n",
      "  conv2d_14/Conv2D (442.37k/442.37k flops)\n",
      "  conv2d_18/Conv2D (442.37k/442.37k flops)\n",
      "  conv2d_9/Conv2D (294.91k/294.91k flops)\n",
      "  conv2d_6/BiasAdd (262.14k/262.14k flops)\n",
      "  max_pooling2d_1/MaxPool (262.14k/262.14k flops)\n",
      "  conv2d_22/Conv2D (165.89k/165.89k flops)\n",
      "  conv2d_19/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_20/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_21/Conv2D (110.59k/110.59k flops)\n",
      "  max_pooling2d_2/MaxPool (65.54k/65.54k flops)\n",
      "  conv2d_10/BiasAdd (49.15k/49.15k flops)\n",
      "  conv2d_11/BiasAdd (32.77k/32.77k flops)\n",
      "  conv2d_12/BiasAdd (32.77k/32.77k flops)\n",
      "  conv2d_7/BiasAdd (32.77k/32.77k flops)\n",
      "  max_pooling2d_3/MaxPool (32.77k/32.77k flops)\n",
      "  conv2d_25/Conv2D (18.43k/18.43k flops)\n",
      "  conv2d_15/BiasAdd (16.38k/16.38k flops)\n",
      "  conv2d_8/BiasAdd (16.38k/16.38k flops)\n",
      "  conv2d_9/BiasAdd (16.38k/16.38k flops)\n",
      "  conv2d_24/Conv2D (13.82k/13.82k flops)\n",
      "  conv2d_13/BiasAdd (12.29k/12.29k flops)\n",
      "  conv2d_16/BiasAdd (12.29k/12.29k flops)\n",
      "  conv2d_17/BiasAdd (12.29k/12.29k flops)\n",
      "  conv2d_23/Conv2D (10.37k/10.37k flops)\n",
      "  conv2d_14/BiasAdd (8.19k/8.19k flops)\n",
      "  conv2d_18/BiasAdd (8.19k/8.19k flops)\n",
      "  conv2d_20/BiasAdd (8.19k/8.19k flops)\n",
      "  max_pooling2d_4/MaxPool (8.19k/8.19k flops)\n",
      "  conv2d_19/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_21/BiasAdd (3.07k/3.07k flops)\n",
      "  conv2d_22/BiasAdd (3.07k/3.07k flops)\n",
      "  max_pooling2d_5/MaxPool (3.07k/3.07k flops)\n",
      "  max_pooling2d_6/MaxPool (768/768 flops)\n",
      "  conv2d_24/BiasAdd (256/256 flops)\n",
      "  conv2d_25/BiasAdd (256/256 flops)\n",
      "  conv2d_23/BiasAdd (192/192 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/446.31m flops)\n",
      "  conv2d_1/Conv2D (226.49m/226.49m flops)\n",
      "  conv2d/Conv2D (169.87m/169.87m flops)\n",
      "  conv2d_2/Conv2D (14.16m/14.16m flops)\n",
      "  conv2d_4/Conv2D (4.72m/4.72m flops)\n",
      "  conv2d_1/BiasAdd (4.19m/4.19m flops)\n",
      "  max_pooling2d/MaxPool (4.19m/4.19m flops)\n",
      "  conv2d_3/Conv2D (3.54m/3.54m flops)\n",
      "  conv2d_5/Conv2D (3.54m/3.54m flops)\n",
      "  conv2d_6/Conv2D (3.54m/3.54m flops)\n",
      "  conv2d/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_9/Conv2D (1.77m/1.77m flops)\n",
      "  conv2d_11/Conv2D (1.18m/1.18m flops)\n",
      "  conv2d_7/Conv2D (1.18m/1.18m flops)\n",
      "  max_pooling2d_1/MaxPool (1.05m/1.05m flops)\n",
      "  conv2d_10/Conv2D (884.74k/884.74k flops)\n",
      "  conv2d_8/Conv2D (589.82k/589.82k flops)\n",
      "  conv2d_12/Conv2D (294.91k/294.91k flops)\n",
      "  conv2d_13/Conv2D (294.91k/294.91k flops)\n",
      "  conv2d_17/Conv2D (294.91k/294.91k flops)\n",
      "  conv2d_4/BiasAdd (262.14k/262.14k flops)\n",
      "  max_pooling2d_2/MaxPool (262.14k/262.14k flops)\n",
      "  conv2d_2/BiasAdd (196.61k/196.61k flops)\n",
      "  conv2d_14/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_16/Conv2D (73.73k/73.73k flops)\n",
      "  conv2d_3/BiasAdd (65.54k/65.54k flops)\n",
      "  conv2d_6/BiasAdd (65.54k/65.54k flops)\n",
      "  conv2d_5/BiasAdd (49.15k/49.15k flops)\n",
      "  conv2d_9/BiasAdd (49.15k/49.15k flops)\n",
      "  max_pooling2d_3/MaxPool (49.15k/49.15k flops)\n",
      "  conv2d_15/Conv2D (36.86k/36.86k flops)\n",
      "  conv2d_8/BiasAdd (32.77k/32.77k flops)\n",
      "  conv2d_10/BiasAdd (16.38k/16.38k flops)\n",
      "  conv2d_11/BiasAdd (16.38k/16.38k flops)\n",
      "  conv2d_7/BiasAdd (16.38k/16.38k flops)\n",
      "  max_pooling2d_4/MaxPool (16.38k/16.38k flops)\n",
      "  conv2d_18/Conv2D (4.61k/4.61k flops)\n",
      "  conv2d_12/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_13/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_16/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_17/BiasAdd (4.10k/4.10k flops)\n",
      "  max_pooling2d_5/MaxPool (4.10k/4.10k flops)\n",
      "  conv2d_22/Conv2D (2.30k/2.30k flops)\n",
      "  conv2d_14/BiasAdd (2.05k/2.05k flops)\n",
      "  conv2d_21/Conv2D (1.15k/1.15k flops)\n",
      "  conv2d_23/Conv2D (1.15k/1.15k flops)\n",
      "  conv2d_15/BiasAdd (1.02k/1.02k flops)\n",
      "  max_pooling2d_6/MaxPool (1.02k/1.02k flops)\n",
      "  conv2d_20/Conv2D (576/576 flops)\n",
      "  conv2d_19/Conv2D (288/288 flops)\n",
      "  conv2d_18/BiasAdd (64/64 flops)\n",
      "  conv2d_22/BiasAdd (64/64 flops)\n",
      "  max_pooling2d_7/MaxPool (64/64 flops)\n",
      "  max_pooling2d_8/MaxPool (64/64 flops)\n",
      "  conv2d_20/BiasAdd (32/32 flops)\n",
      "  conv2d_21/BiasAdd (32/32 flops)\n",
      "  conv2d_19/BiasAdd (16/16 flops)\n",
      "  conv2d_23/BiasAdd (16/16 flops)\n",
      "  max_pooling2d_9/MaxPool (16/16 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/64.48m flops)\n",
      "  conv2d/Conv2D (28.31m/28.31m flops)\n",
      "  conv2d_3/Conv2D (4.72m/4.72m flops)\n",
      "  conv2d_7/Conv2D (4.72m/4.72m flops)\n",
      "  conv2d_11/Conv2D (3.54m/3.54m flops)\n",
      "  max_pooling2d/MaxPool (3.15m/3.15m flops)\n",
      "  conv2d_1/Conv2D (2.36m/2.36m flops)\n",
      "  conv2d_4/Conv2D (2.36m/2.36m flops)\n",
      "  conv2d_6/Conv2D (2.36m/2.36m flops)\n",
      "  conv2d_12/Conv2D (1.77m/1.77m flops)\n",
      "  conv2d_10/Conv2D (1.18m/1.18m flops)\n",
      "  conv2d_18/Conv2D (1.18m/1.18m flops)\n",
      "  conv2d_2/Conv2D (1.18m/1.18m flops)\n",
      "  conv2d_5/Conv2D (1.18m/1.18m flops)\n",
      "  conv2d_8/Conv2D (1.18m/1.18m flops)\n",
      "  conv2d_19/Conv2D (884.74k/884.74k flops)\n",
      "  conv2d/BiasAdd (524.29k/524.29k flops)\n",
      "  max_pooling2d_1/MaxPool (524.29k/524.29k flops)\n",
      "  conv2d_15/Conv2D (294.91k/294.91k flops)\n",
      "  conv2d_17/Conv2D (294.91k/294.91k flops)\n",
      "  conv2d_9/Conv2D (294.91k/294.91k flops)\n",
      "  conv2d_3/BiasAdd (262.14k/262.14k flops)\n",
      "  max_pooling2d_2/MaxPool (262.14k/262.14k flops)\n",
      "  conv2d_13/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_14/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_16/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_21/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_22/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_24/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_25/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_20/Conv2D (110.59k/110.59k flops)\n",
      "  conv2d_23/Conv2D (73.73k/73.73k flops)\n",
      "  conv2d_1/BiasAdd (65.54k/65.54k flops)\n",
      "  conv2d_10/BiasAdd (65.54k/65.54k flops)\n",
      "  conv2d_2/BiasAdd (65.54k/65.54k flops)\n",
      "  conv2d_6/BiasAdd (65.54k/65.54k flops)\n",
      "  conv2d_7/BiasAdd (65.54k/65.54k flops)\n",
      "  conv2d_11/BiasAdd (49.15k/49.15k flops)\n",
      "  conv2d_26/Conv2D (36.86k/36.86k flops)\n",
      "  conv2d_28/Conv2D (36.86k/36.86k flops)\n",
      "  conv2d_12/BiasAdd (32.77k/32.77k flops)\n",
      "  conv2d_4/BiasAdd (32.77k/32.77k flops)\n",
      "  conv2d_5/BiasAdd (32.77k/32.77k flops)\n",
      "  max_pooling2d_3/MaxPool (32.77k/32.77k flops)\n",
      "  conv2d_27/Conv2D (18.43k/18.43k flops)\n",
      "  conv2d_17/BiasAdd (16.38k/16.38k flops)\n",
      "  conv2d_18/BiasAdd (16.38k/16.38k flops)\n",
      "  conv2d_8/BiasAdd (16.38k/16.38k flops)\n",
      "  conv2d_9/BiasAdd (16.38k/16.38k flops)\n",
      "  conv2d_19/BiasAdd (12.29k/12.29k flops)\n",
      "  max_pooling2d_4/MaxPool (12.29k/12.29k flops)\n",
      "  conv2d_14/BiasAdd (8.19k/8.19k flops)\n",
      "  conv2d_15/BiasAdd (8.19k/8.19k flops)\n",
      "  conv2d_13/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_16/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_21/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_24/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_20/BiasAdd (2.05k/2.05k flops)\n",
      "  conv2d_22/BiasAdd (2.05k/2.05k flops)\n",
      "  conv2d_23/BiasAdd (2.05k/2.05k flops)\n",
      "  conv2d_25/BiasAdd (2.05k/2.05k flops)\n",
      "  conv2d_28/BiasAdd (2.05k/2.05k flops)\n",
      "  max_pooling2d_5/MaxPool (2.05k/2.05k flops)\n",
      "  conv2d_26/BiasAdd (1.02k/1.02k flops)\n",
      "  conv2d_27/BiasAdd (1.02k/1.02k flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/789.85m flops)\n",
      "  conv2d/Conv2D (169.87m/169.87m flops)\n",
      "  conv2d_1/Conv2D (169.87m/169.87m flops)\n",
      "  conv2d_2/Conv2D (113.25m/113.25m flops)\n",
      "  conv2d_3/Conv2D (75.50m/75.50m flops)\n",
      "  conv2d_7/Conv2D (75.50m/75.50m flops)\n",
      "  conv2d_6/Conv2D (37.75m/37.75m flops)\n",
      "  conv2d_8/Conv2D (37.75m/37.75m flops)\n",
      "  conv2d_4/Conv2D (28.31m/28.31m flops)\n",
      "  conv2d_5/Conv2D (28.31m/28.31m flops)\n",
      "  conv2d_9/Conv2D (28.31m/28.31m flops)\n",
      "  conv2d/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_1/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_13/Conv2D (2.36m/2.36m flops)\n",
      "  conv2d_2/BiasAdd (2.10m/2.10m flops)\n",
      "  conv2d_3/BiasAdd (2.10m/2.10m flops)\n",
      "  max_pooling2d/MaxPool (2.10m/2.10m flops)\n",
      "  conv2d_10/Conv2D (1.77m/1.77m flops)\n",
      "  conv2d_6/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_7/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_4/BiasAdd (786.43k/786.43k flops)\n",
      "  conv2d_9/BiasAdd (786.43k/786.43k flops)\n",
      "  max_pooling2d_1/MaxPool (786.43k/786.43k flops)\n",
      "  conv2d_11/Conv2D (589.82k/589.82k flops)\n",
      "  conv2d_12/Conv2D (589.82k/589.82k flops)\n",
      "  conv2d_5/BiasAdd (524.29k/524.29k flops)\n",
      "  conv2d_8/BiasAdd (524.29k/524.29k flops)\n",
      "  conv2d_14/Conv2D (294.91k/294.91k flops)\n",
      "  conv2d_17/Conv2D (294.91k/294.91k flops)\n",
      "  conv2d_15/Conv2D (221.18k/221.18k flops)\n",
      "  conv2d_16/Conv2D (221.18k/221.18k flops)\n",
      "  max_pooling2d_2/MaxPool (196.61k/196.61k flops)\n",
      "  conv2d_18/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_20/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_21/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_19/Conv2D (73.73k/73.73k flops)\n",
      "  conv2d_13/BiasAdd (65.54k/65.54k flops)\n",
      "  max_pooling2d_3/MaxPool (65.54k/65.54k flops)\n",
      "  conv2d_22/Conv2D (36.86k/36.86k flops)\n",
      "  conv2d_10/BiasAdd (32.77k/32.77k flops)\n",
      "  conv2d_12/BiasAdd (32.77k/32.77k flops)\n",
      "  conv2d_11/BiasAdd (16.38k/16.38k flops)\n",
      "  max_pooling2d_4/MaxPool (16.38k/16.38k flops)\n",
      "  conv2d_14/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_16/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_17/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_20/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_23/Conv2D (3.46k/3.46k flops)\n",
      "  conv2d_15/BiasAdd (3.07k/3.07k flops)\n",
      "  conv2d_18/BiasAdd (2.05k/2.05k flops)\n",
      "  conv2d_19/BiasAdd (2.05k/2.05k flops)\n",
      "  conv2d_21/BiasAdd (2.05k/2.05k flops)\n",
      "  conv2d_25/Conv2D (1.15k/1.15k flops)\n",
      "  conv2d_26/Conv2D (1.15k/1.15k flops)\n",
      "  conv2d_22/BiasAdd (1.02k/1.02k flops)\n",
      "  max_pooling2d_5/MaxPool (1.02k/1.02k flops)\n",
      "  conv2d_24/Conv2D (864/864 flops)\n",
      "  max_pooling2d_6/MaxPool (256/256 flops)\n",
      "  conv2d_23/BiasAdd (192/192 flops)\n",
      "  max_pooling2d_7/MaxPool (192/192 flops)\n",
      "  conv2d_25/BiasAdd (64/64 flops)\n",
      "  conv2d_24/BiasAdd (16/16 flops)\n",
      "  conv2d_26/BiasAdd (16/16 flops)\n",
      "  max_pooling2d_8/MaxPool (16/16 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/595.13m flops)\n",
      "  conv2d/Conv2D (169.87m/169.87m flops)\n",
      "  conv2d_1/Conv2D (113.25m/113.25m flops)\n",
      "  conv2d_3/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_5/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_4/Conv2D (42.47m/42.47m flops)\n",
      "  conv2d_2/Conv2D (37.75m/37.75m flops)\n",
      "  conv2d_6/Conv2D (37.75m/37.75m flops)\n",
      "  conv2d_7/Conv2D (28.31m/28.31m flops)\n",
      "  conv2d_8/Conv2D (28.31m/28.31m flops)\n",
      "  conv2d_9/Conv2D (4.72m/4.72m flops)\n",
      "  conv2d/BiasAdd (3.15m/3.15m flops)\n",
      "  conv2d_3/BiasAdd (3.15m/3.15m flops)\n",
      "  max_pooling2d/MaxPool (3.15m/3.15m flops)\n",
      "  conv2d_1/BiasAdd (2.10m/2.10m flops)\n",
      "  conv2d_2/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_5/BiasAdd (1.05m/1.05m flops)\n",
      "  conv2d_4/BiasAdd (786.43k/786.43k flops)\n",
      "  conv2d_7/BiasAdd (786.43k/786.43k flops)\n",
      "  conv2d_6/BiasAdd (524.29k/524.29k flops)\n",
      "  conv2d_8/BiasAdd (524.29k/524.29k flops)\n",
      "  max_pooling2d_1/MaxPool (524.29k/524.29k flops)\n",
      "  conv2d_14/Conv2D (442.37k/442.37k flops)\n",
      "  conv2d_10/Conv2D (294.91k/294.91k flops)\n",
      "  conv2d_11/Conv2D (294.91k/294.91k flops)\n",
      "  conv2d_13/Conv2D (221.18k/221.18k flops)\n",
      "  conv2d_18/Conv2D (221.18k/221.18k flops)\n",
      "  conv2d_12/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_15/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_17/Conv2D (147.46k/147.46k flops)\n",
      "  conv2d_9/BiasAdd (131.07k/131.07k flops)\n",
      "  max_pooling2d_2/MaxPool (131.07k/131.07k flops)\n",
      "  conv2d_21/Conv2D (73.73k/73.73k flops)\n",
      "  conv2d_22/Conv2D (73.73k/73.73k flops)\n",
      "  conv2d_19/Conv2D (55.30k/55.30k flops)\n",
      "  conv2d_23/Conv2D (55.30k/55.30k flops)\n",
      "  conv2d_24/Conv2D (55.30k/55.30k flops)\n",
      "  conv2d_16/Conv2D (36.86k/36.86k flops)\n",
      "  max_pooling2d_3/MaxPool (32.77k/32.77k flops)\n",
      "  conv2d_20/Conv2D (18.43k/18.43k flops)\n",
      "  conv2d_25/Conv2D (18.43k/18.43k flops)\n",
      "  conv2d_13/BiasAdd (12.29k/12.29k flops)\n",
      "  conv2d_28/Conv2D (9.22k/9.22k flops)\n",
      "  conv2d_10/BiasAdd (8.19k/8.19k flops)\n",
      "  conv2d_11/BiasAdd (8.19k/8.19k flops)\n",
      "  conv2d_14/BiasAdd (8.19k/8.19k flops)\n",
      "  conv2d_26/Conv2D (4.61k/4.61k flops)\n",
      "  conv2d_27/Conv2D (4.61k/4.61k flops)\n",
      "  conv2d_12/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_15/BiasAdd (4.10k/4.10k flops)\n",
      "  conv2d_17/BiasAdd (4.10k/4.10k flops)\n",
      "  max_pooling2d_4/MaxPool (4.10k/4.10k flops)\n",
      "  conv2d_18/BiasAdd (3.07k/3.07k flops)\n",
      "  conv2d_29/Conv2D (2.30k/2.30k flops)\n",
      "  conv2d_16/BiasAdd (2.05k/2.05k flops)\n",
      "  conv2d_19/BiasAdd (1.02k/1.02k flops)\n",
      "  conv2d_20/BiasAdd (1.02k/1.02k flops)\n",
      "  conv2d_21/BiasAdd (1.02k/1.02k flops)\n",
      "  conv2d_22/BiasAdd (1.02k/1.02k flops)\n",
      "  conv2d_24/BiasAdd (1.02k/1.02k flops)\n",
      "  max_pooling2d_5/MaxPool (1.02k/1.02k flops)\n",
      "  conv2d_23/BiasAdd (768/768 flops)\n",
      "  conv2d_25/BiasAdd (256/256 flops)\n",
      "  conv2d_26/BiasAdd (256/256 flops)\n",
      "  conv2d_27/BiasAdd (256/256 flops)\n",
      "  max_pooling2d_6/MaxPool (256/256 flops)\n",
      "  conv2d_28/BiasAdd (128/128 flops)\n",
      "  conv2d_29/BiasAdd (64/64 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/420 flops)\n",
      "  dense/MatMul (200/200 flops)\n",
      "  dense_1/MatMul (200/200 flops)\n",
      "  dense/BiasAdd (10/10 flops)\n",
      "  dense_1/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/930 flops)\n",
      "  dense/MatMul (450/450 flops)\n",
      "  dense_1/MatMul (450/450 flops)\n",
      "  dense/BiasAdd (15/15 flops)\n",
      "  dense_1/BiasAdd (15/15 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.64k flops)\n",
      "  dense/MatMul (800/800 flops)\n",
      "  dense_1/MatMul (800/800 flops)\n",
      "  dense/BiasAdd (20/20 flops)\n",
      "  dense_1/BiasAdd (20/20 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.55k flops)\n",
      "  dense/MatMul (1.25k/1.25k flops)\n",
      "  dense_1/MatMul (1.25k/1.25k flops)\n",
      "  dense/BiasAdd (25/25 flops)\n",
      "  dense_1/BiasAdd (25/25 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/3.66k flops)\n",
      "  dense/MatMul (1.80k/1.80k flops)\n",
      "  dense_1/MatMul (1.80k/1.80k flops)\n",
      "  dense/BiasAdd (30/30 flops)\n",
      "  dense_1/BiasAdd (30/30 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/4.97k flops)\n",
      "  dense/MatMul (2.45k/2.45k flops)\n",
      "  dense_1/MatMul (2.45k/2.45k flops)\n",
      "  dense/BiasAdd (35/35 flops)\n",
      "  dense_1/BiasAdd (35/35 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/6.48k flops)\n",
      "  dense/MatMul (3.20k/3.20k flops)\n",
      "  dense_1/MatMul (3.20k/3.20k flops)\n",
      "  dense/BiasAdd (40/40 flops)\n",
      "  dense_1/BiasAdd (40/40 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/8.19k flops)\n",
      "  dense/MatMul (4.05k/4.05k flops)\n",
      "  dense_1/MatMul (4.05k/4.05k flops)\n",
      "  dense/BiasAdd (45/45 flops)\n",
      "  dense_1/BiasAdd (45/45 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/10.10k flops)\n",
      "  dense/MatMul (5.00k/5.00k flops)\n",
      "  dense_1/MatMul (5.00k/5.00k flops)\n",
      "  dense/BiasAdd (50/50 flops)\n",
      "  dense_1/BiasAdd (50/50 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.05k flops)\n",
      "  dense/MatMul (200/200 flops)\n",
      "  dense_1/MatMul (200/200 flops)\n",
      "  dense_2/MatMul (200/200 flops)\n",
      "  dense_3/MatMul (200/200 flops)\n",
      "  dense_4/MatMul (200/200 flops)\n",
      "  dense/BiasAdd (10/10 flops)\n",
      "  dense_1/BiasAdd (10/10 flops)\n",
      "  dense_2/BiasAdd (10/10 flops)\n",
      "  dense_3/BiasAdd (10/10 flops)\n",
      "  dense_4/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.33k flops)\n",
      "  dense/MatMul (450/450 flops)\n",
      "  dense_1/MatMul (450/450 flops)\n",
      "  dense_2/MatMul (450/450 flops)\n",
      "  dense_3/MatMul (450/450 flops)\n",
      "  dense_4/MatMul (450/450 flops)\n",
      "  dense/BiasAdd (15/15 flops)\n",
      "  dense_1/BiasAdd (15/15 flops)\n",
      "  dense_2/BiasAdd (15/15 flops)\n",
      "  dense_3/BiasAdd (15/15 flops)\n",
      "  dense_4/BiasAdd (15/15 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/4.10k flops)\n",
      "  dense/MatMul (800/800 flops)\n",
      "  dense_1/MatMul (800/800 flops)\n",
      "  dense_2/MatMul (800/800 flops)\n",
      "  dense_3/MatMul (800/800 flops)\n",
      "  dense_4/MatMul (800/800 flops)\n",
      "  dense/BiasAdd (20/20 flops)\n",
      "  dense_1/BiasAdd (20/20 flops)\n",
      "  dense_2/BiasAdd (20/20 flops)\n",
      "  dense_3/BiasAdd (20/20 flops)\n",
      "  dense_4/BiasAdd (20/20 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/6.38k flops)\n",
      "  dense/MatMul (1.25k/1.25k flops)\n",
      "  dense_1/MatMul (1.25k/1.25k flops)\n",
      "  dense_2/MatMul (1.25k/1.25k flops)\n",
      "  dense_3/MatMul (1.25k/1.25k flops)\n",
      "  dense_4/MatMul (1.25k/1.25k flops)\n",
      "  dense/BiasAdd (25/25 flops)\n",
      "  dense_1/BiasAdd (25/25 flops)\n",
      "  dense_2/BiasAdd (25/25 flops)\n",
      "  dense_3/BiasAdd (25/25 flops)\n",
      "  dense_4/BiasAdd (25/25 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/9.15k flops)\n",
      "  dense/MatMul (1.80k/1.80k flops)\n",
      "  dense_1/MatMul (1.80k/1.80k flops)\n",
      "  dense_2/MatMul (1.80k/1.80k flops)\n",
      "  dense_3/MatMul (1.80k/1.80k flops)\n",
      "  dense_4/MatMul (1.80k/1.80k flops)\n",
      "  dense/BiasAdd (30/30 flops)\n",
      "  dense_1/BiasAdd (30/30 flops)\n",
      "  dense_2/BiasAdd (30/30 flops)\n",
      "  dense_3/BiasAdd (30/30 flops)\n",
      "  dense_4/BiasAdd (30/30 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/12.43k flops)\n",
      "  dense/MatMul (2.45k/2.45k flops)\n",
      "  dense_1/MatMul (2.45k/2.45k flops)\n",
      "  dense_2/MatMul (2.45k/2.45k flops)\n",
      "  dense_3/MatMul (2.45k/2.45k flops)\n",
      "  dense_4/MatMul (2.45k/2.45k flops)\n",
      "  dense/BiasAdd (35/35 flops)\n",
      "  dense_1/BiasAdd (35/35 flops)\n",
      "  dense_2/BiasAdd (35/35 flops)\n",
      "  dense_3/BiasAdd (35/35 flops)\n",
      "  dense_4/BiasAdd (35/35 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/16.20k flops)\n",
      "  dense/MatMul (3.20k/3.20k flops)\n",
      "  dense_1/MatMul (3.20k/3.20k flops)\n",
      "  dense_2/MatMul (3.20k/3.20k flops)\n",
      "  dense_3/MatMul (3.20k/3.20k flops)\n",
      "  dense_4/MatMul (3.20k/3.20k flops)\n",
      "  dense/BiasAdd (40/40 flops)\n",
      "  dense_1/BiasAdd (40/40 flops)\n",
      "  dense_2/BiasAdd (40/40 flops)\n",
      "  dense_3/BiasAdd (40/40 flops)\n",
      "  dense_4/BiasAdd (40/40 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/20.48k flops)\n",
      "  dense/MatMul (4.05k/4.05k flops)\n",
      "  dense_1/MatMul (4.05k/4.05k flops)\n",
      "  dense_2/MatMul (4.05k/4.05k flops)\n",
      "  dense_3/MatMul (4.05k/4.05k flops)\n",
      "  dense_4/MatMul (4.05k/4.05k flops)\n",
      "  dense/BiasAdd (45/45 flops)\n",
      "  dense_1/BiasAdd (45/45 flops)\n",
      "  dense_2/BiasAdd (45/45 flops)\n",
      "  dense_3/BiasAdd (45/45 flops)\n",
      "  dense_4/BiasAdd (45/45 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/25.25k flops)\n",
      "  dense/MatMul (5.00k/5.00k flops)\n",
      "  dense_1/MatMul (5.00k/5.00k flops)\n",
      "  dense_2/MatMul (5.00k/5.00k flops)\n",
      "  dense_3/MatMul (5.00k/5.00k flops)\n",
      "  dense_4/MatMul (5.00k/5.00k flops)\n",
      "  dense/BiasAdd (50/50 flops)\n",
      "  dense_1/BiasAdd (50/50 flops)\n",
      "  dense_2/BiasAdd (50/50 flops)\n",
      "  dense_3/BiasAdd (50/50 flops)\n",
      "  dense_4/BiasAdd (50/50 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.68k flops)\n",
      "  dense/MatMul (200/200 flops)\n",
      "  dense_1/MatMul (200/200 flops)\n",
      "  dense_2/MatMul (200/200 flops)\n",
      "  dense_3/MatMul (200/200 flops)\n",
      "  dense_4/MatMul (200/200 flops)\n",
      "  dense_5/MatMul (200/200 flops)\n",
      "  dense_6/MatMul (200/200 flops)\n",
      "  dense_7/MatMul (200/200 flops)\n",
      "  dense/BiasAdd (10/10 flops)\n",
      "  dense_1/BiasAdd (10/10 flops)\n",
      "  dense_2/BiasAdd (10/10 flops)\n",
      "  dense_3/BiasAdd (10/10 flops)\n",
      "  dense_4/BiasAdd (10/10 flops)\n",
      "  dense_5/BiasAdd (10/10 flops)\n",
      "  dense_6/BiasAdd (10/10 flops)\n",
      "  dense_7/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/3.72k flops)\n",
      "  dense/MatMul (450/450 flops)\n",
      "  dense_1/MatMul (450/450 flops)\n",
      "  dense_2/MatMul (450/450 flops)\n",
      "  dense_3/MatMul (450/450 flops)\n",
      "  dense_4/MatMul (450/450 flops)\n",
      "  dense_5/MatMul (450/450 flops)\n",
      "  dense_6/MatMul (450/450 flops)\n",
      "  dense_7/MatMul (450/450 flops)\n",
      "  dense/BiasAdd (15/15 flops)\n",
      "  dense_1/BiasAdd (15/15 flops)\n",
      "  dense_2/BiasAdd (15/15 flops)\n",
      "  dense_3/BiasAdd (15/15 flops)\n",
      "  dense_4/BiasAdd (15/15 flops)\n",
      "  dense_5/BiasAdd (15/15 flops)\n",
      "  dense_6/BiasAdd (15/15 flops)\n",
      "  dense_7/BiasAdd (15/15 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/6.56k flops)\n",
      "  dense/MatMul (800/800 flops)\n",
      "  dense_1/MatMul (800/800 flops)\n",
      "  dense_2/MatMul (800/800 flops)\n",
      "  dense_3/MatMul (800/800 flops)\n",
      "  dense_4/MatMul (800/800 flops)\n",
      "  dense_5/MatMul (800/800 flops)\n",
      "  dense_6/MatMul (800/800 flops)\n",
      "  dense_7/MatMul (800/800 flops)\n",
      "  dense/BiasAdd (20/20 flops)\n",
      "  dense_1/BiasAdd (20/20 flops)\n",
      "  dense_2/BiasAdd (20/20 flops)\n",
      "  dense_3/BiasAdd (20/20 flops)\n",
      "  dense_4/BiasAdd (20/20 flops)\n",
      "  dense_5/BiasAdd (20/20 flops)\n",
      "  dense_6/BiasAdd (20/20 flops)\n",
      "  dense_7/BiasAdd (20/20 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/10.20k flops)\n",
      "  dense/MatMul (1.25k/1.25k flops)\n",
      "  dense_1/MatMul (1.25k/1.25k flops)\n",
      "  dense_2/MatMul (1.25k/1.25k flops)\n",
      "  dense_3/MatMul (1.25k/1.25k flops)\n",
      "  dense_4/MatMul (1.25k/1.25k flops)\n",
      "  dense_5/MatMul (1.25k/1.25k flops)\n",
      "  dense_6/MatMul (1.25k/1.25k flops)\n",
      "  dense_7/MatMul (1.25k/1.25k flops)\n",
      "  dense/BiasAdd (25/25 flops)\n",
      "  dense_1/BiasAdd (25/25 flops)\n",
      "  dense_2/BiasAdd (25/25 flops)\n",
      "  dense_3/BiasAdd (25/25 flops)\n",
      "  dense_4/BiasAdd (25/25 flops)\n",
      "  dense_5/BiasAdd (25/25 flops)\n",
      "  dense_6/BiasAdd (25/25 flops)\n",
      "  dense_7/BiasAdd (25/25 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/14.64k flops)\n",
      "  dense/MatMul (1.80k/1.80k flops)\n",
      "  dense_1/MatMul (1.80k/1.80k flops)\n",
      "  dense_2/MatMul (1.80k/1.80k flops)\n",
      "  dense_3/MatMul (1.80k/1.80k flops)\n",
      "  dense_4/MatMul (1.80k/1.80k flops)\n",
      "  dense_5/MatMul (1.80k/1.80k flops)\n",
      "  dense_6/MatMul (1.80k/1.80k flops)\n",
      "  dense_7/MatMul (1.80k/1.80k flops)\n",
      "  dense/BiasAdd (30/30 flops)\n",
      "  dense_1/BiasAdd (30/30 flops)\n",
      "  dense_2/BiasAdd (30/30 flops)\n",
      "  dense_3/BiasAdd (30/30 flops)\n",
      "  dense_4/BiasAdd (30/30 flops)\n",
      "  dense_5/BiasAdd (30/30 flops)\n",
      "  dense_6/BiasAdd (30/30 flops)\n",
      "  dense_7/BiasAdd (30/30 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/19.88k flops)\n",
      "  dense/MatMul (2.45k/2.45k flops)\n",
      "  dense_1/MatMul (2.45k/2.45k flops)\n",
      "  dense_2/MatMul (2.45k/2.45k flops)\n",
      "  dense_3/MatMul (2.45k/2.45k flops)\n",
      "  dense_4/MatMul (2.45k/2.45k flops)\n",
      "  dense_5/MatMul (2.45k/2.45k flops)\n",
      "  dense_6/MatMul (2.45k/2.45k flops)\n",
      "  dense_7/MatMul (2.45k/2.45k flops)\n",
      "  dense/BiasAdd (35/35 flops)\n",
      "  dense_1/BiasAdd (35/35 flops)\n",
      "  dense_2/BiasAdd (35/35 flops)\n",
      "  dense_3/BiasAdd (35/35 flops)\n",
      "  dense_4/BiasAdd (35/35 flops)\n",
      "  dense_5/BiasAdd (35/35 flops)\n",
      "  dense_6/BiasAdd (35/35 flops)\n",
      "  dense_7/BiasAdd (35/35 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/25.92k flops)\n",
      "  dense/MatMul (3.20k/3.20k flops)\n",
      "  dense_1/MatMul (3.20k/3.20k flops)\n",
      "  dense_2/MatMul (3.20k/3.20k flops)\n",
      "  dense_3/MatMul (3.20k/3.20k flops)\n",
      "  dense_4/MatMul (3.20k/3.20k flops)\n",
      "  dense_5/MatMul (3.20k/3.20k flops)\n",
      "  dense_6/MatMul (3.20k/3.20k flops)\n",
      "  dense_7/MatMul (3.20k/3.20k flops)\n",
      "  dense/BiasAdd (40/40 flops)\n",
      "  dense_1/BiasAdd (40/40 flops)\n",
      "  dense_2/BiasAdd (40/40 flops)\n",
      "  dense_3/BiasAdd (40/40 flops)\n",
      "  dense_4/BiasAdd (40/40 flops)\n",
      "  dense_5/BiasAdd (40/40 flops)\n",
      "  dense_6/BiasAdd (40/40 flops)\n",
      "  dense_7/BiasAdd (40/40 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/32.76k flops)\n",
      "  dense/MatMul (4.05k/4.05k flops)\n",
      "  dense_1/MatMul (4.05k/4.05k flops)\n",
      "  dense_2/MatMul (4.05k/4.05k flops)\n",
      "  dense_3/MatMul (4.05k/4.05k flops)\n",
      "  dense_4/MatMul (4.05k/4.05k flops)\n",
      "  dense_5/MatMul (4.05k/4.05k flops)\n",
      "  dense_6/MatMul (4.05k/4.05k flops)\n",
      "  dense_7/MatMul (4.05k/4.05k flops)\n",
      "  dense/BiasAdd (45/45 flops)\n",
      "  dense_1/BiasAdd (45/45 flops)\n",
      "  dense_2/BiasAdd (45/45 flops)\n",
      "  dense_3/BiasAdd (45/45 flops)\n",
      "  dense_4/BiasAdd (45/45 flops)\n",
      "  dense_5/BiasAdd (45/45 flops)\n",
      "  dense_6/BiasAdd (45/45 flops)\n",
      "  dense_7/BiasAdd (45/45 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/40.40k flops)\n",
      "  dense/MatMul (5.00k/5.00k flops)\n",
      "  dense_1/MatMul (5.00k/5.00k flops)\n",
      "  dense_2/MatMul (5.00k/5.00k flops)\n",
      "  dense_3/MatMul (5.00k/5.00k flops)\n",
      "  dense_4/MatMul (5.00k/5.00k flops)\n",
      "  dense_5/MatMul (5.00k/5.00k flops)\n",
      "  dense_6/MatMul (5.00k/5.00k flops)\n",
      "  dense_7/MatMul (5.00k/5.00k flops)\n",
      "  dense/BiasAdd (50/50 flops)\n",
      "  dense_1/BiasAdd (50/50 flops)\n",
      "  dense_2/BiasAdd (50/50 flops)\n",
      "  dense_3/BiasAdd (50/50 flops)\n",
      "  dense_4/BiasAdd (50/50 flops)\n",
      "  dense_5/BiasAdd (50/50 flops)\n",
      "  dense_6/BiasAdd (50/50 flops)\n",
      "  dense_7/BiasAdd (50/50 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.31k flops)\n",
      "  dense/MatMul (200/200 flops)\n",
      "  dense_1/MatMul (200/200 flops)\n",
      "  dense_10/MatMul (200/200 flops)\n",
      "  dense_2/MatMul (200/200 flops)\n",
      "  dense_3/MatMul (200/200 flops)\n",
      "  dense_4/MatMul (200/200 flops)\n",
      "  dense_5/MatMul (200/200 flops)\n",
      "  dense_6/MatMul (200/200 flops)\n",
      "  dense_7/MatMul (200/200 flops)\n",
      "  dense_8/MatMul (200/200 flops)\n",
      "  dense_9/MatMul (200/200 flops)\n",
      "  dense/BiasAdd (10/10 flops)\n",
      "  dense_1/BiasAdd (10/10 flops)\n",
      "  dense_10/BiasAdd (10/10 flops)\n",
      "  dense_2/BiasAdd (10/10 flops)\n",
      "  dense_3/BiasAdd (10/10 flops)\n",
      "  dense_4/BiasAdd (10/10 flops)\n",
      "  dense_5/BiasAdd (10/10 flops)\n",
      "  dense_6/BiasAdd (10/10 flops)\n",
      "  dense_7/BiasAdd (10/10 flops)\n",
      "  dense_8/BiasAdd (10/10 flops)\n",
      "  dense_9/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/5.12k flops)\n",
      "  dense/MatMul (450/450 flops)\n",
      "  dense_1/MatMul (450/450 flops)\n",
      "  dense_10/MatMul (450/450 flops)\n",
      "  dense_2/MatMul (450/450 flops)\n",
      "  dense_3/MatMul (450/450 flops)\n",
      "  dense_4/MatMul (450/450 flops)\n",
      "  dense_5/MatMul (450/450 flops)\n",
      "  dense_6/MatMul (450/450 flops)\n",
      "  dense_7/MatMul (450/450 flops)\n",
      "  dense_8/MatMul (450/450 flops)\n",
      "  dense_9/MatMul (450/450 flops)\n",
      "  dense/BiasAdd (15/15 flops)\n",
      "  dense_1/BiasAdd (15/15 flops)\n",
      "  dense_10/BiasAdd (15/15 flops)\n",
      "  dense_2/BiasAdd (15/15 flops)\n",
      "  dense_3/BiasAdd (15/15 flops)\n",
      "  dense_4/BiasAdd (15/15 flops)\n",
      "  dense_5/BiasAdd (15/15 flops)\n",
      "  dense_6/BiasAdd (15/15 flops)\n",
      "  dense_7/BiasAdd (15/15 flops)\n",
      "  dense_8/BiasAdd (15/15 flops)\n",
      "  dense_9/BiasAdd (15/15 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/9.02k flops)\n",
      "  dense/MatMul (800/800 flops)\n",
      "  dense_1/MatMul (800/800 flops)\n",
      "  dense_10/MatMul (800/800 flops)\n",
      "  dense_2/MatMul (800/800 flops)\n",
      "  dense_3/MatMul (800/800 flops)\n",
      "  dense_4/MatMul (800/800 flops)\n",
      "  dense_5/MatMul (800/800 flops)\n",
      "  dense_6/MatMul (800/800 flops)\n",
      "  dense_7/MatMul (800/800 flops)\n",
      "  dense_8/MatMul (800/800 flops)\n",
      "  dense_9/MatMul (800/800 flops)\n",
      "  dense/BiasAdd (20/20 flops)\n",
      "  dense_1/BiasAdd (20/20 flops)\n",
      "  dense_10/BiasAdd (20/20 flops)\n",
      "  dense_2/BiasAdd (20/20 flops)\n",
      "  dense_3/BiasAdd (20/20 flops)\n",
      "  dense_4/BiasAdd (20/20 flops)\n",
      "  dense_5/BiasAdd (20/20 flops)\n",
      "  dense_6/BiasAdd (20/20 flops)\n",
      "  dense_7/BiasAdd (20/20 flops)\n",
      "  dense_8/BiasAdd (20/20 flops)\n",
      "  dense_9/BiasAdd (20/20 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/14.03k flops)\n",
      "  dense/MatMul (1.25k/1.25k flops)\n",
      "  dense_1/MatMul (1.25k/1.25k flops)\n",
      "  dense_10/MatMul (1.25k/1.25k flops)\n",
      "  dense_2/MatMul (1.25k/1.25k flops)\n",
      "  dense_3/MatMul (1.25k/1.25k flops)\n",
      "  dense_4/MatMul (1.25k/1.25k flops)\n",
      "  dense_5/MatMul (1.25k/1.25k flops)\n",
      "  dense_6/MatMul (1.25k/1.25k flops)\n",
      "  dense_7/MatMul (1.25k/1.25k flops)\n",
      "  dense_8/MatMul (1.25k/1.25k flops)\n",
      "  dense_9/MatMul (1.25k/1.25k flops)\n",
      "  dense/BiasAdd (25/25 flops)\n",
      "  dense_1/BiasAdd (25/25 flops)\n",
      "  dense_10/BiasAdd (25/25 flops)\n",
      "  dense_2/BiasAdd (25/25 flops)\n",
      "  dense_3/BiasAdd (25/25 flops)\n",
      "  dense_4/BiasAdd (25/25 flops)\n",
      "  dense_5/BiasAdd (25/25 flops)\n",
      "  dense_6/BiasAdd (25/25 flops)\n",
      "  dense_7/BiasAdd (25/25 flops)\n",
      "  dense_8/BiasAdd (25/25 flops)\n",
      "  dense_9/BiasAdd (25/25 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/20.13k flops)\n",
      "  dense/MatMul (1.80k/1.80k flops)\n",
      "  dense_1/MatMul (1.80k/1.80k flops)\n",
      "  dense_10/MatMul (1.80k/1.80k flops)\n",
      "  dense_2/MatMul (1.80k/1.80k flops)\n",
      "  dense_3/MatMul (1.80k/1.80k flops)\n",
      "  dense_4/MatMul (1.80k/1.80k flops)\n",
      "  dense_5/MatMul (1.80k/1.80k flops)\n",
      "  dense_6/MatMul (1.80k/1.80k flops)\n",
      "  dense_7/MatMul (1.80k/1.80k flops)\n",
      "  dense_8/MatMul (1.80k/1.80k flops)\n",
      "  dense_9/MatMul (1.80k/1.80k flops)\n",
      "  dense/BiasAdd (30/30 flops)\n",
      "  dense_1/BiasAdd (30/30 flops)\n",
      "  dense_10/BiasAdd (30/30 flops)\n",
      "  dense_2/BiasAdd (30/30 flops)\n",
      "  dense_3/BiasAdd (30/30 flops)\n",
      "  dense_4/BiasAdd (30/30 flops)\n",
      "  dense_5/BiasAdd (30/30 flops)\n",
      "  dense_6/BiasAdd (30/30 flops)\n",
      "  dense_7/BiasAdd (30/30 flops)\n",
      "  dense_8/BiasAdd (30/30 flops)\n",
      "  dense_9/BiasAdd (30/30 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/27.34k flops)\n",
      "  dense/MatMul (2.45k/2.45k flops)\n",
      "  dense_1/MatMul (2.45k/2.45k flops)\n",
      "  dense_10/MatMul (2.45k/2.45k flops)\n",
      "  dense_2/MatMul (2.45k/2.45k flops)\n",
      "  dense_3/MatMul (2.45k/2.45k flops)\n",
      "  dense_4/MatMul (2.45k/2.45k flops)\n",
      "  dense_5/MatMul (2.45k/2.45k flops)\n",
      "  dense_6/MatMul (2.45k/2.45k flops)\n",
      "  dense_7/MatMul (2.45k/2.45k flops)\n",
      "  dense_8/MatMul (2.45k/2.45k flops)\n",
      "  dense_9/MatMul (2.45k/2.45k flops)\n",
      "  dense/BiasAdd (35/35 flops)\n",
      "  dense_1/BiasAdd (35/35 flops)\n",
      "  dense_10/BiasAdd (35/35 flops)\n",
      "  dense_2/BiasAdd (35/35 flops)\n",
      "  dense_3/BiasAdd (35/35 flops)\n",
      "  dense_4/BiasAdd (35/35 flops)\n",
      "  dense_5/BiasAdd (35/35 flops)\n",
      "  dense_6/BiasAdd (35/35 flops)\n",
      "  dense_7/BiasAdd (35/35 flops)\n",
      "  dense_8/BiasAdd (35/35 flops)\n",
      "  dense_9/BiasAdd (35/35 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/35.64k flops)\n",
      "  dense/MatMul (3.20k/3.20k flops)\n",
      "  dense_1/MatMul (3.20k/3.20k flops)\n",
      "  dense_10/MatMul (3.20k/3.20k flops)\n",
      "  dense_2/MatMul (3.20k/3.20k flops)\n",
      "  dense_3/MatMul (3.20k/3.20k flops)\n",
      "  dense_4/MatMul (3.20k/3.20k flops)\n",
      "  dense_5/MatMul (3.20k/3.20k flops)\n",
      "  dense_6/MatMul (3.20k/3.20k flops)\n",
      "  dense_7/MatMul (3.20k/3.20k flops)\n",
      "  dense_8/MatMul (3.20k/3.20k flops)\n",
      "  dense_9/MatMul (3.20k/3.20k flops)\n",
      "  dense/BiasAdd (40/40 flops)\n",
      "  dense_1/BiasAdd (40/40 flops)\n",
      "  dense_10/BiasAdd (40/40 flops)\n",
      "  dense_2/BiasAdd (40/40 flops)\n",
      "  dense_3/BiasAdd (40/40 flops)\n",
      "  dense_4/BiasAdd (40/40 flops)\n",
      "  dense_5/BiasAdd (40/40 flops)\n",
      "  dense_6/BiasAdd (40/40 flops)\n",
      "  dense_7/BiasAdd (40/40 flops)\n",
      "  dense_8/BiasAdd (40/40 flops)\n",
      "  dense_9/BiasAdd (40/40 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/45.05k flops)\n",
      "  dense/MatMul (4.05k/4.05k flops)\n",
      "  dense_1/MatMul (4.05k/4.05k flops)\n",
      "  dense_10/MatMul (4.05k/4.05k flops)\n",
      "  dense_2/MatMul (4.05k/4.05k flops)\n",
      "  dense_3/MatMul (4.05k/4.05k flops)\n",
      "  dense_4/MatMul (4.05k/4.05k flops)\n",
      "  dense_5/MatMul (4.05k/4.05k flops)\n",
      "  dense_6/MatMul (4.05k/4.05k flops)\n",
      "  dense_7/MatMul (4.05k/4.05k flops)\n",
      "  dense_8/MatMul (4.05k/4.05k flops)\n",
      "  dense_9/MatMul (4.05k/4.05k flops)\n",
      "  dense/BiasAdd (45/45 flops)\n",
      "  dense_1/BiasAdd (45/45 flops)\n",
      "  dense_10/BiasAdd (45/45 flops)\n",
      "  dense_2/BiasAdd (45/45 flops)\n",
      "  dense_3/BiasAdd (45/45 flops)\n",
      "  dense_4/BiasAdd (45/45 flops)\n",
      "  dense_5/BiasAdd (45/45 flops)\n",
      "  dense_6/BiasAdd (45/45 flops)\n",
      "  dense_7/BiasAdd (45/45 flops)\n",
      "  dense_8/BiasAdd (45/45 flops)\n",
      "  dense_9/BiasAdd (45/45 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/55.55k flops)\n",
      "  dense/MatMul (5.00k/5.00k flops)\n",
      "  dense_1/MatMul (5.00k/5.00k flops)\n",
      "  dense_10/MatMul (5.00k/5.00k flops)\n",
      "  dense_2/MatMul (5.00k/5.00k flops)\n",
      "  dense_3/MatMul (5.00k/5.00k flops)\n",
      "  dense_4/MatMul (5.00k/5.00k flops)\n",
      "  dense_5/MatMul (5.00k/5.00k flops)\n",
      "  dense_6/MatMul (5.00k/5.00k flops)\n",
      "  dense_7/MatMul (5.00k/5.00k flops)\n",
      "  dense_8/MatMul (5.00k/5.00k flops)\n",
      "  dense_9/MatMul (5.00k/5.00k flops)\n",
      "  dense/BiasAdd (50/50 flops)\n",
      "  dense_1/BiasAdd (50/50 flops)\n",
      "  dense_10/BiasAdd (50/50 flops)\n",
      "  dense_2/BiasAdd (50/50 flops)\n",
      "  dense_3/BiasAdd (50/50 flops)\n",
      "  dense_4/BiasAdd (50/50 flops)\n",
      "  dense_5/BiasAdd (50/50 flops)\n",
      "  dense_6/BiasAdd (50/50 flops)\n",
      "  dense_7/BiasAdd (50/50 flops)\n",
      "  dense_8/BiasAdd (50/50 flops)\n",
      "  dense_9/BiasAdd (50/50 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.94k flops)\n",
      "  dense/MatMul (200/200 flops)\n",
      "  dense_1/MatMul (200/200 flops)\n",
      "  dense_10/MatMul (200/200 flops)\n",
      "  dense_11/MatMul (200/200 flops)\n",
      "  dense_12/MatMul (200/200 flops)\n",
      "  dense_13/MatMul (200/200 flops)\n",
      "  dense_2/MatMul (200/200 flops)\n",
      "  dense_3/MatMul (200/200 flops)\n",
      "  dense_4/MatMul (200/200 flops)\n",
      "  dense_5/MatMul (200/200 flops)\n",
      "  dense_6/MatMul (200/200 flops)\n",
      "  dense_7/MatMul (200/200 flops)\n",
      "  dense_8/MatMul (200/200 flops)\n",
      "  dense_9/MatMul (200/200 flops)\n",
      "  dense/BiasAdd (10/10 flops)\n",
      "  dense_1/BiasAdd (10/10 flops)\n",
      "  dense_10/BiasAdd (10/10 flops)\n",
      "  dense_11/BiasAdd (10/10 flops)\n",
      "  dense_12/BiasAdd (10/10 flops)\n",
      "  dense_13/BiasAdd (10/10 flops)\n",
      "  dense_2/BiasAdd (10/10 flops)\n",
      "  dense_3/BiasAdd (10/10 flops)\n",
      "  dense_4/BiasAdd (10/10 flops)\n",
      "  dense_5/BiasAdd (10/10 flops)\n",
      "  dense_6/BiasAdd (10/10 flops)\n",
      "  dense_7/BiasAdd (10/10 flops)\n",
      "  dense_8/BiasAdd (10/10 flops)\n",
      "  dense_9/BiasAdd (10/10 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/6.51k flops)\n",
      "  dense/MatMul (450/450 flops)\n",
      "  dense_1/MatMul (450/450 flops)\n",
      "  dense_10/MatMul (450/450 flops)\n",
      "  dense_11/MatMul (450/450 flops)\n",
      "  dense_12/MatMul (450/450 flops)\n",
      "  dense_13/MatMul (450/450 flops)\n",
      "  dense_2/MatMul (450/450 flops)\n",
      "  dense_3/MatMul (450/450 flops)\n",
      "  dense_4/MatMul (450/450 flops)\n",
      "  dense_5/MatMul (450/450 flops)\n",
      "  dense_6/MatMul (450/450 flops)\n",
      "  dense_7/MatMul (450/450 flops)\n",
      "  dense_8/MatMul (450/450 flops)\n",
      "  dense_9/MatMul (450/450 flops)\n",
      "  dense/BiasAdd (15/15 flops)\n",
      "  dense_1/BiasAdd (15/15 flops)\n",
      "  dense_10/BiasAdd (15/15 flops)\n",
      "  dense_11/BiasAdd (15/15 flops)\n",
      "  dense_12/BiasAdd (15/15 flops)\n",
      "  dense_13/BiasAdd (15/15 flops)\n",
      "  dense_2/BiasAdd (15/15 flops)\n",
      "  dense_3/BiasAdd (15/15 flops)\n",
      "  dense_4/BiasAdd (15/15 flops)\n",
      "  dense_5/BiasAdd (15/15 flops)\n",
      "  dense_6/BiasAdd (15/15 flops)\n",
      "  dense_7/BiasAdd (15/15 flops)\n",
      "  dense_8/BiasAdd (15/15 flops)\n",
      "  dense_9/BiasAdd (15/15 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/11.48k flops)\n",
      "  dense/MatMul (800/800 flops)\n",
      "  dense_1/MatMul (800/800 flops)\n",
      "  dense_10/MatMul (800/800 flops)\n",
      "  dense_11/MatMul (800/800 flops)\n",
      "  dense_12/MatMul (800/800 flops)\n",
      "  dense_13/MatMul (800/800 flops)\n",
      "  dense_2/MatMul (800/800 flops)\n",
      "  dense_3/MatMul (800/800 flops)\n",
      "  dense_4/MatMul (800/800 flops)\n",
      "  dense_5/MatMul (800/800 flops)\n",
      "  dense_6/MatMul (800/800 flops)\n",
      "  dense_7/MatMul (800/800 flops)\n",
      "  dense_8/MatMul (800/800 flops)\n",
      "  dense_9/MatMul (800/800 flops)\n",
      "  dense/BiasAdd (20/20 flops)\n",
      "  dense_1/BiasAdd (20/20 flops)\n",
      "  dense_10/BiasAdd (20/20 flops)\n",
      "  dense_11/BiasAdd (20/20 flops)\n",
      "  dense_12/BiasAdd (20/20 flops)\n",
      "  dense_13/BiasAdd (20/20 flops)\n",
      "  dense_2/BiasAdd (20/20 flops)\n",
      "  dense_3/BiasAdd (20/20 flops)\n",
      "  dense_4/BiasAdd (20/20 flops)\n",
      "  dense_5/BiasAdd (20/20 flops)\n",
      "  dense_6/BiasAdd (20/20 flops)\n",
      "  dense_7/BiasAdd (20/20 flops)\n",
      "  dense_8/BiasAdd (20/20 flops)\n",
      "  dense_9/BiasAdd (20/20 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/17.85k flops)\n",
      "  dense/MatMul (1.25k/1.25k flops)\n",
      "  dense_1/MatMul (1.25k/1.25k flops)\n",
      "  dense_10/MatMul (1.25k/1.25k flops)\n",
      "  dense_11/MatMul (1.25k/1.25k flops)\n",
      "  dense_12/MatMul (1.25k/1.25k flops)\n",
      "  dense_13/MatMul (1.25k/1.25k flops)\n",
      "  dense_2/MatMul (1.25k/1.25k flops)\n",
      "  dense_3/MatMul (1.25k/1.25k flops)\n",
      "  dense_4/MatMul (1.25k/1.25k flops)\n",
      "  dense_5/MatMul (1.25k/1.25k flops)\n",
      "  dense_6/MatMul (1.25k/1.25k flops)\n",
      "  dense_7/MatMul (1.25k/1.25k flops)\n",
      "  dense_8/MatMul (1.25k/1.25k flops)\n",
      "  dense_9/MatMul (1.25k/1.25k flops)\n",
      "  dense/BiasAdd (25/25 flops)\n",
      "  dense_1/BiasAdd (25/25 flops)\n",
      "  dense_10/BiasAdd (25/25 flops)\n",
      "  dense_11/BiasAdd (25/25 flops)\n",
      "  dense_12/BiasAdd (25/25 flops)\n",
      "  dense_13/BiasAdd (25/25 flops)\n",
      "  dense_2/BiasAdd (25/25 flops)\n",
      "  dense_3/BiasAdd (25/25 flops)\n",
      "  dense_4/BiasAdd (25/25 flops)\n",
      "  dense_5/BiasAdd (25/25 flops)\n",
      "  dense_6/BiasAdd (25/25 flops)\n",
      "  dense_7/BiasAdd (25/25 flops)\n",
      "  dense_8/BiasAdd (25/25 flops)\n",
      "  dense_9/BiasAdd (25/25 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/25.62k flops)\n",
      "  dense/MatMul (1.80k/1.80k flops)\n",
      "  dense_1/MatMul (1.80k/1.80k flops)\n",
      "  dense_10/MatMul (1.80k/1.80k flops)\n",
      "  dense_11/MatMul (1.80k/1.80k flops)\n",
      "  dense_12/MatMul (1.80k/1.80k flops)\n",
      "  dense_13/MatMul (1.80k/1.80k flops)\n",
      "  dense_2/MatMul (1.80k/1.80k flops)\n",
      "  dense_3/MatMul (1.80k/1.80k flops)\n",
      "  dense_4/MatMul (1.80k/1.80k flops)\n",
      "  dense_5/MatMul (1.80k/1.80k flops)\n",
      "  dense_6/MatMul (1.80k/1.80k flops)\n",
      "  dense_7/MatMul (1.80k/1.80k flops)\n",
      "  dense_8/MatMul (1.80k/1.80k flops)\n",
      "  dense_9/MatMul (1.80k/1.80k flops)\n",
      "  dense/BiasAdd (30/30 flops)\n",
      "  dense_1/BiasAdd (30/30 flops)\n",
      "  dense_10/BiasAdd (30/30 flops)\n",
      "  dense_11/BiasAdd (30/30 flops)\n",
      "  dense_12/BiasAdd (30/30 flops)\n",
      "  dense_13/BiasAdd (30/30 flops)\n",
      "  dense_2/BiasAdd (30/30 flops)\n",
      "  dense_3/BiasAdd (30/30 flops)\n",
      "  dense_4/BiasAdd (30/30 flops)\n",
      "  dense_5/BiasAdd (30/30 flops)\n",
      "  dense_6/BiasAdd (30/30 flops)\n",
      "  dense_7/BiasAdd (30/30 flops)\n",
      "  dense_8/BiasAdd (30/30 flops)\n",
      "  dense_9/BiasAdd (30/30 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/34.79k flops)\n",
      "  dense/MatMul (2.45k/2.45k flops)\n",
      "  dense_1/MatMul (2.45k/2.45k flops)\n",
      "  dense_10/MatMul (2.45k/2.45k flops)\n",
      "  dense_11/MatMul (2.45k/2.45k flops)\n",
      "  dense_12/MatMul (2.45k/2.45k flops)\n",
      "  dense_13/MatMul (2.45k/2.45k flops)\n",
      "  dense_2/MatMul (2.45k/2.45k flops)\n",
      "  dense_3/MatMul (2.45k/2.45k flops)\n",
      "  dense_4/MatMul (2.45k/2.45k flops)\n",
      "  dense_5/MatMul (2.45k/2.45k flops)\n",
      "  dense_6/MatMul (2.45k/2.45k flops)\n",
      "  dense_7/MatMul (2.45k/2.45k flops)\n",
      "  dense_8/MatMul (2.45k/2.45k flops)\n",
      "  dense_9/MatMul (2.45k/2.45k flops)\n",
      "  dense/BiasAdd (35/35 flops)\n",
      "  dense_1/BiasAdd (35/35 flops)\n",
      "  dense_10/BiasAdd (35/35 flops)\n",
      "  dense_11/BiasAdd (35/35 flops)\n",
      "  dense_12/BiasAdd (35/35 flops)\n",
      "  dense_13/BiasAdd (35/35 flops)\n",
      "  dense_2/BiasAdd (35/35 flops)\n",
      "  dense_3/BiasAdd (35/35 flops)\n",
      "  dense_4/BiasAdd (35/35 flops)\n",
      "  dense_5/BiasAdd (35/35 flops)\n",
      "  dense_6/BiasAdd (35/35 flops)\n",
      "  dense_7/BiasAdd (35/35 flops)\n",
      "  dense_8/BiasAdd (35/35 flops)\n",
      "  dense_9/BiasAdd (35/35 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/45.36k flops)\n",
      "  dense/MatMul (3.20k/3.20k flops)\n",
      "  dense_1/MatMul (3.20k/3.20k flops)\n",
      "  dense_10/MatMul (3.20k/3.20k flops)\n",
      "  dense_11/MatMul (3.20k/3.20k flops)\n",
      "  dense_12/MatMul (3.20k/3.20k flops)\n",
      "  dense_13/MatMul (3.20k/3.20k flops)\n",
      "  dense_2/MatMul (3.20k/3.20k flops)\n",
      "  dense_3/MatMul (3.20k/3.20k flops)\n",
      "  dense_4/MatMul (3.20k/3.20k flops)\n",
      "  dense_5/MatMul (3.20k/3.20k flops)\n",
      "  dense_6/MatMul (3.20k/3.20k flops)\n",
      "  dense_7/MatMul (3.20k/3.20k flops)\n",
      "  dense_8/MatMul (3.20k/3.20k flops)\n",
      "  dense_9/MatMul (3.20k/3.20k flops)\n",
      "  dense/BiasAdd (40/40 flops)\n",
      "  dense_1/BiasAdd (40/40 flops)\n",
      "  dense_10/BiasAdd (40/40 flops)\n",
      "  dense_11/BiasAdd (40/40 flops)\n",
      "  dense_12/BiasAdd (40/40 flops)\n",
      "  dense_13/BiasAdd (40/40 flops)\n",
      "  dense_2/BiasAdd (40/40 flops)\n",
      "  dense_3/BiasAdd (40/40 flops)\n",
      "  dense_4/BiasAdd (40/40 flops)\n",
      "  dense_5/BiasAdd (40/40 flops)\n",
      "  dense_6/BiasAdd (40/40 flops)\n",
      "  dense_7/BiasAdd (40/40 flops)\n",
      "  dense_8/BiasAdd (40/40 flops)\n",
      "  dense_9/BiasAdd (40/40 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/57.33k flops)\n",
      "  dense/MatMul (4.05k/4.05k flops)\n",
      "  dense_1/MatMul (4.05k/4.05k flops)\n",
      "  dense_10/MatMul (4.05k/4.05k flops)\n",
      "  dense_11/MatMul (4.05k/4.05k flops)\n",
      "  dense_12/MatMul (4.05k/4.05k flops)\n",
      "  dense_13/MatMul (4.05k/4.05k flops)\n",
      "  dense_2/MatMul (4.05k/4.05k flops)\n",
      "  dense_3/MatMul (4.05k/4.05k flops)\n",
      "  dense_4/MatMul (4.05k/4.05k flops)\n",
      "  dense_5/MatMul (4.05k/4.05k flops)\n",
      "  dense_6/MatMul (4.05k/4.05k flops)\n",
      "  dense_7/MatMul (4.05k/4.05k flops)\n",
      "  dense_8/MatMul (4.05k/4.05k flops)\n",
      "  dense_9/MatMul (4.05k/4.05k flops)\n",
      "  dense/BiasAdd (45/45 flops)\n",
      "  dense_1/BiasAdd (45/45 flops)\n",
      "  dense_10/BiasAdd (45/45 flops)\n",
      "  dense_11/BiasAdd (45/45 flops)\n",
      "  dense_12/BiasAdd (45/45 flops)\n",
      "  dense_13/BiasAdd (45/45 flops)\n",
      "  dense_2/BiasAdd (45/45 flops)\n",
      "  dense_3/BiasAdd (45/45 flops)\n",
      "  dense_4/BiasAdd (45/45 flops)\n",
      "  dense_5/BiasAdd (45/45 flops)\n",
      "  dense_6/BiasAdd (45/45 flops)\n",
      "  dense_7/BiasAdd (45/45 flops)\n",
      "  dense_8/BiasAdd (45/45 flops)\n",
      "  dense_9/BiasAdd (45/45 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/70.70k flops)\n",
      "  dense/MatMul (5.00k/5.00k flops)\n",
      "  dense_1/MatMul (5.00k/5.00k flops)\n",
      "  dense_10/MatMul (5.00k/5.00k flops)\n",
      "  dense_11/MatMul (5.00k/5.00k flops)\n",
      "  dense_12/MatMul (5.00k/5.00k flops)\n",
      "  dense_13/MatMul (5.00k/5.00k flops)\n",
      "  dense_2/MatMul (5.00k/5.00k flops)\n",
      "  dense_3/MatMul (5.00k/5.00k flops)\n",
      "  dense_4/MatMul (5.00k/5.00k flops)\n",
      "  dense_5/MatMul (5.00k/5.00k flops)\n",
      "  dense_6/MatMul (5.00k/5.00k flops)\n",
      "  dense_7/MatMul (5.00k/5.00k flops)\n",
      "  dense_8/MatMul (5.00k/5.00k flops)\n",
      "  dense_9/MatMul (5.00k/5.00k flops)\n",
      "  dense/BiasAdd (50/50 flops)\n",
      "  dense_1/BiasAdd (50/50 flops)\n",
      "  dense_10/BiasAdd (50/50 flops)\n",
      "  dense_11/BiasAdd (50/50 flops)\n",
      "  dense_12/BiasAdd (50/50 flops)\n",
      "  dense_13/BiasAdd (50/50 flops)\n",
      "  dense_2/BiasAdd (50/50 flops)\n",
      "  dense_3/BiasAdd (50/50 flops)\n",
      "  dense_4/BiasAdd (50/50 flops)\n",
      "  dense_5/BiasAdd (50/50 flops)\n",
      "  dense_6/BiasAdd (50/50 flops)\n",
      "  dense_7/BiasAdd (50/50 flops)\n",
      "  dense_8/BiasAdd (50/50 flops)\n",
      "  dense_9/BiasAdd (50/50 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/5.67b flops)\n",
      "  conv1/conv/Conv2D (236.03m/236.03m flops)\n",
      "  conv2_block1_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv2_block2_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv2_block3_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv2_block4_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv2_block5_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv2_block6_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  pool2_conv/Conv2D (205.52m/205.52m flops)\n",
      "  pool3_conv/Conv2D (205.52m/205.52m flops)\n",
      "  pool4_conv/Conv2D (205.52m/205.52m flops)\n",
      "  conv2_block6_1_conv/Conv2D (179.83m/179.83m flops)\n",
      "  conv2_block5_1_conv/Conv2D (154.14m/154.14m flops)\n",
      "  conv2_block4_1_conv/Conv2D (128.45m/128.45m flops)\n",
      "  conv2_block3_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block12_1_conv/Conv2D (96.34m/96.34m flops)\n",
      "  conv3_block11_1_conv/Conv2D (89.92m/89.92m flops)\n",
      "  conv3_block10_1_conv/Conv2D (83.49m/83.49m flops)\n",
      "  conv2_block2_1_conv/Conv2D (77.07m/77.07m flops)\n",
      "  conv3_block9_1_conv/Conv2D (77.07m/77.07m flops)\n",
      "  conv3_block8_1_conv/Conv2D (70.65m/70.65m flops)\n",
      "  conv3_block7_1_conv/Conv2D (64.23m/64.23m flops)\n",
      "  conv3_block10_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block11_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block12_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block1_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block2_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block3_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block4_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block5_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block6_1_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block6_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block7_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block8_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block9_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv2_block1_1_conv/Conv2D (51.38m/51.38m flops)\n",
      "  conv3_block5_1_conv/Conv2D (51.38m/51.38m flops)\n",
      "  conv4_block24_1_conv/Conv2D (49.77m/49.77m flops)\n",
      "  conv4_block23_1_conv/Conv2D (48.17m/48.17m flops)\n",
      "  conv4_block22_1_conv/Conv2D (46.56m/46.56m flops)\n",
      "  conv3_block4_1_conv/Conv2D (44.96m/44.96m flops)\n",
      "  conv4_block21_1_conv/Conv2D (44.96m/44.96m flops)\n",
      "  conv4_block20_1_conv/Conv2D (43.35m/43.35m flops)\n",
      "  conv4_block19_1_conv/Conv2D (41.75m/41.75m flops)\n",
      "  conv4_block18_1_conv/Conv2D (40.14m/40.14m flops)\n",
      "  conv3_block3_1_conv/Conv2D (38.54m/38.54m flops)\n",
      "  conv4_block17_1_conv/Conv2D (38.54m/38.54m flops)\n",
      "  conv4_block16_1_conv/Conv2D (36.93m/36.93m flops)\n",
      "  conv4_block15_1_conv/Conv2D (35.32m/35.32m flops)\n",
      "  conv4_block14_1_conv/Conv2D (33.72m/33.72m flops)\n",
      "  conv3_block2_1_conv/Conv2D (32.11m/32.11m flops)\n",
      "  conv4_block13_1_conv/Conv2D (32.11m/32.11m flops)\n",
      "  conv4_block12_1_conv/Conv2D (30.51m/30.51m flops)\n",
      "  conv4_block11_1_conv/Conv2D (28.90m/28.90m flops)\n",
      "  conv4_block10_1_conv/Conv2D (27.30m/27.30m flops)\n",
      "  conv3_block1_1_conv/Conv2D (25.69m/25.69m flops)\n",
      "  conv4_block9_1_conv/Conv2D (25.69m/25.69m flops)\n",
      "  conv4_block8_1_conv/Conv2D (24.08m/24.08m flops)\n",
      "  conv4_block7_1_conv/Conv2D (22.48m/22.48m flops)\n",
      "  conv4_block6_1_conv/Conv2D (20.87m/20.87m flops)\n",
      "  conv4_block5_1_conv/Conv2D (19.27m/19.27m flops)\n",
      "  conv4_block4_1_conv/Conv2D (17.66m/17.66m flops)\n",
      "  conv4_block3_1_conv/Conv2D (16.06m/16.06m flops)\n",
      "  conv4_block10_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block11_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block12_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block13_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block14_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block15_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block16_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block17_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block18_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block19_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block1_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block20_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block21_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block22_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block23_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block24_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block2_1_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block2_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block3_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block4_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block5_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block6_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block7_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block8_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block9_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block1_1_conv/Conv2D (12.85m/12.85m flops)\n",
      "  conv5_block16_1_conv/Conv2D (12.44m/12.44m flops)\n",
      "  conv5_block15_1_conv/Conv2D (12.04m/12.04m flops)\n",
      "  conv5_block14_1_conv/Conv2D (11.64m/11.64m flops)\n",
      "  conv5_block13_1_conv/Conv2D (11.24m/11.24m flops)\n",
      "  conv5_block12_1_conv/Conv2D (10.84m/10.84m flops)\n",
      "  conv5_block11_1_conv/Conv2D (10.44m/10.44m flops)\n",
      "  conv5_block10_1_conv/Conv2D (10.04m/10.04m flops)\n",
      "  conv5_block9_1_conv/Conv2D (9.63m/9.63m flops)\n",
      "  conv5_block8_1_conv/Conv2D (9.23m/9.23m flops)\n",
      "  conv5_block7_1_conv/Conv2D (8.83m/8.83m flops)\n",
      "  conv5_block6_1_conv/Conv2D (8.43m/8.43m flops)\n",
      "  conv5_block5_1_conv/Conv2D (8.03m/8.03m flops)\n",
      "  conv5_block4_1_conv/Conv2D (7.63m/7.63m flops)\n",
      "  conv5_block3_1_conv/Conv2D (7.23m/7.23m flops)\n",
      "  conv5_block2_1_conv/Conv2D (6.82m/6.82m flops)\n",
      "  conv5_block1_1_conv/Conv2D (6.42m/6.42m flops)\n",
      "  conv5_block10_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block11_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block12_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block13_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block14_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block15_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block16_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block1_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block2_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block3_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block4_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block5_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block6_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block7_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block8_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block9_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  predictions/MatMul (2.05m/2.05m flops)\n",
      "  pool1/MaxPool (1.81m/1.81m flops)\n",
      "  pool2_pool/AvgPool (401.41k/401.41k flops)\n",
      "  pool3_pool/AvgPool (200.70k/200.70k flops)\n",
      "  pool4_pool/AvgPool (100.35k/100.35k flops)\n",
      "  avg_pool/Mean (50.18k/50.18k flops)\n",
      "  predictions/Softmax (5.00k/5.00k flops)\n",
      "  predictions/BiasAdd (1.00k/1.00k flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/6.72b flops)\n",
      "  pool4_conv/Conv2D (321.13m/321.13m flops)\n",
      "  conv1/conv/Conv2D (236.03m/236.03m flops)\n",
      "  conv2_block1_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv2_block2_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv2_block3_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv2_block4_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv2_block5_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv2_block6_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  pool2_conv/Conv2D (205.52m/205.52m flops)\n",
      "  pool3_conv/Conv2D (205.52m/205.52m flops)\n",
      "  conv2_block6_1_conv/Conv2D (179.83m/179.83m flops)\n",
      "  conv2_block5_1_conv/Conv2D (154.14m/154.14m flops)\n",
      "  conv2_block4_1_conv/Conv2D (128.45m/128.45m flops)\n",
      "  conv2_block3_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block12_1_conv/Conv2D (96.34m/96.34m flops)\n",
      "  conv3_block11_1_conv/Conv2D (89.92m/89.92m flops)\n",
      "  conv3_block10_1_conv/Conv2D (83.49m/83.49m flops)\n",
      "  conv2_block2_1_conv/Conv2D (77.07m/77.07m flops)\n",
      "  conv3_block9_1_conv/Conv2D (77.07m/77.07m flops)\n",
      "  conv3_block8_1_conv/Conv2D (70.65m/70.65m flops)\n",
      "  conv3_block7_1_conv/Conv2D (64.23m/64.23m flops)\n",
      "  conv4_block32_1_conv/Conv2D (62.62m/62.62m flops)\n",
      "  conv4_block31_1_conv/Conv2D (61.01m/61.01m flops)\n",
      "  conv4_block30_1_conv/Conv2D (59.41m/59.41m flops)\n",
      "  conv3_block10_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block11_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block12_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block1_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block2_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block3_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block4_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block5_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block6_1_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block6_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block7_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block8_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block9_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv4_block29_1_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv4_block28_1_conv/Conv2D (56.20m/56.20m flops)\n",
      "  conv4_block27_1_conv/Conv2D (54.59m/54.59m flops)\n",
      "  conv4_block26_1_conv/Conv2D (52.99m/52.99m flops)\n",
      "  conv2_block1_1_conv/Conv2D (51.38m/51.38m flops)\n",
      "  conv3_block5_1_conv/Conv2D (51.38m/51.38m flops)\n",
      "  conv4_block25_1_conv/Conv2D (51.38m/51.38m flops)\n",
      "  conv4_block24_1_conv/Conv2D (49.77m/49.77m flops)\n",
      "  conv4_block23_1_conv/Conv2D (48.17m/48.17m flops)\n",
      "  conv4_block22_1_conv/Conv2D (46.56m/46.56m flops)\n",
      "  conv3_block4_1_conv/Conv2D (44.96m/44.96m flops)\n",
      "  conv4_block21_1_conv/Conv2D (44.96m/44.96m flops)\n",
      "  conv4_block20_1_conv/Conv2D (43.35m/43.35m flops)\n",
      "  conv4_block19_1_conv/Conv2D (41.75m/41.75m flops)\n",
      "  conv4_block18_1_conv/Conv2D (40.14m/40.14m flops)\n",
      "  conv3_block3_1_conv/Conv2D (38.54m/38.54m flops)\n",
      "  conv4_block17_1_conv/Conv2D (38.54m/38.54m flops)\n",
      "  conv4_block16_1_conv/Conv2D (36.93m/36.93m flops)\n",
      "  conv4_block15_1_conv/Conv2D (35.32m/35.32m flops)\n",
      "  conv4_block14_1_conv/Conv2D (33.72m/33.72m flops)\n",
      "  conv3_block2_1_conv/Conv2D (32.11m/32.11m flops)\n",
      "  conv4_block13_1_conv/Conv2D (32.11m/32.11m flops)\n",
      "  conv4_block12_1_conv/Conv2D (30.51m/30.51m flops)\n",
      "  conv4_block11_1_conv/Conv2D (28.90m/28.90m flops)\n",
      "  conv4_block10_1_conv/Conv2D (27.30m/27.30m flops)\n",
      "  conv3_block1_1_conv/Conv2D (25.69m/25.69m flops)\n",
      "  conv4_block9_1_conv/Conv2D (25.69m/25.69m flops)\n",
      "  conv4_block8_1_conv/Conv2D (24.08m/24.08m flops)\n",
      "  conv4_block7_1_conv/Conv2D (22.48m/22.48m flops)\n",
      "  conv4_block6_1_conv/Conv2D (20.87m/20.87m flops)\n",
      "  conv5_block32_1_conv/Conv2D (20.47m/20.47m flops)\n",
      "  conv5_block31_1_conv/Conv2D (20.07m/20.07m flops)\n",
      "  conv5_block30_1_conv/Conv2D (19.67m/19.67m flops)\n",
      "  conv4_block5_1_conv/Conv2D (19.27m/19.27m flops)\n",
      "  conv5_block29_1_conv/Conv2D (19.27m/19.27m flops)\n",
      "  conv5_block28_1_conv/Conv2D (18.87m/18.87m flops)\n",
      "  conv5_block27_1_conv/Conv2D (18.46m/18.46m flops)\n",
      "  conv5_block26_1_conv/Conv2D (18.06m/18.06m flops)\n",
      "  conv4_block4_1_conv/Conv2D (17.66m/17.66m flops)\n",
      "  conv5_block25_1_conv/Conv2D (17.66m/17.66m flops)\n",
      "  conv5_block24_1_conv/Conv2D (17.26m/17.26m flops)\n",
      "  conv5_block23_1_conv/Conv2D (16.86m/16.86m flops)\n",
      "  conv5_block22_1_conv/Conv2D (16.46m/16.46m flops)\n",
      "  conv4_block3_1_conv/Conv2D (16.06m/16.06m flops)\n",
      "  conv5_block21_1_conv/Conv2D (16.06m/16.06m flops)\n",
      "  conv5_block20_1_conv/Conv2D (15.65m/15.65m flops)\n",
      "  conv5_block19_1_conv/Conv2D (15.25m/15.25m flops)\n",
      "  conv5_block18_1_conv/Conv2D (14.85m/14.85m flops)\n",
      "  conv4_block10_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block11_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block12_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block13_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block14_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block15_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block16_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block17_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block18_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block19_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block1_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block20_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block21_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block22_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block23_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block24_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block25_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block26_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block27_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block28_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block29_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block2_1_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block2_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block30_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block31_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block32_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block3_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block4_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block5_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block6_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block7_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block8_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv4_block9_2_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv5_block17_1_conv/Conv2D (14.45m/14.45m flops)\n",
      "  conv5_block16_1_conv/Conv2D (14.05m/14.05m flops)\n",
      "  conv5_block15_1_conv/Conv2D (13.65m/13.65m flops)\n",
      "  conv5_block14_1_conv/Conv2D (13.25m/13.25m flops)\n",
      "  conv4_block1_1_conv/Conv2D (12.85m/12.85m flops)\n",
      "  conv5_block13_1_conv/Conv2D (12.85m/12.85m flops)\n",
      "  conv5_block12_1_conv/Conv2D (12.44m/12.44m flops)\n",
      "  conv5_block11_1_conv/Conv2D (12.04m/12.04m flops)\n",
      "  conv5_block10_1_conv/Conv2D (11.64m/11.64m flops)\n",
      "  conv5_block9_1_conv/Conv2D (11.24m/11.24m flops)\n",
      "  conv5_block8_1_conv/Conv2D (10.84m/10.84m flops)\n",
      "  conv5_block7_1_conv/Conv2D (10.44m/10.44m flops)\n",
      "  conv5_block6_1_conv/Conv2D (10.04m/10.04m flops)\n",
      "  conv5_block5_1_conv/Conv2D (9.63m/9.63m flops)\n",
      "  conv5_block4_1_conv/Conv2D (9.23m/9.23m flops)\n",
      "  conv5_block3_1_conv/Conv2D (8.83m/8.83m flops)\n",
      "  conv5_block2_1_conv/Conv2D (8.43m/8.43m flops)\n",
      "  conv5_block1_1_conv/Conv2D (8.03m/8.03m flops)\n",
      "  conv5_block10_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block11_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block12_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block13_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block14_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block15_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block16_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block17_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block18_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block19_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block1_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block20_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block21_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block22_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block23_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block24_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block25_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block26_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block27_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block28_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block29_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block2_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block30_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block31_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block32_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block3_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block4_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block5_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block6_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block7_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block8_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  conv5_block9_2_conv/Conv2D (3.61m/3.61m flops)\n",
      "  predictions/MatMul (3.33m/3.33m flops)\n",
      "  pool1/MaxPool (1.81m/1.81m flops)\n",
      "  pool2_pool/AvgPool (401.41k/401.41k flops)\n",
      "  pool3_pool/AvgPool (200.70k/200.70k flops)\n",
      "  pool4_pool/AvgPool (125.44k/125.44k flops)\n",
      "  avg_pool/Mean (81.54k/81.54k flops)\n",
      "  predictions/Softmax (5.00k/5.00k flops)\n",
      "  predictions/BiasAdd (1.00k/1.00k flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/789.09m flops)\n",
      "  top_conv/Conv2D (40.14m/40.14m flops)\n",
      "  block2a_expand_conv/Conv2D (38.54m/38.54m flops)\n",
      "  block7a_project_conv/Conv2D (36.13m/36.13m flops)\n",
      "  block5b_expand_conv/Conv2D (29.50m/29.50m flops)\n",
      "  block5b_project_conv/Conv2D (29.50m/29.50m flops)\n",
      "  block5c_expand_conv/Conv2D (29.50m/29.50m flops)\n",
      "  block5c_project_conv/Conv2D (29.50m/29.50m flops)\n",
      "  block6a_expand_conv/Conv2D (29.50m/29.50m flops)\n",
      "  block2b_expand_conv/Conv2D (21.68m/21.68m flops)\n",
      "  block2b_project_conv/Conv2D (21.68m/21.68m flops)\n",
      "  block3a_expand_conv/Conv2D (21.68m/21.68m flops)\n",
      "  block6b_expand_conv/Conv2D (21.68m/21.68m flops)\n",
      "  block6b_project_conv/Conv2D (21.68m/21.68m flops)\n",
      "  block6c_expand_conv/Conv2D (21.68m/21.68m flops)\n",
      "  block6c_project_conv/Conv2D (21.68m/21.68m flops)\n",
      "  block6d_expand_conv/Conv2D (21.68m/21.68m flops)\n",
      "  block6d_project_conv/Conv2D (21.68m/21.68m flops)\n",
      "  block7a_expand_conv/Conv2D (21.68m/21.68m flops)\n",
      "  stem_conv/Conv2D (21.68m/21.68m flops)\n",
      "  block5a_project_conv/Conv2D (21.07m/21.07m flops)\n",
      "  block3b_expand_conv/Conv2D (15.05m/15.05m flops)\n",
      "  block3b_project_conv/Conv2D (15.05m/15.05m flops)\n",
      "  block4a_expand_conv/Conv2D (15.05m/15.05m flops)\n",
      "  block4b_expand_conv/Conv2D (15.05m/15.05m flops)\n",
      "  block4b_project_conv/Conv2D (15.05m/15.05m flops)\n",
      "  block4c_expand_conv/Conv2D (15.05m/15.05m flops)\n",
      "  block4c_project_conv/Conv2D (15.05m/15.05m flops)\n",
      "  block5a_expand_conv/Conv2D (15.05m/15.05m flops)\n",
      "  block2a_project_conv/Conv2D (14.45m/14.45m flops)\n",
      "  block1a_project_conv/Conv2D (12.85m/12.85m flops)\n",
      "  block6a_project_conv/Conv2D (12.64m/12.64m flops)\n",
      "  block3b_dwconv/depthwise (9.41m/9.41m flops)\n",
      "  block3a_project_conv/Conv2D (9.03m/9.03m flops)\n",
      "  block2b_dwconv/depthwise (8.13m/8.13m flops)\n",
      "  block4a_project_conv/Conv2D (7.53m/7.53m flops)\n",
      "  block1a_dwconv/depthwise (7.23m/7.23m flops)\n",
      "  block5b_dwconv/depthwise (6.59m/6.59m flops)\n",
      "  block5c_dwconv/depthwise (6.59m/6.59m flops)\n",
      "  block3a_dwconv/depthwise (5.64m/5.64m flops)\n",
      "  block2a_dwconv/depthwise (5.42m/5.42m flops)\n",
      "  block5a_dwconv/depthwise (4.70m/4.70m flops)\n",
      "  block6b_dwconv/depthwise (2.82m/2.82m flops)\n",
      "  block6c_dwconv/depthwise (2.82m/2.82m flops)\n",
      "  block6d_dwconv/depthwise (2.82m/2.82m flops)\n",
      "  predictions/MatMul (2.56m/2.56m flops)\n",
      "  block4b_dwconv/depthwise (1.69m/1.69m flops)\n",
      "  block4c_dwconv/depthwise (1.69m/1.69m flops)\n",
      "  block6a_dwconv/depthwise (1.65m/1.65m flops)\n",
      "  block2a_expand_activation/mul (1.20m/1.20m flops)\n",
      "  block2a_expand_activation/mul_1 (1.20m/1.20m flops)\n",
      "  block7a_dwconv/depthwise (1.02m/1.02m flops)\n",
      "  block4a_dwconv/depthwise (846.72k/846.72k flops)\n",
      "  block2b_activation/mul (451.58k/451.58k flops)\n",
      "  block2b_activation/mul_1 (451.58k/451.58k flops)\n",
      "  block2b_expand_activation/mul (451.58k/451.58k flops)\n",
      "  block2b_expand_activation/mul_1 (451.58k/451.58k flops)\n",
      "  block2b_se_excite/mul (451.58k/451.58k flops)\n",
      "  block2b_se_squeeze/Mean (451.58k/451.58k flops)\n",
      "  block3a_expand_activation/mul (451.58k/451.58k flops)\n",
      "  block3a_expand_activation/mul_1 (451.58k/451.58k flops)\n",
      "  block1a_activation/mul (401.41k/401.41k flops)\n",
      "  block1a_activation/mul_1 (401.41k/401.41k flops)\n",
      "  block1a_se_excite/mul (401.41k/401.41k flops)\n",
      "  block1a_se_squeeze/Mean (401.41k/401.41k flops)\n",
      "  stem_activation/mul (401.41k/401.41k flops)\n",
      "  stem_activation/mul_1 (401.41k/401.41k flops)\n",
      "  block2a_activation/mul (301.06k/301.06k flops)\n",
      "  block2a_activation/mul_1 (301.06k/301.06k flops)\n",
      "  block2a_se_excite/mul (301.06k/301.06k flops)\n",
      "  block2a_se_squeeze/Mean (301.06k/301.06k flops)\n",
      "  block3b_activation/mul (188.16k/188.16k flops)\n",
      "  block3b_activation/mul_1 (188.16k/188.16k flops)\n",
      "  block3b_expand_activation/mul (188.16k/188.16k flops)\n",
      "  block3b_expand_activation/mul_1 (188.16k/188.16k flops)\n",
      "  block3b_se_excite/mul (188.16k/188.16k flops)\n",
      "  block3b_se_squeeze/Mean (188.16k/188.16k flops)\n",
      "  block4a_expand_activation/mul (188.16k/188.16k flops)\n",
      "  block4a_expand_activation/mul_1 (188.16k/188.16k flops)\n",
      "  normalization/sub (150.53k/150.53k flops)\n",
      "  normalization/truediv (150.53k/150.53k flops)\n",
      "  rescaling/mul (150.53k/150.53k flops)\n",
      "  block5b_activation/mul (131.71k/131.71k flops)\n",
      "  block5b_activation/mul_1 (131.71k/131.71k flops)\n",
      "  block5b_expand_activation/mul (131.71k/131.71k flops)\n",
      "  block5b_expand_activation/mul_1 (131.71k/131.71k flops)\n",
      "  block5b_se_excite/mul (131.71k/131.71k flops)\n",
      "  block5b_se_squeeze/Mean (131.71k/131.71k flops)\n",
      "  block5c_activation/mul (131.71k/131.71k flops)\n",
      "  block5c_activation/mul_1 (131.71k/131.71k flops)\n",
      "  block5c_expand_activation/mul (131.71k/131.71k flops)\n",
      "  block5c_expand_activation/mul_1 (131.71k/131.71k flops)\n",
      "  block5c_se_excite/mul (131.71k/131.71k flops)\n",
      "  block5c_se_squeeze/Mean (131.71k/131.71k flops)\n",
      "  block6a_expand_activation/mul (131.71k/131.71k flops)\n",
      "  block6a_expand_activation/mul_1 (131.71k/131.71k flops)\n",
      "  block3a_activation/mul (112.90k/112.90k flops)\n",
      "  block3a_activation/mul_1 (112.90k/112.90k flops)\n",
      "  block3a_se_excite/mul (112.90k/112.90k flops)\n",
      "  block3a_se_squeeze/Mean (112.90k/112.90k flops)\n",
      "  block6b_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  block6b_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  block6c_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  block6c_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  block6d_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  block6d_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  block7a_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  block7a_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  block4b_activation/mul (94.08k/94.08k flops)\n",
      "  block4b_activation/mul_1 (94.08k/94.08k flops)\n",
      "  block4b_expand_activation/mul (94.08k/94.08k flops)\n",
      "  block4b_expand_activation/mul_1 (94.08k/94.08k flops)\n",
      "  block4b_se_excite/mul (94.08k/94.08k flops)\n",
      "  block4b_se_squeeze/Mean (94.08k/94.08k flops)\n",
      "  block4c_activation/mul (94.08k/94.08k flops)\n",
      "  block4c_activation/mul_1 (94.08k/94.08k flops)\n",
      "  block4c_expand_activation/mul (94.08k/94.08k flops)\n",
      "  block4c_expand_activation/mul_1 (94.08k/94.08k flops)\n",
      "  block4c_se_excite/mul (94.08k/94.08k flops)\n",
      "  block4c_se_squeeze/Mean (94.08k/94.08k flops)\n",
      "  block5a_activation/mul (94.08k/94.08k flops)\n",
      "  block5a_activation/mul_1 (94.08k/94.08k flops)\n",
      "  block5a_expand_activation/mul (94.08k/94.08k flops)\n",
      "  block5a_expand_activation/mul_1 (94.08k/94.08k flops)\n",
      "  block5a_se_excite/mul (94.08k/94.08k flops)\n",
      "  block5a_se_squeeze/Mean (94.08k/94.08k flops)\n",
      "  avg_pool/Mean (62.72k/62.72k flops)\n",
      "  top_activation/mul (62.72k/62.72k flops)\n",
      "  top_activation/mul_1 (62.72k/62.72k flops)\n",
      "  block6b_activation/mul (56.45k/56.45k flops)\n",
      "  block6b_activation/mul_1 (56.45k/56.45k flops)\n",
      "  block6b_expand_activation/mul (56.45k/56.45k flops)\n",
      "  block6b_expand_activation/mul_1 (56.45k/56.45k flops)\n",
      "  block6b_se_excite/mul (56.45k/56.45k flops)\n",
      "  block6b_se_squeeze/Mean (56.45k/56.45k flops)\n",
      "  block6c_activation/mul (56.45k/56.45k flops)\n",
      "  block6c_activation/mul_1 (56.45k/56.45k flops)\n",
      "  block6c_expand_activation/mul (56.45k/56.45k flops)\n",
      "  block6c_expand_activation/mul_1 (56.45k/56.45k flops)\n",
      "  block6c_se_excite/mul (56.45k/56.45k flops)\n",
      "  block6c_se_squeeze/Mean (56.45k/56.45k flops)\n",
      "  block6d_activation/mul (56.45k/56.45k flops)\n",
      "  block6d_activation/mul_1 (56.45k/56.45k flops)\n",
      "  block6d_expand_activation/mul (56.45k/56.45k flops)\n",
      "  block6d_expand_activation/mul_1 (56.45k/56.45k flops)\n",
      "  block6d_se_excite/mul (56.45k/56.45k flops)\n",
      "  block6d_se_squeeze/Mean (56.45k/56.45k flops)\n",
      "  block7a_activation/mul (56.45k/56.45k flops)\n",
      "  block7a_activation/mul_1 (56.45k/56.45k flops)\n",
      "  block7a_expand_activation/mul (56.45k/56.45k flops)\n",
      "  block7a_expand_activation/mul_1 (56.45k/56.45k flops)\n",
      "  block7a_se_excite/mul (56.45k/56.45k flops)\n",
      "  block7a_se_squeeze/Mean (56.45k/56.45k flops)\n",
      "  block4a_activation/mul (47.04k/47.04k flops)\n",
      "  block4a_activation/mul_1 (47.04k/47.04k flops)\n",
      "  block4a_se_excite/mul (47.04k/47.04k flops)\n",
      "  block4a_se_squeeze/Mean (47.04k/47.04k flops)\n",
      "  block5b_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  block5b_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  block5c_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  block5c_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  block6a_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  block6a_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  block6a_activation/mul (32.93k/32.93k flops)\n",
      "  block6a_activation/mul_1 (32.93k/32.93k flops)\n",
      "  block6a_se_excite/mul (32.93k/32.93k flops)\n",
      "  block6a_se_squeeze/Mean (32.93k/32.93k flops)\n",
      "  block4b_se_expand/Conv2D (19.20k/19.20k flops)\n",
      "  block4b_se_reduce/Conv2D (19.20k/19.20k flops)\n",
      "  block4c_se_expand/Conv2D (19.20k/19.20k flops)\n",
      "  block4c_se_reduce/Conv2D (19.20k/19.20k flops)\n",
      "  block5a_se_expand/Conv2D (19.20k/19.20k flops)\n",
      "  block5a_se_reduce/Conv2D (19.20k/19.20k flops)\n",
      "  predictions/Softmax (5.00k/5.00k flops)\n",
      "  block3b_se_expand/Conv2D (4.80k/4.80k flops)\n",
      "  block3b_se_reduce/Conv2D (4.80k/4.80k flops)\n",
      "  block4a_se_expand/Conv2D (4.80k/4.80k flops)\n",
      "  block4a_se_reduce/Conv2D (4.80k/4.80k flops)\n",
      "  block2b_se_expand/Conv2D (1.73k/1.73k flops)\n",
      "  block2b_se_reduce/Conv2D (1.73k/1.73k flops)\n",
      "  block3a_se_expand/Conv2D (1.73k/1.73k flops)\n",
      "  block3a_se_reduce/Conv2D (1.73k/1.73k flops)\n",
      "  block6b_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  block6c_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  block6d_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  block7a_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  predictions/BiasAdd (1.00k/1.00k flops)\n",
      "  block2a_se_expand/Conv2D (768/768 flops)\n",
      "  block2a_se_reduce/Conv2D (768/768 flops)\n",
      "  block5b_se_expand/BiasAdd (672/672 flops)\n",
      "  block5c_se_expand/BiasAdd (672/672 flops)\n",
      "  block6a_se_expand/BiasAdd (672/672 flops)\n",
      "  block1a_se_expand/Conv2D (512/512 flops)\n",
      "  block1a_se_reduce/Conv2D (512/512 flops)\n",
      "  block4b_se_expand/BiasAdd (480/480 flops)\n",
      "  block4c_se_expand/BiasAdd (480/480 flops)\n",
      "  block5a_se_expand/BiasAdd (480/480 flops)\n",
      "  block3b_se_expand/BiasAdd (240/240 flops)\n",
      "  block4a_se_expand/BiasAdd (240/240 flops)\n",
      "  block2b_se_expand/BiasAdd (144/144 flops)\n",
      "  block3a_se_expand/BiasAdd (144/144 flops)\n",
      "  block2a_se_expand/BiasAdd (96/96 flops)\n",
      "  block6b_se_reduce/BiasAdd (48/48 flops)\n",
      "  block6b_se_reduce/mul (48/48 flops)\n",
      "  block6b_se_reduce/mul_1 (48/48 flops)\n",
      "  block6c_se_reduce/BiasAdd (48/48 flops)\n",
      "  block6c_se_reduce/mul (48/48 flops)\n",
      "  block6c_se_reduce/mul_1 (48/48 flops)\n",
      "  block6d_se_reduce/BiasAdd (48/48 flops)\n",
      "  block6d_se_reduce/mul (48/48 flops)\n",
      "  block6d_se_reduce/mul_1 (48/48 flops)\n",
      "  block7a_se_reduce/BiasAdd (48/48 flops)\n",
      "  block7a_se_reduce/mul (48/48 flops)\n",
      "  block7a_se_reduce/mul_1 (48/48 flops)\n",
      "  block1a_se_expand/BiasAdd (32/32 flops)\n",
      "  block5b_se_reduce/BiasAdd (28/28 flops)\n",
      "  block5b_se_reduce/mul (28/28 flops)\n",
      "  block5b_se_reduce/mul_1 (28/28 flops)\n",
      "  block5c_se_reduce/BiasAdd (28/28 flops)\n",
      "  block5c_se_reduce/mul (28/28 flops)\n",
      "  block5c_se_reduce/mul_1 (28/28 flops)\n",
      "  block6a_se_reduce/BiasAdd (28/28 flops)\n",
      "  block6a_se_reduce/mul (28/28 flops)\n",
      "  block6a_se_reduce/mul_1 (28/28 flops)\n",
      "  block4b_se_reduce/BiasAdd (20/20 flops)\n",
      "  block4b_se_reduce/mul (20/20 flops)\n",
      "  block4b_se_reduce/mul_1 (20/20 flops)\n",
      "  block4c_se_reduce/BiasAdd (20/20 flops)\n",
      "  block4c_se_reduce/mul (20/20 flops)\n",
      "  block4c_se_reduce/mul_1 (20/20 flops)\n",
      "  block5a_se_reduce/BiasAdd (20/20 flops)\n",
      "  block5a_se_reduce/mul (20/20 flops)\n",
      "  block5a_se_reduce/mul_1 (20/20 flops)\n",
      "  block3b_se_reduce/BiasAdd (10/10 flops)\n",
      "  block3b_se_reduce/mul (10/10 flops)\n",
      "  block3b_se_reduce/mul_1 (10/10 flops)\n",
      "  block4a_se_reduce/BiasAdd (10/10 flops)\n",
      "  block4a_se_reduce/mul (10/10 flops)\n",
      "  block4a_se_reduce/mul_1 (10/10 flops)\n",
      "  block1a_se_reduce/BiasAdd (8/8 flops)\n",
      "  block1a_se_reduce/mul (8/8 flops)\n",
      "  block1a_se_reduce/mul_1 (8/8 flops)\n",
      "  block2b_se_reduce/BiasAdd (6/6 flops)\n",
      "  block2b_se_reduce/mul (6/6 flops)\n",
      "  block2b_se_reduce/mul_1 (6/6 flops)\n",
      "  block3a_se_reduce/BiasAdd (6/6 flops)\n",
      "  block3a_se_reduce/mul (6/6 flops)\n",
      "  block3a_se_reduce/mul_1 (6/6 flops)\n",
      "  block2a_se_reduce/BiasAdd (4/4 flops)\n",
      "  block2a_se_reduce/mul (4/4 flops)\n",
      "  block2a_se_reduce/mul_1 (4/4 flops)\n",
      "  normalization/Maximum (3/3 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.40b flops)\n",
      "  block7b_expand_conv/Conv2D (78.64m/78.64m flops)\n",
      "  block7b_project_conv/Conv2D (78.64m/78.64m flops)\n",
      "  top_conv/Conv2D (52.43m/52.43m flops)\n",
      "  block7a_project_conv/Conv2D (47.19m/47.19m flops)\n",
      "  block2a_expand_conv/Conv2D (44.24m/44.24m flops)\n",
      "  block5b_expand_conv/Conv2D (33.87m/33.87m flops)\n",
      "  block5b_project_conv/Conv2D (33.87m/33.87m flops)\n",
      "  block5c_expand_conv/Conv2D (33.87m/33.87m flops)\n",
      "  block5c_project_conv/Conv2D (33.87m/33.87m flops)\n",
      "  block5d_expand_conv/Conv2D (33.87m/33.87m flops)\n",
      "  block5d_project_conv/Conv2D (33.87m/33.87m flops)\n",
      "  block6a_expand_conv/Conv2D (33.87m/33.87m flops)\n",
      "  block6b_expand_conv/Conv2D (28.31m/28.31m flops)\n",
      "  block6b_project_conv/Conv2D (28.31m/28.31m flops)\n",
      "  block6c_expand_conv/Conv2D (28.31m/28.31m flops)\n",
      "  block6c_project_conv/Conv2D (28.31m/28.31m flops)\n",
      "  block6d_expand_conv/Conv2D (28.31m/28.31m flops)\n",
      "  block6d_project_conv/Conv2D (28.31m/28.31m flops)\n",
      "  block6e_expand_conv/Conv2D (28.31m/28.31m flops)\n",
      "  block6e_project_conv/Conv2D (28.31m/28.31m flops)\n",
      "  block7a_expand_conv/Conv2D (28.31m/28.31m flops)\n",
      "  block2b_expand_conv/Conv2D (24.88m/24.88m flops)\n",
      "  block2b_project_conv/Conv2D (24.88m/24.88m flops)\n",
      "  block2c_expand_conv/Conv2D (24.88m/24.88m flops)\n",
      "  block2c_project_conv/Conv2D (24.88m/24.88m flops)\n",
      "  block3a_expand_conv/Conv2D (24.88m/24.88m flops)\n",
      "  stem_conv/Conv2D (24.88m/24.88m flops)\n",
      "  block5a_project_conv/Conv2D (24.19m/24.19m flops)\n",
      "  block3b_expand_conv/Conv2D (17.28m/17.28m flops)\n",
      "  block3b_project_conv/Conv2D (17.28m/17.28m flops)\n",
      "  block3c_expand_conv/Conv2D (17.28m/17.28m flops)\n",
      "  block3c_project_conv/Conv2D (17.28m/17.28m flops)\n",
      "  block4a_expand_conv/Conv2D (17.28m/17.28m flops)\n",
      "  block4b_expand_conv/Conv2D (17.28m/17.28m flops)\n",
      "  block4b_project_conv/Conv2D (17.28m/17.28m flops)\n",
      "  block4c_expand_conv/Conv2D (17.28m/17.28m flops)\n",
      "  block4c_project_conv/Conv2D (17.28m/17.28m flops)\n",
      "  block4d_expand_conv/Conv2D (17.28m/17.28m flops)\n",
      "  block4d_project_conv/Conv2D (17.28m/17.28m flops)\n",
      "  block5a_expand_conv/Conv2D (17.28m/17.28m flops)\n",
      "  block2a_project_conv/Conv2D (16.59m/16.59m flops)\n",
      "  block6a_project_conv/Conv2D (16.52m/16.52m flops)\n",
      "  block1a_project_conv/Conv2D (14.75m/14.75m flops)\n",
      "  block3b_dwconv/depthwise (10.80m/10.80m flops)\n",
      "  block3c_dwconv/depthwise (10.80m/10.80m flops)\n",
      "  block3a_project_conv/Conv2D (10.37m/10.37m flops)\n",
      "  block2b_dwconv/depthwise (9.33m/9.33m flops)\n",
      "  block2c_dwconv/depthwise (9.33m/9.33m flops)\n",
      "  block4a_project_conv/Conv2D (8.64m/8.64m flops)\n",
      "  block1a_dwconv/depthwise (8.29m/8.29m flops)\n",
      "  block5b_dwconv/depthwise (7.56m/7.56m flops)\n",
      "  block5c_dwconv/depthwise (7.56m/7.56m flops)\n",
      "  block5d_dwconv/depthwise (7.56m/7.56m flops)\n",
      "  block1b_project_conv/Conv2D (7.37m/7.37m flops)\n",
      "  block3a_dwconv/depthwise (6.48m/6.48m flops)\n",
      "  block2a_dwconv/depthwise (6.22m/6.22m flops)\n",
      "  block5a_dwconv/depthwise (5.40m/5.40m flops)\n",
      "  block1b_dwconv/depthwise (4.15m/4.15m flops)\n",
      "  block6b_dwconv/depthwise (3.69m/3.69m flops)\n",
      "  block6c_dwconv/depthwise (3.69m/3.69m flops)\n",
      "  block6d_dwconv/depthwise (3.69m/3.69m flops)\n",
      "  block6e_dwconv/depthwise (3.69m/3.69m flops)\n",
      "  predictions/MatMul (2.56m/2.56m flops)\n",
      "  block7b_dwconv/depthwise (2.21m/2.21m flops)\n",
      "  block6a_dwconv/depthwise (2.15m/2.15m flops)\n",
      "  block4b_dwconv/depthwise (1.94m/1.94m flops)\n",
      "  block4c_dwconv/depthwise (1.94m/1.94m flops)\n",
      "  block4d_dwconv/depthwise (1.94m/1.94m flops)\n",
      "  block2a_expand_activation/mul (1.38m/1.38m flops)\n",
      "  block2a_expand_activation/mul_1 (1.38m/1.38m flops)\n",
      "  block7a_dwconv/depthwise (1.33m/1.33m flops)\n",
      "  block4a_dwconv/depthwise (972.00k/972.00k flops)\n",
      "  block2b_activation/mul (518.40k/518.40k flops)\n",
      "  block2b_activation/mul_1 (518.40k/518.40k flops)\n",
      "  block2b_expand_activation/mul (518.40k/518.40k flops)\n",
      "  block2b_expand_activation/mul_1 (518.40k/518.40k flops)\n",
      "  block2b_se_excite/mul (518.40k/518.40k flops)\n",
      "  block2b_se_squeeze/Mean (518.40k/518.40k flops)\n",
      "  block2c_activation/mul (518.40k/518.40k flops)\n",
      "  block2c_activation/mul_1 (518.40k/518.40k flops)\n",
      "  block2c_expand_activation/mul (518.40k/518.40k flops)\n",
      "  block2c_expand_activation/mul_1 (518.40k/518.40k flops)\n",
      "  block2c_se_excite/mul (518.40k/518.40k flops)\n",
      "  block2c_se_squeeze/Mean (518.40k/518.40k flops)\n",
      "  block3a_expand_activation/mul (518.40k/518.40k flops)\n",
      "  block3a_expand_activation/mul_1 (518.40k/518.40k flops)\n",
      "  block1a_activation/mul (460.80k/460.80k flops)\n",
      "  block1a_activation/mul_1 (460.80k/460.80k flops)\n",
      "  block1a_se_excite/mul (460.80k/460.80k flops)\n",
      "  block1a_se_squeeze/Mean (460.80k/460.80k flops)\n",
      "  stem_activation/mul (460.80k/460.80k flops)\n",
      "  stem_activation/mul_1 (460.80k/460.80k flops)\n",
      "  block2a_activation/mul (345.60k/345.60k flops)\n",
      "  block2a_activation/mul_1 (345.60k/345.60k flops)\n",
      "  block2a_se_excite/mul (345.60k/345.60k flops)\n",
      "  block2a_se_squeeze/Mean (345.60k/345.60k flops)\n",
      "  block7b_se_expand/Conv2D (307.20k/307.20k flops)\n",
      "  block7b_se_reduce/Conv2D (307.20k/307.20k flops)\n",
      "  block1b_activation/mul (230.40k/230.40k flops)\n",
      "  block1b_activation/mul_1 (230.40k/230.40k flops)\n",
      "  block1b_se_excite/mul (230.40k/230.40k flops)\n",
      "  block1b_se_squeeze/Mean (230.40k/230.40k flops)\n",
      "  block3b_activation/mul (216.00k/216.00k flops)\n",
      "  block3b_activation/mul_1 (216.00k/216.00k flops)\n",
      "  block3b_expand_activation/mul (216.00k/216.00k flops)\n",
      "  block3b_expand_activation/mul_1 (216.00k/216.00k flops)\n",
      "  block3b_se_excite/mul (216.00k/216.00k flops)\n",
      "  block3b_se_squeeze/Mean (216.00k/216.00k flops)\n",
      "  block3c_activation/mul (216.00k/216.00k flops)\n",
      "  block3c_activation/mul_1 (216.00k/216.00k flops)\n",
      "  block3c_expand_activation/mul (216.00k/216.00k flops)\n",
      "  block3c_expand_activation/mul_1 (216.00k/216.00k flops)\n",
      "  block3c_se_excite/mul (216.00k/216.00k flops)\n",
      "  block3c_se_squeeze/Mean (216.00k/216.00k flops)\n",
      "  block4a_expand_activation/mul (216.00k/216.00k flops)\n",
      "  block4a_expand_activation/mul_1 (216.00k/216.00k flops)\n",
      "  normalization_1/sub (172.80k/172.80k flops)\n",
      "  normalization_1/truediv (172.80k/172.80k flops)\n",
      "  rescaling_1/mul (172.80k/172.80k flops)\n",
      "  block5b_activation/mul (151.20k/151.20k flops)\n",
      "  block5b_activation/mul_1 (151.20k/151.20k flops)\n",
      "  block5b_expand_activation/mul (151.20k/151.20k flops)\n",
      "  block5b_expand_activation/mul_1 (151.20k/151.20k flops)\n",
      "  block5b_se_excite/mul (151.20k/151.20k flops)\n",
      "  block5b_se_squeeze/Mean (151.20k/151.20k flops)\n",
      "  block5c_activation/mul (151.20k/151.20k flops)\n",
      "  block5c_activation/mul_1 (151.20k/151.20k flops)\n",
      "  block5c_expand_activation/mul (151.20k/151.20k flops)\n",
      "  block5c_expand_activation/mul_1 (151.20k/151.20k flops)\n",
      "  block5c_se_excite/mul (151.20k/151.20k flops)\n",
      "  block5c_se_squeeze/Mean (151.20k/151.20k flops)\n",
      "  block5d_activation/mul (151.20k/151.20k flops)\n",
      "  block5d_activation/mul_1 (151.20k/151.20k flops)\n",
      "  block5d_expand_activation/mul (151.20k/151.20k flops)\n",
      "  block5d_expand_activation/mul_1 (151.20k/151.20k flops)\n",
      "  block5d_se_excite/mul (151.20k/151.20k flops)\n",
      "  block5d_se_squeeze/Mean (151.20k/151.20k flops)\n",
      "  block6a_expand_activation/mul (151.20k/151.20k flops)\n",
      "  block6a_expand_activation/mul_1 (151.20k/151.20k flops)\n",
      "  block3a_activation/mul (129.60k/129.60k flops)\n",
      "  block3a_activation/mul_1 (129.60k/129.60k flops)\n",
      "  block3a_se_excite/mul (129.60k/129.60k flops)\n",
      "  block3a_se_squeeze/Mean (129.60k/129.60k flops)\n",
      "  block7b_activation/mul (122.88k/122.88k flops)\n",
      "  block7b_activation/mul_1 (122.88k/122.88k flops)\n",
      "  block7b_expand_activation/mul (122.88k/122.88k flops)\n",
      "  block7b_expand_activation/mul_1 (122.88k/122.88k flops)\n",
      "  block7b_se_excite/mul (122.88k/122.88k flops)\n",
      "  block7b_se_squeeze/Mean (122.88k/122.88k flops)\n",
      "  block6b_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  block6b_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  block6c_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  block6c_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  block6d_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  block6d_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  block6e_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  block6e_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  block7a_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  block7a_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  block4b_activation/mul (108.00k/108.00k flops)\n",
      "  block4b_activation/mul_1 (108.00k/108.00k flops)\n",
      "  block4b_expand_activation/mul (108.00k/108.00k flops)\n",
      "  block4b_expand_activation/mul_1 (108.00k/108.00k flops)\n",
      "  block4b_se_excite/mul (108.00k/108.00k flops)\n",
      "  block4b_se_squeeze/Mean (108.00k/108.00k flops)\n",
      "  block4c_activation/mul (108.00k/108.00k flops)\n",
      "  block4c_activation/mul_1 (108.00k/108.00k flops)\n",
      "  block4c_expand_activation/mul (108.00k/108.00k flops)\n",
      "  block4c_expand_activation/mul_1 (108.00k/108.00k flops)\n",
      "  block4c_se_excite/mul (108.00k/108.00k flops)\n",
      "  block4c_se_squeeze/Mean (108.00k/108.00k flops)\n",
      "  block4d_activation/mul (108.00k/108.00k flops)\n",
      "  block4d_activation/mul_1 (108.00k/108.00k flops)\n",
      "  block4d_expand_activation/mul (108.00k/108.00k flops)\n",
      "  block4d_expand_activation/mul_1 (108.00k/108.00k flops)\n",
      "  block4d_se_excite/mul (108.00k/108.00k flops)\n",
      "  block4d_se_squeeze/Mean (108.00k/108.00k flops)\n",
      "  block5a_activation/mul (108.00k/108.00k flops)\n",
      "  block5a_activation/mul_1 (108.00k/108.00k flops)\n",
      "  block5a_expand_activation/mul (108.00k/108.00k flops)\n",
      "  block5a_expand_activation/mul_1 (108.00k/108.00k flops)\n",
      "  block5a_se_excite/mul (108.00k/108.00k flops)\n",
      "  block5a_se_squeeze/Mean (108.00k/108.00k flops)\n",
      "  avg_pool/Mean (81.92k/81.92k flops)\n",
      "  top_activation/mul (81.92k/81.92k flops)\n",
      "  top_activation/mul_1 (81.92k/81.92k flops)\n",
      "  block6b_activation/mul (73.73k/73.73k flops)\n",
      "  block6b_activation/mul_1 (73.73k/73.73k flops)\n",
      "  block6b_expand_activation/mul (73.73k/73.73k flops)\n",
      "  block6b_expand_activation/mul_1 (73.73k/73.73k flops)\n",
      "  block6b_se_excite/mul (73.73k/73.73k flops)\n",
      "  block6b_se_squeeze/Mean (73.73k/73.73k flops)\n",
      "  block6c_activation/mul (73.73k/73.73k flops)\n",
      "  block6c_activation/mul_1 (73.73k/73.73k flops)\n",
      "  block6c_expand_activation/mul (73.73k/73.73k flops)\n",
      "  block6c_expand_activation/mul_1 (73.73k/73.73k flops)\n",
      "  block6c_se_excite/mul (73.73k/73.73k flops)\n",
      "  block6c_se_squeeze/Mean (73.73k/73.73k flops)\n",
      "  block6d_activation/mul (73.73k/73.73k flops)\n",
      "  block6d_activation/mul_1 (73.73k/73.73k flops)\n",
      "  block6d_expand_activation/mul (73.73k/73.73k flops)\n",
      "  block6d_expand_activation/mul_1 (73.73k/73.73k flops)\n",
      "  block6d_se_excite/mul (73.73k/73.73k flops)\n",
      "  block6d_se_squeeze/Mean (73.73k/73.73k flops)\n",
      "  block6e_activation/mul (73.73k/73.73k flops)\n",
      "  block6e_activation/mul_1 (73.73k/73.73k flops)\n",
      "  block6e_expand_activation/mul (73.73k/73.73k flops)\n",
      "  block6e_expand_activation/mul_1 (73.73k/73.73k flops)\n",
      "  block6e_se_excite/mul (73.73k/73.73k flops)\n",
      "  block6e_se_squeeze/Mean (73.73k/73.73k flops)\n",
      "  block7a_activation/mul (73.73k/73.73k flops)\n",
      "  block7a_activation/mul_1 (73.73k/73.73k flops)\n",
      "  block7a_expand_activation/mul (73.73k/73.73k flops)\n",
      "  block7a_expand_activation/mul_1 (73.73k/73.73k flops)\n",
      "  block7a_se_excite/mul (73.73k/73.73k flops)\n",
      "  block7a_se_squeeze/Mean (73.73k/73.73k flops)\n",
      "  block4a_activation/mul (54.00k/54.00k flops)\n",
      "  block4a_activation/mul_1 (54.00k/54.00k flops)\n",
      "  block4a_se_excite/mul (54.00k/54.00k flops)\n",
      "  block4a_se_squeeze/Mean (54.00k/54.00k flops)\n",
      "  block6a_activation/mul (43.01k/43.01k flops)\n",
      "  block6a_activation/mul_1 (43.01k/43.01k flops)\n",
      "  block6a_se_excite/mul (43.01k/43.01k flops)\n",
      "  block6a_se_squeeze/Mean (43.01k/43.01k flops)\n",
      "  block5b_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  block5b_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  block5c_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  block5c_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  block5d_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  block5d_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  block6a_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  block6a_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  block4b_se_expand/Conv2D (19.20k/19.20k flops)\n",
      "  block4b_se_reduce/Conv2D (19.20k/19.20k flops)\n",
      "  block4c_se_expand/Conv2D (19.20k/19.20k flops)\n",
      "  block4c_se_reduce/Conv2D (19.20k/19.20k flops)\n",
      "  block4d_se_expand/Conv2D (19.20k/19.20k flops)\n",
      "  block4d_se_reduce/Conv2D (19.20k/19.20k flops)\n",
      "  block5a_se_expand/Conv2D (19.20k/19.20k flops)\n",
      "  block5a_se_reduce/Conv2D (19.20k/19.20k flops)\n",
      "  predictions/Softmax (5.00k/5.00k flops)\n",
      "  block3b_se_expand/Conv2D (4.80k/4.80k flops)\n",
      "  block3b_se_reduce/Conv2D (4.80k/4.80k flops)\n",
      "  block3c_se_expand/Conv2D (4.80k/4.80k flops)\n",
      "  block3c_se_reduce/Conv2D (4.80k/4.80k flops)\n",
      "  block4a_se_expand/Conv2D (4.80k/4.80k flops)\n",
      "  block4a_se_reduce/Conv2D (4.80k/4.80k flops)\n",
      "  block7b_se_expand/BiasAdd (1.92k/1.92k flops)\n",
      "  block2b_se_expand/Conv2D (1.73k/1.73k flops)\n",
      "  block2b_se_reduce/Conv2D (1.73k/1.73k flops)\n",
      "  block2c_se_expand/Conv2D (1.73k/1.73k flops)\n",
      "  block2c_se_reduce/Conv2D (1.73k/1.73k flops)\n",
      "  block3a_se_expand/Conv2D (1.73k/1.73k flops)\n",
      "  block3a_se_reduce/Conv2D (1.73k/1.73k flops)\n",
      "  block6b_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  block6c_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  block6d_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  block6e_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  block7a_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  predictions/BiasAdd (1.00k/1.00k flops)\n",
      "  block2a_se_expand/Conv2D (768/768 flops)\n",
      "  block2a_se_reduce/Conv2D (768/768 flops)\n",
      "  block5b_se_expand/BiasAdd (672/672 flops)\n",
      "  block5c_se_expand/BiasAdd (672/672 flops)\n",
      "  block5d_se_expand/BiasAdd (672/672 flops)\n",
      "  block6a_se_expand/BiasAdd (672/672 flops)\n",
      "  block1a_se_expand/Conv2D (512/512 flops)\n",
      "  block1a_se_reduce/Conv2D (512/512 flops)\n",
      "  block4b_se_expand/BiasAdd (480/480 flops)\n",
      "  block4c_se_expand/BiasAdd (480/480 flops)\n",
      "  block4d_se_expand/BiasAdd (480/480 flops)\n",
      "  block5a_se_expand/BiasAdd (480/480 flops)\n",
      "  block3b_se_expand/BiasAdd (240/240 flops)\n",
      "  block3c_se_expand/BiasAdd (240/240 flops)\n",
      "  block4a_se_expand/BiasAdd (240/240 flops)\n",
      "  block2b_se_expand/BiasAdd (144/144 flops)\n",
      "  block2c_se_expand/BiasAdd (144/144 flops)\n",
      "  block3a_se_expand/BiasAdd (144/144 flops)\n",
      "  block1b_se_expand/Conv2D (128/128 flops)\n",
      "  block1b_se_reduce/Conv2D (128/128 flops)\n",
      "  block2a_se_expand/BiasAdd (96/96 flops)\n",
      "  block7b_se_reduce/BiasAdd (80/80 flops)\n",
      "  block7b_se_reduce/mul (80/80 flops)\n",
      "  block7b_se_reduce/mul_1 (80/80 flops)\n",
      "  block6b_se_reduce/BiasAdd (48/48 flops)\n",
      "  block6b_se_reduce/mul (48/48 flops)\n",
      "  block6b_se_reduce/mul_1 (48/48 flops)\n",
      "  block6c_se_reduce/BiasAdd (48/48 flops)\n",
      "  block6c_se_reduce/mul (48/48 flops)\n",
      "  block6c_se_reduce/mul_1 (48/48 flops)\n",
      "  block6d_se_reduce/BiasAdd (48/48 flops)\n",
      "  block6d_se_reduce/mul (48/48 flops)\n",
      "  block6d_se_reduce/mul_1 (48/48 flops)\n",
      "  block6e_se_reduce/BiasAdd (48/48 flops)\n",
      "  block6e_se_reduce/mul (48/48 flops)\n",
      "  block6e_se_reduce/mul_1 (48/48 flops)\n",
      "  block7a_se_reduce/BiasAdd (48/48 flops)\n",
      "  block7a_se_reduce/mul (48/48 flops)\n",
      "  block7a_se_reduce/mul_1 (48/48 flops)\n",
      "  block1a_se_expand/BiasAdd (32/32 flops)\n",
      "  block5b_se_reduce/BiasAdd (28/28 flops)\n",
      "  block5b_se_reduce/mul (28/28 flops)\n",
      "  block5b_se_reduce/mul_1 (28/28 flops)\n",
      "  block5c_se_reduce/BiasAdd (28/28 flops)\n",
      "  block5c_se_reduce/mul (28/28 flops)\n",
      "  block5c_se_reduce/mul_1 (28/28 flops)\n",
      "  block5d_se_reduce/BiasAdd (28/28 flops)\n",
      "  block5d_se_reduce/mul (28/28 flops)\n",
      "  block5d_se_reduce/mul_1 (28/28 flops)\n",
      "  block6a_se_reduce/BiasAdd (28/28 flops)\n",
      "  block6a_se_reduce/mul (28/28 flops)\n",
      "  block6a_se_reduce/mul_1 (28/28 flops)\n",
      "  block4b_se_reduce/BiasAdd (20/20 flops)\n",
      "  block4b_se_reduce/mul (20/20 flops)\n",
      "  block4b_se_reduce/mul_1 (20/20 flops)\n",
      "  block4c_se_reduce/BiasAdd (20/20 flops)\n",
      "  block4c_se_reduce/mul (20/20 flops)\n",
      "  block4c_se_reduce/mul_1 (20/20 flops)\n",
      "  block4d_se_reduce/BiasAdd (20/20 flops)\n",
      "  block4d_se_reduce/mul (20/20 flops)\n",
      "  block4d_se_reduce/mul_1 (20/20 flops)\n",
      "  block5a_se_reduce/BiasAdd (20/20 flops)\n",
      "  block5a_se_reduce/mul (20/20 flops)\n",
      "  block5a_se_reduce/mul_1 (20/20 flops)\n",
      "  block1b_se_expand/BiasAdd (16/16 flops)\n",
      "  block3b_se_reduce/BiasAdd (10/10 flops)\n",
      "  block3b_se_reduce/mul (10/10 flops)\n",
      "  block3b_se_reduce/mul_1 (10/10 flops)\n",
      "  block3c_se_reduce/BiasAdd (10/10 flops)\n",
      "  block3c_se_reduce/mul (10/10 flops)\n",
      "  block3c_se_reduce/mul_1 (10/10 flops)\n",
      "  block4a_se_reduce/BiasAdd (10/10 flops)\n",
      "  block4a_se_reduce/mul (10/10 flops)\n",
      "  block4a_se_reduce/mul_1 (10/10 flops)\n",
      "  block1a_se_reduce/BiasAdd (8/8 flops)\n",
      "  block1a_se_reduce/mul (8/8 flops)\n",
      "  block1a_se_reduce/mul_1 (8/8 flops)\n",
      "  block2b_se_reduce/BiasAdd (6/6 flops)\n",
      "  block2b_se_reduce/mul (6/6 flops)\n",
      "  block2b_se_reduce/mul_1 (6/6 flops)\n",
      "  block2c_se_reduce/BiasAdd (6/6 flops)\n",
      "  block2c_se_reduce/mul (6/6 flops)\n",
      "  block2c_se_reduce/mul_1 (6/6 flops)\n",
      "  block3a_se_reduce/BiasAdd (6/6 flops)\n",
      "  block3a_se_reduce/mul (6/6 flops)\n",
      "  block3a_se_reduce/mul_1 (6/6 flops)\n",
      "  block1b_se_reduce/BiasAdd (4/4 flops)\n",
      "  block1b_se_reduce/mul (4/4 flops)\n",
      "  block1b_se_reduce/mul_1 (4/4 flops)\n",
      "  block2a_se_reduce/BiasAdd (4/4 flops)\n",
      "  block2a_se_reduce/mul (4/4 flops)\n",
      "  block2a_se_reduce/mul_1 (4/4 flops)\n",
      "  normalization_1/Maximum (3/3 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.02b flops)\n",
      "  block7b_expand_conv/Conv2D (120.43m/120.43m flops)\n",
      "  block7b_project_conv/Conv2D (120.43m/120.43m flops)\n",
      "  top_conv/Conv2D (80.29m/80.29m flops)\n",
      "  block7a_project_conv/Conv2D (71.17m/71.17m flops)\n",
      "  block2a_expand_conv/Conv2D (51.92m/51.92m flops)\n",
      "  block5b_expand_conv/Conv2D (49.94m/49.94m flops)\n",
      "  block5b_project_conv/Conv2D (49.94m/49.94m flops)\n",
      "  block5c_expand_conv/Conv2D (49.94m/49.94m flops)\n",
      "  block5c_project_conv/Conv2D (49.94m/49.94m flops)\n",
      "  block5d_expand_conv/Conv2D (49.94m/49.94m flops)\n",
      "  block5d_project_conv/Conv2D (49.94m/49.94m flops)\n",
      "  block6a_expand_conv/Conv2D (49.94m/49.94m flops)\n",
      "  block6b_expand_conv/Conv2D (42.05m/42.05m flops)\n",
      "  block6b_project_conv/Conv2D (42.05m/42.05m flops)\n",
      "  block6c_expand_conv/Conv2D (42.05m/42.05m flops)\n",
      "  block6c_project_conv/Conv2D (42.05m/42.05m flops)\n",
      "  block6d_expand_conv/Conv2D (42.05m/42.05m flops)\n",
      "  block6d_project_conv/Conv2D (42.05m/42.05m flops)\n",
      "  block6e_expand_conv/Conv2D (42.05m/42.05m flops)\n",
      "  block6e_project_conv/Conv2D (42.05m/42.05m flops)\n",
      "  block7a_expand_conv/Conv2D (42.05m/42.05m flops)\n",
      "  block5a_project_conv/Conv2D (36.62m/36.62m flops)\n",
      "  block3b_expand_conv/Conv2D (30.11m/30.11m flops)\n",
      "  block3b_project_conv/Conv2D (30.11m/30.11m flops)\n",
      "  block3c_expand_conv/Conv2D (30.11m/30.11m flops)\n",
      "  block3c_project_conv/Conv2D (30.11m/30.11m flops)\n",
      "  block4a_expand_conv/Conv2D (30.11m/30.11m flops)\n",
      "  block2b_expand_conv/Conv2D (29.20m/29.20m flops)\n",
      "  block2b_project_conv/Conv2D (29.20m/29.20m flops)\n",
      "  block2c_expand_conv/Conv2D (29.20m/29.20m flops)\n",
      "  block2c_project_conv/Conv2D (29.20m/29.20m flops)\n",
      "  block3a_expand_conv/Conv2D (29.20m/29.20m flops)\n",
      "  stem_conv/Conv2D (29.20m/29.20m flops)\n",
      "  block4b_expand_conv/Conv2D (26.86m/26.86m flops)\n",
      "  block4b_project_conv/Conv2D (26.86m/26.86m flops)\n",
      "  block4c_expand_conv/Conv2D (26.86m/26.86m flops)\n",
      "  block4c_project_conv/Conv2D (26.86m/26.86m flops)\n",
      "  block4d_expand_conv/Conv2D (26.86m/26.86m flops)\n",
      "  block4d_project_conv/Conv2D (26.86m/26.86m flops)\n",
      "  block5a_expand_conv/Conv2D (26.86m/26.86m flops)\n",
      "  block6a_project_conv/Conv2D (24.26m/24.26m flops)\n",
      "  block2a_project_conv/Conv2D (19.47m/19.47m flops)\n",
      "  block1a_project_conv/Conv2D (17.31m/17.31m flops)\n",
      "  block3b_dwconv/depthwise (15.68m/15.68m flops)\n",
      "  block3c_dwconv/depthwise (15.68m/15.68m flops)\n",
      "  block3a_project_conv/Conv2D (15.05m/15.05m flops)\n",
      "  block4a_project_conv/Conv2D (14.65m/14.65m flops)\n",
      "  block2b_dwconv/depthwise (10.95m/10.95m flops)\n",
      "  block2c_dwconv/depthwise (10.95m/10.95m flops)\n",
      "  block5b_dwconv/depthwise (10.40m/10.40m flops)\n",
      "  block5c_dwconv/depthwise (10.40m/10.40m flops)\n",
      "  block5d_dwconv/depthwise (10.40m/10.40m flops)\n",
      "  block1a_dwconv/depthwise (9.73m/9.73m flops)\n",
      "  block1b_project_conv/Conv2D (8.65m/8.65m flops)\n",
      "  block3a_dwconv/depthwise (7.84m/7.84m flops)\n",
      "  block5a_dwconv/depthwise (7.63m/7.63m flops)\n",
      "  block2a_dwconv/depthwise (7.30m/7.30m flops)\n",
      "  block6b_dwconv/depthwise (5.05m/5.05m flops)\n",
      "  block6c_dwconv/depthwise (5.05m/5.05m flops)\n",
      "  block6d_dwconv/depthwise (5.05m/5.05m flops)\n",
      "  block6e_dwconv/depthwise (5.05m/5.05m flops)\n",
      "  block1b_dwconv/depthwise (4.87m/4.87m flops)\n",
      "  block7b_dwconv/depthwise (3.08m/3.08m flops)\n",
      "  block6a_dwconv/depthwise (2.92m/2.92m flops)\n",
      "  predictions/MatMul (2.82m/2.82m flops)\n",
      "  block4b_dwconv/depthwise (2.75m/2.75m flops)\n",
      "  block4c_dwconv/depthwise (2.75m/2.75m flops)\n",
      "  block4d_dwconv/depthwise (2.75m/2.75m flops)\n",
      "  block7a_dwconv/depthwise (1.82m/1.82m flops)\n",
      "  block2a_expand_activation/mul (1.62m/1.62m flops)\n",
      "  block2a_expand_activation/mul_1 (1.62m/1.62m flops)\n",
      "  block4a_dwconv/depthwise (1.50m/1.50m flops)\n",
      "  block2b_activation/mul (608.40k/608.40k flops)\n",
      "  block2b_activation/mul_1 (608.40k/608.40k flops)\n",
      "  block2b_expand_activation/mul (608.40k/608.40k flops)\n",
      "  block2b_expand_activation/mul_1 (608.40k/608.40k flops)\n",
      "  block2b_se_excite/mul (608.40k/608.40k flops)\n",
      "  block2b_se_squeeze/Mean (608.40k/608.40k flops)\n",
      "  block2c_activation/mul (608.40k/608.40k flops)\n",
      "  block2c_activation/mul_1 (608.40k/608.40k flops)\n",
      "  block2c_expand_activation/mul (608.40k/608.40k flops)\n",
      "  block2c_expand_activation/mul_1 (608.40k/608.40k flops)\n",
      "  block2c_se_excite/mul (608.40k/608.40k flops)\n",
      "  block2c_se_squeeze/Mean (608.40k/608.40k flops)\n",
      "  block3a_expand_activation/mul (608.40k/608.40k flops)\n",
      "  block3a_expand_activation/mul_1 (608.40k/608.40k flops)\n",
      "  block1a_activation/mul (540.80k/540.80k flops)\n",
      "  block1a_activation/mul_1 (540.80k/540.80k flops)\n",
      "  block1a_se_excite/mul (540.80k/540.80k flops)\n",
      "  block1a_se_squeeze/Mean (540.80k/540.80k flops)\n",
      "  stem_activation/mul (540.80k/540.80k flops)\n",
      "  stem_activation/mul_1 (540.80k/540.80k flops)\n",
      "  block2a_activation/mul (405.60k/405.60k flops)\n",
      "  block2a_activation/mul_1 (405.60k/405.60k flops)\n",
      "  block2a_se_excite/mul (405.60k/405.60k flops)\n",
      "  block2a_se_squeeze/Mean (405.60k/405.60k flops)\n",
      "  block7b_se_expand/Conv2D (371.71k/371.71k flops)\n",
      "  block7b_se_reduce/Conv2D (371.71k/371.71k flops)\n",
      "  block3b_activation/mul (313.63k/313.63k flops)\n",
      "  block3b_activation/mul_1 (313.63k/313.63k flops)\n",
      "  block3b_expand_activation/mul (313.63k/313.63k flops)\n",
      "  block3b_expand_activation/mul_1 (313.63k/313.63k flops)\n",
      "  block3b_se_excite/mul (313.63k/313.63k flops)\n",
      "  block3b_se_squeeze/Mean (313.63k/313.63k flops)\n",
      "  block3c_activation/mul (313.63k/313.63k flops)\n",
      "  block3c_activation/mul_1 (313.63k/313.63k flops)\n",
      "  block3c_expand_activation/mul (313.63k/313.63k flops)\n",
      "  block3c_expand_activation/mul_1 (313.63k/313.63k flops)\n",
      "  block3c_se_excite/mul (313.63k/313.63k flops)\n",
      "  block3c_se_squeeze/Mean (313.63k/313.63k flops)\n",
      "  block4a_expand_activation/mul (313.63k/313.63k flops)\n",
      "  block4a_expand_activation/mul_1 (313.63k/313.63k flops)\n",
      "  block1b_activation/mul (270.40k/270.40k flops)\n",
      "  block1b_activation/mul_1 (270.40k/270.40k flops)\n",
      "  block1b_se_excite/mul (270.40k/270.40k flops)\n",
      "  block1b_se_squeeze/Mean (270.40k/270.40k flops)\n",
      "  block5b_activation/mul (208.08k/208.08k flops)\n",
      "  block5b_activation/mul_1 (208.08k/208.08k flops)\n",
      "  block5b_expand_activation/mul (208.08k/208.08k flops)\n",
      "  block5b_expand_activation/mul_1 (208.08k/208.08k flops)\n",
      "  block5b_se_excite/mul (208.08k/208.08k flops)\n",
      "  block5b_se_squeeze/Mean (208.08k/208.08k flops)\n",
      "  block5c_activation/mul (208.08k/208.08k flops)\n",
      "  block5c_activation/mul_1 (208.08k/208.08k flops)\n",
      "  block5c_expand_activation/mul (208.08k/208.08k flops)\n",
      "  block5c_expand_activation/mul_1 (208.08k/208.08k flops)\n",
      "  block5c_se_excite/mul (208.08k/208.08k flops)\n",
      "  block5c_se_squeeze/Mean (208.08k/208.08k flops)\n",
      "  block5d_activation/mul (208.08k/208.08k flops)\n",
      "  block5d_activation/mul_1 (208.08k/208.08k flops)\n",
      "  block5d_expand_activation/mul (208.08k/208.08k flops)\n",
      "  block5d_expand_activation/mul_1 (208.08k/208.08k flops)\n",
      "  block5d_se_excite/mul (208.08k/208.08k flops)\n",
      "  block5d_se_squeeze/Mean (208.08k/208.08k flops)\n",
      "  block6a_expand_activation/mul (208.08k/208.08k flops)\n",
      "  block6a_expand_activation/mul_1 (208.08k/208.08k flops)\n",
      "  normalization_2/sub (202.80k/202.80k flops)\n",
      "  normalization_2/truediv (202.80k/202.80k flops)\n",
      "  rescaling_2/mul (202.80k/202.80k flops)\n",
      "  block7b_activation/mul (171.07k/171.07k flops)\n",
      "  block7b_activation/mul_1 (171.07k/171.07k flops)\n",
      "  block7b_expand_activation/mul (171.07k/171.07k flops)\n",
      "  block7b_expand_activation/mul_1 (171.07k/171.07k flops)\n",
      "  block7b_se_excite/mul (171.07k/171.07k flops)\n",
      "  block7b_se_squeeze/Mean (171.07k/171.07k flops)\n",
      "  block3a_activation/mul (156.82k/156.82k flops)\n",
      "  block3a_activation/mul_1 (156.82k/156.82k flops)\n",
      "  block3a_se_excite/mul (156.82k/156.82k flops)\n",
      "  block3a_se_squeeze/Mean (156.82k/156.82k flops)\n",
      "  block4b_activation/mul (152.59k/152.59k flops)\n",
      "  block4b_activation/mul_1 (152.59k/152.59k flops)\n",
      "  block4b_expand_activation/mul (152.59k/152.59k flops)\n",
      "  block4b_expand_activation/mul_1 (152.59k/152.59k flops)\n",
      "  block4b_se_excite/mul (152.59k/152.59k flops)\n",
      "  block4b_se_squeeze/Mean (152.59k/152.59k flops)\n",
      "  block4c_activation/mul (152.59k/152.59k flops)\n",
      "  block4c_activation/mul_1 (152.59k/152.59k flops)\n",
      "  block4c_expand_activation/mul (152.59k/152.59k flops)\n",
      "  block4c_expand_activation/mul_1 (152.59k/152.59k flops)\n",
      "  block4c_se_excite/mul (152.59k/152.59k flops)\n",
      "  block4c_se_squeeze/Mean (152.59k/152.59k flops)\n",
      "  block4d_activation/mul (152.59k/152.59k flops)\n",
      "  block4d_activation/mul_1 (152.59k/152.59k flops)\n",
      "  block4d_expand_activation/mul (152.59k/152.59k flops)\n",
      "  block4d_expand_activation/mul_1 (152.59k/152.59k flops)\n",
      "  block4d_se_excite/mul (152.59k/152.59k flops)\n",
      "  block4d_se_squeeze/Mean (152.59k/152.59k flops)\n",
      "  block5a_activation/mul (152.59k/152.59k flops)\n",
      "  block5a_activation/mul_1 (152.59k/152.59k flops)\n",
      "  block5a_expand_activation/mul (152.59k/152.59k flops)\n",
      "  block5a_expand_activation/mul_1 (152.59k/152.59k flops)\n",
      "  block5a_se_excite/mul (152.59k/152.59k flops)\n",
      "  block5a_se_squeeze/Mean (152.59k/152.59k flops)\n",
      "  block6b_se_expand/Conv2D (129.79k/129.79k flops)\n",
      "  block6b_se_reduce/Conv2D (129.79k/129.79k flops)\n",
      "  block6c_se_expand/Conv2D (129.79k/129.79k flops)\n",
      "  block6c_se_reduce/Conv2D (129.79k/129.79k flops)\n",
      "  block6d_se_expand/Conv2D (129.79k/129.79k flops)\n",
      "  block6d_se_reduce/Conv2D (129.79k/129.79k flops)\n",
      "  block6e_se_expand/Conv2D (129.79k/129.79k flops)\n",
      "  block6e_se_reduce/Conv2D (129.79k/129.79k flops)\n",
      "  block7a_se_expand/Conv2D (129.79k/129.79k flops)\n",
      "  block7a_se_reduce/Conv2D (129.79k/129.79k flops)\n",
      "  avg_pool/Mean (114.05k/114.05k flops)\n",
      "  top_activation/mul (114.05k/114.05k flops)\n",
      "  top_activation/mul_1 (114.05k/114.05k flops)\n",
      "  block6b_activation/mul (101.09k/101.09k flops)\n",
      "  block6b_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block6b_expand_activation/mul (101.09k/101.09k flops)\n",
      "  block6b_expand_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block6b_se_excite/mul (101.09k/101.09k flops)\n",
      "  block6b_se_squeeze/Mean (101.09k/101.09k flops)\n",
      "  block6c_activation/mul (101.09k/101.09k flops)\n",
      "  block6c_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block6c_expand_activation/mul (101.09k/101.09k flops)\n",
      "  block6c_expand_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block6c_se_excite/mul (101.09k/101.09k flops)\n",
      "  block6c_se_squeeze/Mean (101.09k/101.09k flops)\n",
      "  block6d_activation/mul (101.09k/101.09k flops)\n",
      "  block6d_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block6d_expand_activation/mul (101.09k/101.09k flops)\n",
      "  block6d_expand_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block6d_se_excite/mul (101.09k/101.09k flops)\n",
      "  block6d_se_squeeze/Mean (101.09k/101.09k flops)\n",
      "  block6e_activation/mul (101.09k/101.09k flops)\n",
      "  block6e_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block6e_expand_activation/mul (101.09k/101.09k flops)\n",
      "  block6e_expand_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block6e_se_excite/mul (101.09k/101.09k flops)\n",
      "  block6e_se_squeeze/Mean (101.09k/101.09k flops)\n",
      "  block7a_activation/mul (101.09k/101.09k flops)\n",
      "  block7a_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block7a_expand_activation/mul (101.09k/101.09k flops)\n",
      "  block7a_expand_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block7a_se_excite/mul (101.09k/101.09k flops)\n",
      "  block7a_se_squeeze/Mean (101.09k/101.09k flops)\n",
      "  block4a_activation/mul (83.23k/83.23k flops)\n",
      "  block4a_activation/mul_1 (83.23k/83.23k flops)\n",
      "  block4a_se_excite/mul (83.23k/83.23k flops)\n",
      "  block4a_se_squeeze/Mean (83.23k/83.23k flops)\n",
      "  block6a_activation/mul (58.32k/58.32k flops)\n",
      "  block6a_activation/mul_1 (58.32k/58.32k flops)\n",
      "  block6a_se_excite/mul (58.32k/58.32k flops)\n",
      "  block6a_se_squeeze/Mean (58.32k/58.32k flops)\n",
      "  block5b_se_expand/Conv2D (43.20k/43.20k flops)\n",
      "  block5b_se_reduce/Conv2D (43.20k/43.20k flops)\n",
      "  block5c_se_expand/Conv2D (43.20k/43.20k flops)\n",
      "  block5c_se_reduce/Conv2D (43.20k/43.20k flops)\n",
      "  block5d_se_expand/Conv2D (43.20k/43.20k flops)\n",
      "  block5d_se_reduce/Conv2D (43.20k/43.20k flops)\n",
      "  block6a_se_expand/Conv2D (43.20k/43.20k flops)\n",
      "  block6a_se_reduce/Conv2D (43.20k/43.20k flops)\n",
      "  block4b_se_expand/Conv2D (23.23k/23.23k flops)\n",
      "  block4b_se_reduce/Conv2D (23.23k/23.23k flops)\n",
      "  block4c_se_expand/Conv2D (23.23k/23.23k flops)\n",
      "  block4c_se_reduce/Conv2D (23.23k/23.23k flops)\n",
      "  block4d_se_expand/Conv2D (23.23k/23.23k flops)\n",
      "  block4d_se_reduce/Conv2D (23.23k/23.23k flops)\n",
      "  block5a_se_expand/Conv2D (23.23k/23.23k flops)\n",
      "  block5a_se_reduce/Conv2D (23.23k/23.23k flops)\n",
      "  block3b_se_expand/Conv2D (6.91k/6.91k flops)\n",
      "  block3b_se_reduce/Conv2D (6.91k/6.91k flops)\n",
      "  block3c_se_expand/Conv2D (6.91k/6.91k flops)\n",
      "  block3c_se_reduce/Conv2D (6.91k/6.91k flops)\n",
      "  block4a_se_expand/Conv2D (6.91k/6.91k flops)\n",
      "  block4a_se_reduce/Conv2D (6.91k/6.91k flops)\n",
      "  predictions/Softmax (5.00k/5.00k flops)\n",
      "  block7b_se_expand/BiasAdd (2.11k/2.11k flops)\n",
      "  block2b_se_expand/Conv2D (1.73k/1.73k flops)\n",
      "  block2b_se_reduce/Conv2D (1.73k/1.73k flops)\n",
      "  block2c_se_expand/Conv2D (1.73k/1.73k flops)\n",
      "  block2c_se_reduce/Conv2D (1.73k/1.73k flops)\n",
      "  block3a_se_expand/Conv2D (1.73k/1.73k flops)\n",
      "  block3a_se_reduce/Conv2D (1.73k/1.73k flops)\n",
      "  block6b_se_expand/BiasAdd (1.25k/1.25k flops)\n",
      "  block6c_se_expand/BiasAdd (1.25k/1.25k flops)\n",
      "  block6d_se_expand/BiasAdd (1.25k/1.25k flops)\n",
      "  block6e_se_expand/BiasAdd (1.25k/1.25k flops)\n",
      "  block7a_se_expand/BiasAdd (1.25k/1.25k flops)\n",
      "  predictions/BiasAdd (1.00k/1.00k flops)\n",
      "  block2a_se_expand/Conv2D (768/768 flops)\n",
      "  block2a_se_reduce/Conv2D (768/768 flops)\n",
      "  block5b_se_expand/BiasAdd (720/720 flops)\n",
      "  block5c_se_expand/BiasAdd (720/720 flops)\n",
      "  block5d_se_expand/BiasAdd (720/720 flops)\n",
      "  block6a_se_expand/BiasAdd (720/720 flops)\n",
      "  block4b_se_expand/BiasAdd (528/528 flops)\n",
      "  block4c_se_expand/BiasAdd (528/528 flops)\n",
      "  block4d_se_expand/BiasAdd (528/528 flops)\n",
      "  block5a_se_expand/BiasAdd (528/528 flops)\n",
      "  block1a_se_expand/Conv2D (512/512 flops)\n",
      "  block1a_se_reduce/Conv2D (512/512 flops)\n",
      "  block3b_se_expand/BiasAdd (288/288 flops)\n",
      "  block3c_se_expand/BiasAdd (288/288 flops)\n",
      "  block4a_se_expand/BiasAdd (288/288 flops)\n",
      "  block2b_se_expand/BiasAdd (144/144 flops)\n",
      "  block2c_se_expand/BiasAdd (144/144 flops)\n",
      "  block3a_se_expand/BiasAdd (144/144 flops)\n",
      "  block1b_se_expand/Conv2D (128/128 flops)\n",
      "  block1b_se_reduce/Conv2D (128/128 flops)\n",
      "  block2a_se_expand/BiasAdd (96/96 flops)\n",
      "  block7b_se_reduce/BiasAdd (88/88 flops)\n",
      "  block7b_se_reduce/mul (88/88 flops)\n",
      "  block7b_se_reduce/mul_1 (88/88 flops)\n",
      "  block6b_se_reduce/BiasAdd (52/52 flops)\n",
      "  block6b_se_reduce/mul (52/52 flops)\n",
      "  block6b_se_reduce/mul_1 (52/52 flops)\n",
      "  block6c_se_reduce/BiasAdd (52/52 flops)\n",
      "  block6c_se_reduce/mul (52/52 flops)\n",
      "  block6c_se_reduce/mul_1 (52/52 flops)\n",
      "  block6d_se_reduce/BiasAdd (52/52 flops)\n",
      "  block6d_se_reduce/mul (52/52 flops)\n",
      "  block6d_se_reduce/mul_1 (52/52 flops)\n",
      "  block6e_se_reduce/BiasAdd (52/52 flops)\n",
      "  block6e_se_reduce/mul (52/52 flops)\n",
      "  block6e_se_reduce/mul_1 (52/52 flops)\n",
      "  block7a_se_reduce/BiasAdd (52/52 flops)\n",
      "  block7a_se_reduce/mul (52/52 flops)\n",
      "  block7a_se_reduce/mul_1 (52/52 flops)\n",
      "  block1a_se_expand/BiasAdd (32/32 flops)\n",
      "  block5b_se_reduce/BiasAdd (30/30 flops)\n",
      "  block5b_se_reduce/mul (30/30 flops)\n",
      "  block5b_se_reduce/mul_1 (30/30 flops)\n",
      "  block5c_se_reduce/BiasAdd (30/30 flops)\n",
      "  block5c_se_reduce/mul (30/30 flops)\n",
      "  block5c_se_reduce/mul_1 (30/30 flops)\n",
      "  block5d_se_reduce/BiasAdd (30/30 flops)\n",
      "  block5d_se_reduce/mul (30/30 flops)\n",
      "  block5d_se_reduce/mul_1 (30/30 flops)\n",
      "  block6a_se_reduce/BiasAdd (30/30 flops)\n",
      "  block6a_se_reduce/mul (30/30 flops)\n",
      "  block6a_se_reduce/mul_1 (30/30 flops)\n",
      "  block4b_se_reduce/BiasAdd (22/22 flops)\n",
      "  block4b_se_reduce/mul (22/22 flops)\n",
      "  block4b_se_reduce/mul_1 (22/22 flops)\n",
      "  block4c_se_reduce/BiasAdd (22/22 flops)\n",
      "  block4c_se_reduce/mul (22/22 flops)\n",
      "  block4c_se_reduce/mul_1 (22/22 flops)\n",
      "  block4d_se_reduce/BiasAdd (22/22 flops)\n",
      "  block4d_se_reduce/mul (22/22 flops)\n",
      "  block4d_se_reduce/mul_1 (22/22 flops)\n",
      "  block5a_se_reduce/BiasAdd (22/22 flops)\n",
      "  block5a_se_reduce/mul (22/22 flops)\n",
      "  block5a_se_reduce/mul_1 (22/22 flops)\n",
      "  block1b_se_expand/BiasAdd (16/16 flops)\n",
      "  block3b_se_reduce/BiasAdd (12/12 flops)\n",
      "  block3b_se_reduce/mul (12/12 flops)\n",
      "  block3b_se_reduce/mul_1 (12/12 flops)\n",
      "  block3c_se_reduce/BiasAdd (12/12 flops)\n",
      "  block3c_se_reduce/mul (12/12 flops)\n",
      "  block3c_se_reduce/mul_1 (12/12 flops)\n",
      "  block4a_se_reduce/BiasAdd (12/12 flops)\n",
      "  block4a_se_reduce/mul (12/12 flops)\n",
      "  block4a_se_reduce/mul_1 (12/12 flops)\n",
      "  block1a_se_reduce/BiasAdd (8/8 flops)\n",
      "  block1a_se_reduce/mul (8/8 flops)\n",
      "  block1a_se_reduce/mul_1 (8/8 flops)\n",
      "  block2b_se_reduce/BiasAdd (6/6 flops)\n",
      "  block2b_se_reduce/mul (6/6 flops)\n",
      "  block2b_se_reduce/mul_1 (6/6 flops)\n",
      "  block2c_se_reduce/BiasAdd (6/6 flops)\n",
      "  block2c_se_reduce/mul (6/6 flops)\n",
      "  block2c_se_reduce/mul_1 (6/6 flops)\n",
      "  block3a_se_reduce/BiasAdd (6/6 flops)\n",
      "  block3a_se_reduce/mul (6/6 flops)\n",
      "  block3a_se_reduce/mul_1 (6/6 flops)\n",
      "  block1b_se_reduce/BiasAdd (4/4 flops)\n",
      "  block1b_se_reduce/mul (4/4 flops)\n",
      "  block1b_se_reduce/mul_1 (4/4 flops)\n",
      "  block2a_se_reduce/BiasAdd (4/4 flops)\n",
      "  block2a_se_reduce/mul (4/4 flops)\n",
      "  block2a_se_reduce/mul_1 (4/4 flops)\n",
      "  normalization_2/Maximum (3/3 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/3.72b flops)\n",
      "  block7b_expand_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block7b_project_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block2a_expand_conv/Conv2D (155.52m/155.52m flops)\n",
      "  top_conv/Conv2D (117.96m/117.96m flops)\n",
      "  block7a_project_conv/Conv2D (106.91m/106.91m flops)\n",
      "  block5b_expand_conv/Conv2D (80.12m/80.12m flops)\n",
      "  block5b_project_conv/Conv2D (80.12m/80.12m flops)\n",
      "  block5c_expand_conv/Conv2D (80.12m/80.12m flops)\n",
      "  block5c_project_conv/Conv2D (80.12m/80.12m flops)\n",
      "  block5d_expand_conv/Conv2D (80.12m/80.12m flops)\n",
      "  block5d_project_conv/Conv2D (80.12m/80.12m flops)\n",
      "  block5e_expand_conv/Conv2D (80.12m/80.12m flops)\n",
      "  block5e_project_conv/Conv2D (80.12m/80.12m flops)\n",
      "  block6a_expand_conv/Conv2D (80.12m/80.12m flops)\n",
      "  block2b_expand_conv/Conv2D (69.12m/69.12m flops)\n",
      "  block2b_project_conv/Conv2D (69.12m/69.12m flops)\n",
      "  block2c_expand_conv/Conv2D (69.12m/69.12m flops)\n",
      "  block2c_project_conv/Conv2D (69.12m/69.12m flops)\n",
      "  block3a_expand_conv/Conv2D (69.12m/69.12m flops)\n",
      "  block6b_expand_conv/Conv2D (64.59m/64.59m flops)\n",
      "  block6b_project_conv/Conv2D (64.59m/64.59m flops)\n",
      "  block6c_expand_conv/Conv2D (64.59m/64.59m flops)\n",
      "  block6c_project_conv/Conv2D (64.59m/64.59m flops)\n",
      "  block6d_expand_conv/Conv2D (64.59m/64.59m flops)\n",
      "  block6d_project_conv/Conv2D (64.59m/64.59m flops)\n",
      "  block6e_expand_conv/Conv2D (64.59m/64.59m flops)\n",
      "  block6e_project_conv/Conv2D (64.59m/64.59m flops)\n",
      "  block6f_expand_conv/Conv2D (64.59m/64.59m flops)\n",
      "  block6f_project_conv/Conv2D (64.59m/64.59m flops)\n",
      "  block7a_expand_conv/Conv2D (64.59m/64.59m flops)\n",
      "  block5a_project_conv/Conv2D (56.56m/56.56m flops)\n",
      "  block2a_project_conv/Conv2D (51.84m/51.84m flops)\n",
      "  stem_conv/Conv2D (48.60m/48.60m flops)\n",
      "  block1a_project_conv/Conv2D (43.20m/43.20m flops)\n",
      "  block3b_expand_conv/Conv2D (39.92m/39.92m flops)\n",
      "  block3b_project_conv/Conv2D (39.92m/39.92m flops)\n",
      "  block3c_expand_conv/Conv2D (39.92m/39.92m flops)\n",
      "  block3c_project_conv/Conv2D (39.92m/39.92m flops)\n",
      "  block4a_expand_conv/Conv2D (39.92m/39.92m flops)\n",
      "  block4b_expand_conv/Conv2D (39.92m/39.92m flops)\n",
      "  block4b_project_conv/Conv2D (39.92m/39.92m flops)\n",
      "  block4c_expand_conv/Conv2D (39.92m/39.92m flops)\n",
      "  block4c_project_conv/Conv2D (39.92m/39.92m flops)\n",
      "  block4d_expand_conv/Conv2D (39.92m/39.92m flops)\n",
      "  block4d_project_conv/Conv2D (39.92m/39.92m flops)\n",
      "  block4e_expand_conv/Conv2D (39.92m/39.92m flops)\n",
      "  block4e_project_conv/Conv2D (39.92m/39.92m flops)\n",
      "  block5a_expand_conv/Conv2D (39.92m/39.92m flops)\n",
      "  block6a_project_conv/Conv2D (37.86m/37.86m flops)\n",
      "  block3a_project_conv/Conv2D (26.62m/26.62m flops)\n",
      "  block1b_project_conv/Conv2D (25.92m/25.92m flops)\n",
      "  block3b_dwconv/depthwise (20.79m/20.79m flops)\n",
      "  block3c_dwconv/depthwise (20.79m/20.79m flops)\n",
      "  block4a_project_conv/Conv2D (19.96m/19.96m flops)\n",
      "  block2b_dwconv/depthwise (19.44m/19.44m flops)\n",
      "  block2c_dwconv/depthwise (19.44m/19.44m flops)\n",
      "  block1a_dwconv/depthwise (16.20m/16.20m flops)\n",
      "  block5b_dwconv/depthwise (14.73m/14.73m flops)\n",
      "  block5c_dwconv/depthwise (14.73m/14.73m flops)\n",
      "  block5d_dwconv/depthwise (14.73m/14.73m flops)\n",
      "  block5e_dwconv/depthwise (14.73m/14.73m flops)\n",
      "  block2a_dwconv/depthwise (14.58m/14.58m flops)\n",
      "  block3a_dwconv/depthwise (13.86m/13.86m flops)\n",
      "  block5a_dwconv/depthwise (10.40m/10.40m flops)\n",
      "  block1b_dwconv/depthwise (9.72m/9.72m flops)\n",
      "  block6b_dwconv/depthwise (6.96m/6.96m flops)\n",
      "  block6c_dwconv/depthwise (6.96m/6.96m flops)\n",
      "  block6d_dwconv/depthwise (6.96m/6.96m flops)\n",
      "  block6e_dwconv/depthwise (6.96m/6.96m flops)\n",
      "  block6f_dwconv/depthwise (6.96m/6.96m flops)\n",
      "  block7b_dwconv/depthwise (4.15m/4.15m flops)\n",
      "  block6a_dwconv/depthwise (4.08m/4.08m flops)\n",
      "  block4b_dwconv/depthwise (3.74m/3.74m flops)\n",
      "  block4c_dwconv/depthwise (3.74m/3.74m flops)\n",
      "  block4d_dwconv/depthwise (3.74m/3.74m flops)\n",
      "  block4e_dwconv/depthwise (3.74m/3.74m flops)\n",
      "  block2a_expand_activation/mul (3.24m/3.24m flops)\n",
      "  block2a_expand_activation/mul_1 (3.24m/3.24m flops)\n",
      "  predictions/MatMul (3.07m/3.07m flops)\n",
      "  block7a_dwconv/depthwise (2.51m/2.51m flops)\n",
      "  block4a_dwconv/depthwise (1.87m/1.87m flops)\n",
      "  block2b_activation/mul (1.08m/1.08m flops)\n",
      "  block2b_activation/mul_1 (1.08m/1.08m flops)\n",
      "  block2b_expand_activation/mul (1.08m/1.08m flops)\n",
      "  block2b_expand_activation/mul_1 (1.08m/1.08m flops)\n",
      "  block2b_se_excite/mul (1.08m/1.08m flops)\n",
      "  block2b_se_squeeze/Mean (1.08m/1.08m flops)\n",
      "  block2c_activation/mul (1.08m/1.08m flops)\n",
      "  block2c_activation/mul_1 (1.08m/1.08m flops)\n",
      "  block2c_expand_activation/mul (1.08m/1.08m flops)\n",
      "  block2c_expand_activation/mul_1 (1.08m/1.08m flops)\n",
      "  block2c_se_excite/mul (1.08m/1.08m flops)\n",
      "  block2c_se_squeeze/Mean (1.08m/1.08m flops)\n",
      "  block3a_expand_activation/mul (1.08m/1.08m flops)\n",
      "  block3a_expand_activation/mul_1 (1.08m/1.08m flops)\n",
      "  block1a_activation/mul (900.00k/900.00k flops)\n",
      "  block1a_activation/mul_1 (900.00k/900.00k flops)\n",
      "  block1a_se_excite/mul (900.00k/900.00k flops)\n",
      "  block1a_se_squeeze/Mean (900.00k/900.00k flops)\n",
      "  stem_activation/mul (900.00k/900.00k flops)\n",
      "  stem_activation/mul_1 (900.00k/900.00k flops)\n",
      "  block2a_activation/mul (810.00k/810.00k flops)\n",
      "  block2a_activation/mul_1 (810.00k/810.00k flops)\n",
      "  block2a_se_excite/mul (810.00k/810.00k flops)\n",
      "  block2a_se_squeeze/Mean (810.00k/810.00k flops)\n",
      "  block1b_activation/mul (540.00k/540.00k flops)\n",
      "  block1b_activation/mul_1 (540.00k/540.00k flops)\n",
      "  block1b_se_excite/mul (540.00k/540.00k flops)\n",
      "  block1b_se_squeeze/Mean (540.00k/540.00k flops)\n",
      "  block7b_se_expand/Conv2D (442.37k/442.37k flops)\n",
      "  block7b_se_reduce/Conv2D (442.37k/442.37k flops)\n",
      "  block3b_activation/mul (415.87k/415.87k flops)\n",
      "  block3b_activation/mul_1 (415.87k/415.87k flops)\n",
      "  block3b_expand_activation/mul (415.87k/415.87k flops)\n",
      "  block3b_expand_activation/mul_1 (415.87k/415.87k flops)\n",
      "  block3b_se_excite/mul (415.87k/415.87k flops)\n",
      "  block3b_se_squeeze/Mean (415.87k/415.87k flops)\n",
      "  block3c_activation/mul (415.87k/415.87k flops)\n",
      "  block3c_activation/mul_1 (415.87k/415.87k flops)\n",
      "  block3c_expand_activation/mul (415.87k/415.87k flops)\n",
      "  block3c_expand_activation/mul_1 (415.87k/415.87k flops)\n",
      "  block3c_se_excite/mul (415.87k/415.87k flops)\n",
      "  block3c_se_squeeze/Mean (415.87k/415.87k flops)\n",
      "  block4a_expand_activation/mul (415.87k/415.87k flops)\n",
      "  block4a_expand_activation/mul_1 (415.87k/415.87k flops)\n",
      "  block5b_activation/mul (294.58k/294.58k flops)\n",
      "  block5b_activation/mul_1 (294.58k/294.58k flops)\n",
      "  block5b_expand_activation/mul (294.58k/294.58k flops)\n",
      "  block5b_expand_activation/mul_1 (294.58k/294.58k flops)\n",
      "  block5b_se_excite/mul (294.58k/294.58k flops)\n",
      "  block5b_se_squeeze/Mean (294.58k/294.58k flops)\n",
      "  block5c_activation/mul (294.58k/294.58k flops)\n",
      "  block5c_activation/mul_1 (294.58k/294.58k flops)\n",
      "  block5c_expand_activation/mul (294.58k/294.58k flops)\n",
      "  block5c_expand_activation/mul_1 (294.58k/294.58k flops)\n",
      "  block5c_se_excite/mul (294.58k/294.58k flops)\n",
      "  block5c_se_squeeze/Mean (294.58k/294.58k flops)\n",
      "  block5d_activation/mul (294.58k/294.58k flops)\n",
      "  block5d_activation/mul_1 (294.58k/294.58k flops)\n",
      "  block5d_expand_activation/mul (294.58k/294.58k flops)\n",
      "  block5d_expand_activation/mul_1 (294.58k/294.58k flops)\n",
      "  block5d_se_excite/mul (294.58k/294.58k flops)\n",
      "  block5d_se_squeeze/Mean (294.58k/294.58k flops)\n",
      "  block5e_activation/mul (294.58k/294.58k flops)\n",
      "  block5e_activation/mul_1 (294.58k/294.58k flops)\n",
      "  block5e_expand_activation/mul (294.58k/294.58k flops)\n",
      "  block5e_expand_activation/mul_1 (294.58k/294.58k flops)\n",
      "  block5e_se_excite/mul (294.58k/294.58k flops)\n",
      "  block5e_se_squeeze/Mean (294.58k/294.58k flops)\n",
      "  block6a_expand_activation/mul (294.58k/294.58k flops)\n",
      "  block6a_expand_activation/mul_1 (294.58k/294.58k flops)\n",
      "  block3a_activation/mul (277.25k/277.25k flops)\n",
      "  block3a_activation/mul_1 (277.25k/277.25k flops)\n",
      "  block3a_se_excite/mul (277.25k/277.25k flops)\n",
      "  block3a_se_squeeze/Mean (277.25k/277.25k flops)\n",
      "  normalization_3/sub (270.00k/270.00k flops)\n",
      "  normalization_3/truediv (270.00k/270.00k flops)\n",
      "  rescaling_3/mul (270.00k/270.00k flops)\n",
      "  block7b_activation/mul (230.40k/230.40k flops)\n",
      "  block7b_activation/mul_1 (230.40k/230.40k flops)\n",
      "  block7b_expand_activation/mul (230.40k/230.40k flops)\n",
      "  block7b_expand_activation/mul_1 (230.40k/230.40k flops)\n",
      "  block7b_se_excite/mul (230.40k/230.40k flops)\n",
      "  block7b_se_squeeze/Mean (230.40k/230.40k flops)\n",
      "  block4b_activation/mul (207.94k/207.94k flops)\n",
      "  block4b_activation/mul_1 (207.94k/207.94k flops)\n",
      "  block4b_expand_activation/mul (207.94k/207.94k flops)\n",
      "  block4b_expand_activation/mul_1 (207.94k/207.94k flops)\n",
      "  block4b_se_excite/mul (207.94k/207.94k flops)\n",
      "  block4b_se_squeeze/Mean (207.94k/207.94k flops)\n",
      "  block4c_activation/mul (207.94k/207.94k flops)\n",
      "  block4c_activation/mul_1 (207.94k/207.94k flops)\n",
      "  block4c_expand_activation/mul (207.94k/207.94k flops)\n",
      "  block4c_expand_activation/mul_1 (207.94k/207.94k flops)\n",
      "  block4c_se_excite/mul (207.94k/207.94k flops)\n",
      "  block4c_se_squeeze/Mean (207.94k/207.94k flops)\n",
      "  block4d_activation/mul (207.94k/207.94k flops)\n",
      "  block4d_activation/mul_1 (207.94k/207.94k flops)\n",
      "  block4d_expand_activation/mul (207.94k/207.94k flops)\n",
      "  block4d_expand_activation/mul_1 (207.94k/207.94k flops)\n",
      "  block4d_se_excite/mul (207.94k/207.94k flops)\n",
      "  block4d_se_squeeze/Mean (207.94k/207.94k flops)\n",
      "  block4e_activation/mul (207.94k/207.94k flops)\n",
      "  block4e_activation/mul_1 (207.94k/207.94k flops)\n",
      "  block4e_expand_activation/mul (207.94k/207.94k flops)\n",
      "  block4e_expand_activation/mul_1 (207.94k/207.94k flops)\n",
      "  block4e_se_excite/mul (207.94k/207.94k flops)\n",
      "  block4e_se_squeeze/Mean (207.94k/207.94k flops)\n",
      "  block5a_activation/mul (207.94k/207.94k flops)\n",
      "  block5a_activation/mul_1 (207.94k/207.94k flops)\n",
      "  block5a_expand_activation/mul (207.94k/207.94k flops)\n",
      "  block5a_expand_activation/mul_1 (207.94k/207.94k flops)\n",
      "  block5a_se_excite/mul (207.94k/207.94k flops)\n",
      "  block5a_se_squeeze/Mean (207.94k/207.94k flops)\n",
      "  block6b_se_expand/Conv2D (161.47k/161.47k flops)\n",
      "  block6b_se_reduce/Conv2D (161.47k/161.47k flops)\n",
      "  block6c_se_expand/Conv2D (161.47k/161.47k flops)\n",
      "  block6c_se_reduce/Conv2D (161.47k/161.47k flops)\n",
      "  block6d_se_expand/Conv2D (161.47k/161.47k flops)\n",
      "  block6d_se_reduce/Conv2D (161.47k/161.47k flops)\n",
      "  block6e_se_expand/Conv2D (161.47k/161.47k flops)\n",
      "  block6e_se_reduce/Conv2D (161.47k/161.47k flops)\n",
      "  block6f_se_expand/Conv2D (161.47k/161.47k flops)\n",
      "  block6f_se_reduce/Conv2D (161.47k/161.47k flops)\n",
      "  block7a_se_expand/Conv2D (161.47k/161.47k flops)\n",
      "  block7a_se_reduce/Conv2D (161.47k/161.47k flops)\n",
      "  avg_pool/Mean (153.60k/153.60k flops)\n",
      "  top_activation/mul (153.60k/153.60k flops)\n",
      "  top_activation/mul_1 (153.60k/153.60k flops)\n",
      "  block6b_activation/mul (139.20k/139.20k flops)\n",
      "  block6b_activation/mul_1 (139.20k/139.20k flops)\n",
      "  block6b_expand_activation/mul (139.20k/139.20k flops)\n",
      "  block6b_expand_activation/mul_1 (139.20k/139.20k flops)\n",
      "  block6b_se_excite/mul (139.20k/139.20k flops)\n",
      "  block6b_se_squeeze/Mean (139.20k/139.20k flops)\n",
      "  block6c_activation/mul (139.20k/139.20k flops)\n",
      "  block6c_activation/mul_1 (139.20k/139.20k flops)\n",
      "  block6c_expand_activation/mul (139.20k/139.20k flops)\n",
      "  block6c_expand_activation/mul_1 (139.20k/139.20k flops)\n",
      "  block6c_se_excite/mul (139.20k/139.20k flops)\n",
      "  block6c_se_squeeze/Mean (139.20k/139.20k flops)\n",
      "  block6d_activation/mul (139.20k/139.20k flops)\n",
      "  block6d_activation/mul_1 (139.20k/139.20k flops)\n",
      "  block6d_expand_activation/mul (139.20k/139.20k flops)\n",
      "  block6d_expand_activation/mul_1 (139.20k/139.20k flops)\n",
      "  block6d_se_excite/mul (139.20k/139.20k flops)\n",
      "  block6d_se_squeeze/Mean (139.20k/139.20k flops)\n",
      "  block6e_activation/mul (139.20k/139.20k flops)\n",
      "  block6e_activation/mul_1 (139.20k/139.20k flops)\n",
      "  block6e_expand_activation/mul (139.20k/139.20k flops)\n",
      "  block6e_expand_activation/mul_1 (139.20k/139.20k flops)\n",
      "  block6e_se_excite/mul (139.20k/139.20k flops)\n",
      "  block6e_se_squeeze/Mean (139.20k/139.20k flops)\n",
      "  block6f_activation/mul (139.20k/139.20k flops)\n",
      "  block6f_activation/mul_1 (139.20k/139.20k flops)\n",
      "  block6f_expand_activation/mul (139.20k/139.20k flops)\n",
      "  block6f_expand_activation/mul_1 (139.20k/139.20k flops)\n",
      "  block6f_se_excite/mul (139.20k/139.20k flops)\n",
      "  block6f_se_squeeze/Mean (139.20k/139.20k flops)\n",
      "  block7a_activation/mul (139.20k/139.20k flops)\n",
      "  block7a_activation/mul_1 (139.20k/139.20k flops)\n",
      "  block7a_expand_activation/mul (139.20k/139.20k flops)\n",
      "  block7a_expand_activation/mul_1 (139.20k/139.20k flops)\n",
      "  block7a_se_excite/mul (139.20k/139.20k flops)\n",
      "  block7a_se_squeeze/Mean (139.20k/139.20k flops)\n",
      "  block4a_activation/mul (103.97k/103.97k flops)\n",
      "  block4a_activation/mul_1 (103.97k/103.97k flops)\n",
      "  block4a_se_excite/mul (103.97k/103.97k flops)\n",
      "  block4a_se_squeeze/Mean (103.97k/103.97k flops)\n",
      "  block6a_activation/mul (81.60k/81.60k flops)\n",
      "  block6a_activation/mul_1 (81.60k/81.60k flops)\n",
      "  block6a_se_excite/mul (81.60k/81.60k flops)\n",
      "  block6a_se_squeeze/Mean (81.60k/81.60k flops)\n",
      "  block5b_se_expand/Conv2D (55.49k/55.49k flops)\n",
      "  block5b_se_reduce/Conv2D (55.49k/55.49k flops)\n",
      "  block5c_se_expand/Conv2D (55.49k/55.49k flops)\n",
      "  block5c_se_reduce/Conv2D (55.49k/55.49k flops)\n",
      "  block5d_se_expand/Conv2D (55.49k/55.49k flops)\n",
      "  block5d_se_reduce/Conv2D (55.49k/55.49k flops)\n",
      "  block5e_se_expand/Conv2D (55.49k/55.49k flops)\n",
      "  block5e_se_reduce/Conv2D (55.49k/55.49k flops)\n",
      "  block6a_se_expand/Conv2D (55.49k/55.49k flops)\n",
      "  block6a_se_reduce/Conv2D (55.49k/55.49k flops)\n",
      "  block4b_se_expand/Conv2D (27.65k/27.65k flops)\n",
      "  block4b_se_reduce/Conv2D (27.65k/27.65k flops)\n",
      "  block4c_se_expand/Conv2D (27.65k/27.65k flops)\n",
      "  block4c_se_reduce/Conv2D (27.65k/27.65k flops)\n",
      "  block4d_se_expand/Conv2D (27.65k/27.65k flops)\n",
      "  block4d_se_reduce/Conv2D (27.65k/27.65k flops)\n",
      "  block4e_se_expand/Conv2D (27.65k/27.65k flops)\n",
      "  block4e_se_reduce/Conv2D (27.65k/27.65k flops)\n",
      "  block5a_se_expand/Conv2D (27.65k/27.65k flops)\n",
      "  block5a_se_reduce/Conv2D (27.65k/27.65k flops)\n",
      "  block3b_se_expand/Conv2D (6.91k/6.91k flops)\n",
      "  block3b_se_reduce/Conv2D (6.91k/6.91k flops)\n",
      "  block3c_se_expand/Conv2D (6.91k/6.91k flops)\n",
      "  block3c_se_reduce/Conv2D (6.91k/6.91k flops)\n",
      "  block4a_se_expand/Conv2D (6.91k/6.91k flops)\n",
      "  block4a_se_reduce/Conv2D (6.91k/6.91k flops)\n",
      "  predictions/Softmax (5.00k/5.00k flops)\n",
      "  block2b_se_expand/Conv2D (3.07k/3.07k flops)\n",
      "  block2b_se_reduce/Conv2D (3.07k/3.07k flops)\n",
      "  block2c_se_expand/Conv2D (3.07k/3.07k flops)\n",
      "  block2c_se_reduce/Conv2D (3.07k/3.07k flops)\n",
      "  block3a_se_expand/Conv2D (3.07k/3.07k flops)\n",
      "  block3a_se_reduce/Conv2D (3.07k/3.07k flops)\n",
      "  block7b_se_expand/BiasAdd (2.30k/2.30k flops)\n",
      "  block2a_se_expand/Conv2D (1.73k/1.73k flops)\n",
      "  block2a_se_reduce/Conv2D (1.73k/1.73k flops)\n",
      "  block6b_se_expand/BiasAdd (1.39k/1.39k flops)\n",
      "  block6c_se_expand/BiasAdd (1.39k/1.39k flops)\n",
      "  block6d_se_expand/BiasAdd (1.39k/1.39k flops)\n",
      "  block6e_se_expand/BiasAdd (1.39k/1.39k flops)\n",
      "  block6f_se_expand/BiasAdd (1.39k/1.39k flops)\n",
      "  block7a_se_expand/BiasAdd (1.39k/1.39k flops)\n",
      "  predictions/BiasAdd (1.00k/1.00k flops)\n",
      "  block5b_se_expand/BiasAdd (816/816 flops)\n",
      "  block5c_se_expand/BiasAdd (816/816 flops)\n",
      "  block5d_se_expand/BiasAdd (816/816 flops)\n",
      "  block5e_se_expand/BiasAdd (816/816 flops)\n",
      "  block6a_se_expand/BiasAdd (816/816 flops)\n",
      "  block1a_se_expand/Conv2D (800/800 flops)\n",
      "  block1a_se_reduce/Conv2D (800/800 flops)\n",
      "  block4b_se_expand/BiasAdd (576/576 flops)\n",
      "  block4c_se_expand/BiasAdd (576/576 flops)\n",
      "  block4d_se_expand/BiasAdd (576/576 flops)\n",
      "  block4e_se_expand/BiasAdd (576/576 flops)\n",
      "  block5a_se_expand/BiasAdd (576/576 flops)\n",
      "  block1b_se_expand/Conv2D (288/288 flops)\n",
      "  block1b_se_reduce/Conv2D (288/288 flops)\n",
      "  block3b_se_expand/BiasAdd (288/288 flops)\n",
      "  block3c_se_expand/BiasAdd (288/288 flops)\n",
      "  block4a_se_expand/BiasAdd (288/288 flops)\n",
      "  block2b_se_expand/BiasAdd (192/192 flops)\n",
      "  block2c_se_expand/BiasAdd (192/192 flops)\n",
      "  block3a_se_expand/BiasAdd (192/192 flops)\n",
      "  block2a_se_expand/BiasAdd (144/144 flops)\n",
      "  block7b_se_reduce/BiasAdd (96/96 flops)\n",
      "  block7b_se_reduce/mul (96/96 flops)\n",
      "  block7b_se_reduce/mul_1 (96/96 flops)\n",
      "  block6b_se_reduce/BiasAdd (58/58 flops)\n",
      "  block6b_se_reduce/mul (58/58 flops)\n",
      "  block6b_se_reduce/mul_1 (58/58 flops)\n",
      "  block6c_se_reduce/BiasAdd (58/58 flops)\n",
      "  block6c_se_reduce/mul (58/58 flops)\n",
      "  block6c_se_reduce/mul_1 (58/58 flops)\n",
      "  block6d_se_reduce/BiasAdd (58/58 flops)\n",
      "  block6d_se_reduce/mul (58/58 flops)\n",
      "  block6d_se_reduce/mul_1 (58/58 flops)\n",
      "  block6e_se_reduce/BiasAdd (58/58 flops)\n",
      "  block6e_se_reduce/mul (58/58 flops)\n",
      "  block6e_se_reduce/mul_1 (58/58 flops)\n",
      "  block6f_se_reduce/BiasAdd (58/58 flops)\n",
      "  block6f_se_reduce/mul (58/58 flops)\n",
      "  block6f_se_reduce/mul_1 (58/58 flops)\n",
      "  block7a_se_reduce/BiasAdd (58/58 flops)\n",
      "  block7a_se_reduce/mul (58/58 flops)\n",
      "  block7a_se_reduce/mul_1 (58/58 flops)\n",
      "  block1a_se_expand/BiasAdd (40/40 flops)\n",
      "  block5b_se_reduce/BiasAdd (34/34 flops)\n",
      "  block5b_se_reduce/mul (34/34 flops)\n",
      "  block5b_se_reduce/mul_1 (34/34 flops)\n",
      "  block5c_se_reduce/BiasAdd (34/34 flops)\n",
      "  block5c_se_reduce/mul (34/34 flops)\n",
      "  block5c_se_reduce/mul_1 (34/34 flops)\n",
      "  block5d_se_reduce/BiasAdd (34/34 flops)\n",
      "  block5d_se_reduce/mul (34/34 flops)\n",
      "  block5d_se_reduce/mul_1 (34/34 flops)\n",
      "  block5e_se_reduce/BiasAdd (34/34 flops)\n",
      "  block5e_se_reduce/mul (34/34 flops)\n",
      "  block5e_se_reduce/mul_1 (34/34 flops)\n",
      "  block6a_se_reduce/BiasAdd (34/34 flops)\n",
      "  block6a_se_reduce/mul (34/34 flops)\n",
      "  block6a_se_reduce/mul_1 (34/34 flops)\n",
      "  block1b_se_expand/BiasAdd (24/24 flops)\n",
      "  block4b_se_reduce/BiasAdd (24/24 flops)\n",
      "  block4b_se_reduce/mul (24/24 flops)\n",
      "  block4b_se_reduce/mul_1 (24/24 flops)\n",
      "  block4c_se_reduce/BiasAdd (24/24 flops)\n",
      "  block4c_se_reduce/mul (24/24 flops)\n",
      "  block4c_se_reduce/mul_1 (24/24 flops)\n",
      "  block4d_se_reduce/BiasAdd (24/24 flops)\n",
      "  block4d_se_reduce/mul (24/24 flops)\n",
      "  block4d_se_reduce/mul_1 (24/24 flops)\n",
      "  block4e_se_reduce/BiasAdd (24/24 flops)\n",
      "  block4e_se_reduce/mul (24/24 flops)\n",
      "  block4e_se_reduce/mul_1 (24/24 flops)\n",
      "  block5a_se_reduce/BiasAdd (24/24 flops)\n",
      "  block5a_se_reduce/mul (24/24 flops)\n",
      "  block5a_se_reduce/mul_1 (24/24 flops)\n",
      "  block3b_se_reduce/BiasAdd (12/12 flops)\n",
      "  block3b_se_reduce/mul (12/12 flops)\n",
      "  block3b_se_reduce/mul_1 (12/12 flops)\n",
      "  block3c_se_reduce/BiasAdd (12/12 flops)\n",
      "  block3c_se_reduce/mul (12/12 flops)\n",
      "  block3c_se_reduce/mul_1 (12/12 flops)\n",
      "  block4a_se_reduce/BiasAdd (12/12 flops)\n",
      "  block4a_se_reduce/mul (12/12 flops)\n",
      "  block4a_se_reduce/mul_1 (12/12 flops)\n",
      "  block1a_se_reduce/BiasAdd (10/10 flops)\n",
      "  block1a_se_reduce/mul (10/10 flops)\n",
      "  block1a_se_reduce/mul_1 (10/10 flops)\n",
      "  block2b_se_reduce/BiasAdd (8/8 flops)\n",
      "  block2b_se_reduce/mul (8/8 flops)\n",
      "  block2b_se_reduce/mul_1 (8/8 flops)\n",
      "  block2c_se_reduce/BiasAdd (8/8 flops)\n",
      "  block2c_se_reduce/mul (8/8 flops)\n",
      "  block2c_se_reduce/mul_1 (8/8 flops)\n",
      "  block3a_se_reduce/BiasAdd (8/8 flops)\n",
      "  block3a_se_reduce/mul (8/8 flops)\n",
      "  block3a_se_reduce/mul_1 (8/8 flops)\n",
      "  block1b_se_reduce/BiasAdd (6/6 flops)\n",
      "  block1b_se_reduce/mul (6/6 flops)\n",
      "  block1b_se_reduce/mul_1 (6/6 flops)\n",
      "  block2a_se_reduce/BiasAdd (6/6 flops)\n",
      "  block2a_se_reduce/mul (6/6 flops)\n",
      "  block2a_se_reduce/mul_1 (6/6 flops)\n",
      "  normalization_3/Maximum (3/3 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/8.92b flops)\n",
      "  block7b_expand_conv/Conv2D (346.82m/346.82m flops)\n",
      "  block7b_project_conv/Conv2D (346.82m/346.82m flops)\n",
      "  block2a_expand_conv/Conv2D (249.52m/249.52m flops)\n",
      "  top_conv/Conv2D (231.21m/231.21m flops)\n",
      "  block7a_project_conv/Conv2D (210.57m/210.57m flops)\n",
      "  block5b_expand_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block5b_project_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block5c_expand_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block5c_project_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block5d_expand_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block5d_project_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block5e_expand_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block5e_project_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block5f_expand_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block5f_project_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block6a_expand_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block6b_expand_conv/Conv2D (127.84m/127.84m flops)\n",
      "  block6b_project_conv/Conv2D (127.84m/127.84m flops)\n",
      "  block6c_expand_conv/Conv2D (127.84m/127.84m flops)\n",
      "  block6c_project_conv/Conv2D (127.84m/127.84m flops)\n",
      "  block6d_expand_conv/Conv2D (127.84m/127.84m flops)\n",
      "  block6d_project_conv/Conv2D (127.84m/127.84m flops)\n",
      "  block6e_expand_conv/Conv2D (127.84m/127.84m flops)\n",
      "  block6e_project_conv/Conv2D (127.84m/127.84m flops)\n",
      "  block6f_expand_conv/Conv2D (127.84m/127.84m flops)\n",
      "  block6f_project_conv/Conv2D (127.84m/127.84m flops)\n",
      "  block6g_expand_conv/Conv2D (127.84m/127.84m flops)\n",
      "  block6g_project_conv/Conv2D (127.84m/127.84m flops)\n",
      "  block6h_expand_conv/Conv2D (127.84m/127.84m flops)\n",
      "  block6h_project_conv/Conv2D (127.84m/127.84m flops)\n",
      "  block7a_expand_conv/Conv2D (127.84m/127.84m flops)\n",
      "  block5a_project_conv/Conv2D (123.86m/123.86m flops)\n",
      "  block2b_expand_conv/Conv2D (110.90m/110.90m flops)\n",
      "  block2b_project_conv/Conv2D (110.90m/110.90m flops)\n",
      "  block2c_expand_conv/Conv2D (110.90m/110.90m flops)\n",
      "  block2c_project_conv/Conv2D (110.90m/110.90m flops)\n",
      "  block2d_expand_conv/Conv2D (110.90m/110.90m flops)\n",
      "  block2d_project_conv/Conv2D (110.90m/110.90m flops)\n",
      "  block3a_expand_conv/Conv2D (110.90m/110.90m flops)\n",
      "  stem_conv/Conv2D (93.57m/93.57m flops)\n",
      "  block3b_expand_conv/Conv2D (86.70m/86.70m flops)\n",
      "  block3b_project_conv/Conv2D (86.70m/86.70m flops)\n",
      "  block3c_expand_conv/Conv2D (86.70m/86.70m flops)\n",
      "  block3c_project_conv/Conv2D (86.70m/86.70m flops)\n",
      "  block3d_expand_conv/Conv2D (86.70m/86.70m flops)\n",
      "  block3d_project_conv/Conv2D (86.70m/86.70m flops)\n",
      "  block4a_expand_conv/Conv2D (86.70m/86.70m flops)\n",
      "  block4b_expand_conv/Conv2D (86.70m/86.70m flops)\n",
      "  block4b_project_conv/Conv2D (86.70m/86.70m flops)\n",
      "  block4c_expand_conv/Conv2D (86.70m/86.70m flops)\n",
      "  block4c_project_conv/Conv2D (86.70m/86.70m flops)\n",
      "  block4d_expand_conv/Conv2D (86.70m/86.70m flops)\n",
      "  block4d_project_conv/Conv2D (86.70m/86.70m flops)\n",
      "  block4e_expand_conv/Conv2D (86.70m/86.70m flops)\n",
      "  block4e_project_conv/Conv2D (86.70m/86.70m flops)\n",
      "  block4f_expand_conv/Conv2D (86.70m/86.70m flops)\n",
      "  block4f_project_conv/Conv2D (86.70m/86.70m flops)\n",
      "  block5a_expand_conv/Conv2D (86.70m/86.70m flops)\n",
      "  block1a_project_conv/Conv2D (83.17m/83.17m flops)\n",
      "  block2a_project_conv/Conv2D (83.17m/83.17m flops)\n",
      "  block6a_project_conv/Conv2D (75.20m/75.20m flops)\n",
      "  block3a_project_conv/Conv2D (49.55m/49.55m flops)\n",
      "  block4a_project_conv/Conv2D (43.35m/43.35m flops)\n",
      "  block1b_project_conv/Conv2D (41.59m/41.59m flops)\n",
      "  block3b_dwconv/depthwise (38.71m/38.71m flops)\n",
      "  block3c_dwconv/depthwise (38.71m/38.71m flops)\n",
      "  block3d_dwconv/depthwise (38.71m/38.71m flops)\n",
      "  block1a_dwconv/depthwise (31.19m/31.19m flops)\n",
      "  block2b_dwconv/depthwise (31.19m/31.19m flops)\n",
      "  block2c_dwconv/depthwise (31.19m/31.19m flops)\n",
      "  block2d_dwconv/depthwise (31.19m/31.19m flops)\n",
      "  block5b_dwconv/depthwise (27.65m/27.65m flops)\n",
      "  block5c_dwconv/depthwise (27.65m/27.65m flops)\n",
      "  block5d_dwconv/depthwise (27.65m/27.65m flops)\n",
      "  block5e_dwconv/depthwise (27.65m/27.65m flops)\n",
      "  block5f_dwconv/depthwise (27.65m/27.65m flops)\n",
      "  block2a_dwconv/depthwise (23.39m/23.39m flops)\n",
      "  block3a_dwconv/depthwise (22.12m/22.12m flops)\n",
      "  block5a_dwconv/depthwise (19.35m/19.35m flops)\n",
      "  block1b_dwconv/depthwise (15.60m/15.60m flops)\n",
      "  block6b_dwconv/depthwise (11.75m/11.75m flops)\n",
      "  block6c_dwconv/depthwise (11.75m/11.75m flops)\n",
      "  block6d_dwconv/depthwise (11.75m/11.75m flops)\n",
      "  block6e_dwconv/depthwise (11.75m/11.75m flops)\n",
      "  block6f_dwconv/depthwise (11.75m/11.75m flops)\n",
      "  block6g_dwconv/depthwise (11.75m/11.75m flops)\n",
      "  block6h_dwconv/depthwise (11.75m/11.75m flops)\n",
      "  block4b_dwconv/depthwise (6.97m/6.97m flops)\n",
      "  block4c_dwconv/depthwise (6.97m/6.97m flops)\n",
      "  block4d_dwconv/depthwise (6.97m/6.97m flops)\n",
      "  block4e_dwconv/depthwise (6.97m/6.97m flops)\n",
      "  block4f_dwconv/depthwise (6.97m/6.97m flops)\n",
      "  block7b_dwconv/depthwise (6.97m/6.97m flops)\n",
      "  block6a_dwconv/depthwise (6.91m/6.91m flops)\n",
      "  block2a_expand_activation/mul (5.20m/5.20m flops)\n",
      "  block2a_expand_activation/mul_1 (5.20m/5.20m flops)\n",
      "  block7a_dwconv/depthwise (4.23m/4.23m flops)\n",
      "  predictions/MatMul (3.58m/3.58m flops)\n",
      "  block4a_dwconv/depthwise (3.48m/3.48m flops)\n",
      "  block1a_activation/mul (1.73m/1.73m flops)\n",
      "  block1a_activation/mul_1 (1.73m/1.73m flops)\n",
      "  block1a_se_excite/mul (1.73m/1.73m flops)\n",
      "  block1a_se_squeeze/Mean (1.73m/1.73m flops)\n",
      "  block2b_activation/mul (1.73m/1.73m flops)\n",
      "  block2b_activation/mul_1 (1.73m/1.73m flops)\n",
      "  block2b_expand_activation/mul (1.73m/1.73m flops)\n",
      "  block2b_expand_activation/mul_1 (1.73m/1.73m flops)\n",
      "  block2b_se_excite/mul (1.73m/1.73m flops)\n",
      "  block2b_se_squeeze/Mean (1.73m/1.73m flops)\n",
      "  block2c_activation/mul (1.73m/1.73m flops)\n",
      "  block2c_activation/mul_1 (1.73m/1.73m flops)\n",
      "  block2c_expand_activation/mul (1.73m/1.73m flops)\n",
      "  block2c_expand_activation/mul_1 (1.73m/1.73m flops)\n",
      "  block2c_se_excite/mul (1.73m/1.73m flops)\n",
      "  block2c_se_squeeze/Mean (1.73m/1.73m flops)\n",
      "  block2d_activation/mul (1.73m/1.73m flops)\n",
      "  block2d_activation/mul_1 (1.73m/1.73m flops)\n",
      "  block2d_expand_activation/mul (1.73m/1.73m flops)\n",
      "  block2d_expand_activation/mul_1 (1.73m/1.73m flops)\n",
      "  block2d_se_excite/mul (1.73m/1.73m flops)\n",
      "  block2d_se_squeeze/Mean (1.73m/1.73m flops)\n",
      "  block3a_expand_activation/mul (1.73m/1.73m flops)\n",
      "  block3a_expand_activation/mul_1 (1.73m/1.73m flops)\n",
      "  stem_activation/mul (1.73m/1.73m flops)\n",
      "  stem_activation/mul_1 (1.73m/1.73m flops)\n",
      "  block2a_activation/mul (1.30m/1.30m flops)\n",
      "  block2a_activation/mul_1 (1.30m/1.30m flops)\n",
      "  block2a_se_excite/mul (1.30m/1.30m flops)\n",
      "  block2a_se_squeeze/Mean (1.30m/1.30m flops)\n",
      "  block1b_activation/mul (866.40k/866.40k flops)\n",
      "  block1b_activation/mul_1 (866.40k/866.40k flops)\n",
      "  block1b_se_excite/mul (866.40k/866.40k flops)\n",
      "  block1b_se_squeeze/Mean (866.40k/866.40k flops)\n",
      "  block3b_activation/mul (774.14k/774.14k flops)\n",
      "  block3b_activation/mul_1 (774.14k/774.14k flops)\n",
      "  block3b_expand_activation/mul (774.14k/774.14k flops)\n",
      "  block3b_expand_activation/mul_1 (774.14k/774.14k flops)\n",
      "  block3b_se_excite/mul (774.14k/774.14k flops)\n",
      "  block3b_se_squeeze/Mean (774.14k/774.14k flops)\n",
      "  block3c_activation/mul (774.14k/774.14k flops)\n",
      "  block3c_activation/mul_1 (774.14k/774.14k flops)\n",
      "  block3c_expand_activation/mul (774.14k/774.14k flops)\n",
      "  block3c_expand_activation/mul_1 (774.14k/774.14k flops)\n",
      "  block3c_se_excite/mul (774.14k/774.14k flops)\n",
      "  block3c_se_squeeze/Mean (774.14k/774.14k flops)\n",
      "  block3d_activation/mul (774.14k/774.14k flops)\n",
      "  block3d_activation/mul_1 (774.14k/774.14k flops)\n",
      "  block3d_expand_activation/mul (774.14k/774.14k flops)\n",
      "  block3d_expand_activation/mul_1 (774.14k/774.14k flops)\n",
      "  block3d_se_excite/mul (774.14k/774.14k flops)\n",
      "  block3d_se_squeeze/Mean (774.14k/774.14k flops)\n",
      "  block4a_expand_activation/mul (774.14k/774.14k flops)\n",
      "  block4a_expand_activation/mul_1 (774.14k/774.14k flops)\n",
      "  block7b_se_expand/Conv2D (602.11k/602.11k flops)\n",
      "  block7b_se_reduce/Conv2D (602.11k/602.11k flops)\n",
      "  block5b_activation/mul (552.96k/552.96k flops)\n",
      "  block5b_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block5b_expand_activation/mul (552.96k/552.96k flops)\n",
      "  block5b_expand_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block5b_se_excite/mul (552.96k/552.96k flops)\n",
      "  block5b_se_squeeze/Mean (552.96k/552.96k flops)\n",
      "  block5c_activation/mul (552.96k/552.96k flops)\n",
      "  block5c_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block5c_expand_activation/mul (552.96k/552.96k flops)\n",
      "  block5c_expand_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block5c_se_excite/mul (552.96k/552.96k flops)\n",
      "  block5c_se_squeeze/Mean (552.96k/552.96k flops)\n",
      "  block5d_activation/mul (552.96k/552.96k flops)\n",
      "  block5d_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block5d_expand_activation/mul (552.96k/552.96k flops)\n",
      "  block5d_expand_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block5d_se_excite/mul (552.96k/552.96k flops)\n",
      "  block5d_se_squeeze/Mean (552.96k/552.96k flops)\n",
      "  block5e_activation/mul (552.96k/552.96k flops)\n",
      "  block5e_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block5e_expand_activation/mul (552.96k/552.96k flops)\n",
      "  block5e_expand_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block5e_se_excite/mul (552.96k/552.96k flops)\n",
      "  block5e_se_squeeze/Mean (552.96k/552.96k flops)\n",
      "  block5f_activation/mul (552.96k/552.96k flops)\n",
      "  block5f_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block5f_expand_activation/mul (552.96k/552.96k flops)\n",
      "  block5f_expand_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block5f_se_excite/mul (552.96k/552.96k flops)\n",
      "  block5f_se_squeeze/Mean (552.96k/552.96k flops)\n",
      "  block6a_expand_activation/mul (552.96k/552.96k flops)\n",
      "  block6a_expand_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block3a_activation/mul (442.37k/442.37k flops)\n",
      "  block3a_activation/mul_1 (442.37k/442.37k flops)\n",
      "  block3a_se_excite/mul (442.37k/442.37k flops)\n",
      "  block3a_se_squeeze/Mean (442.37k/442.37k flops)\n",
      "  normalization_4/sub (433.20k/433.20k flops)\n",
      "  normalization_4/truediv (433.20k/433.20k flops)\n",
      "  rescaling_4/mul (433.20k/433.20k flops)\n",
      "  block4b_activation/mul (387.07k/387.07k flops)\n",
      "  block4b_activation/mul_1 (387.07k/387.07k flops)\n",
      "  block4b_expand_activation/mul (387.07k/387.07k flops)\n",
      "  block4b_expand_activation/mul_1 (387.07k/387.07k flops)\n",
      "  block4b_se_excite/mul (387.07k/387.07k flops)\n",
      "  block4b_se_squeeze/Mean (387.07k/387.07k flops)\n",
      "  block4c_activation/mul (387.07k/387.07k flops)\n",
      "  block4c_activation/mul_1 (387.07k/387.07k flops)\n",
      "  block4c_expand_activation/mul (387.07k/387.07k flops)\n",
      "  block4c_expand_activation/mul_1 (387.07k/387.07k flops)\n",
      "  block4c_se_excite/mul (387.07k/387.07k flops)\n",
      "  block4c_se_squeeze/Mean (387.07k/387.07k flops)\n",
      "  block4d_activation/mul (387.07k/387.07k flops)\n",
      "  block4d_activation/mul_1 (387.07k/387.07k flops)\n",
      "  block4d_expand_activation/mul (387.07k/387.07k flops)\n",
      "  block4d_expand_activation/mul_1 (387.07k/387.07k flops)\n",
      "  block4d_se_excite/mul (387.07k/387.07k flops)\n",
      "  block4d_se_squeeze/Mean (387.07k/387.07k flops)\n",
      "  block4e_activation/mul (387.07k/387.07k flops)\n",
      "  block4e_activation/mul_1 (387.07k/387.07k flops)\n",
      "  block4e_expand_activation/mul (387.07k/387.07k flops)\n",
      "  block4e_expand_activation/mul_1 (387.07k/387.07k flops)\n",
      "  block4e_se_excite/mul (387.07k/387.07k flops)\n",
      "  block4e_se_squeeze/Mean (387.07k/387.07k flops)\n",
      "  block4f_activation/mul (387.07k/387.07k flops)\n",
      "  block4f_activation/mul_1 (387.07k/387.07k flops)\n",
      "  block4f_expand_activation/mul (387.07k/387.07k flops)\n",
      "  block4f_expand_activation/mul_1 (387.07k/387.07k flops)\n",
      "  block4f_se_excite/mul (387.07k/387.07k flops)\n",
      "  block4f_se_squeeze/Mean (387.07k/387.07k flops)\n",
      "  block5a_activation/mul (387.07k/387.07k flops)\n",
      "  block5a_activation/mul_1 (387.07k/387.07k flops)\n",
      "  block5a_expand_activation/mul (387.07k/387.07k flops)\n",
      "  block5a_expand_activation/mul_1 (387.07k/387.07k flops)\n",
      "  block5a_se_excite/mul (387.07k/387.07k flops)\n",
      "  block5a_se_squeeze/Mean (387.07k/387.07k flops)\n",
      "  block7b_activation/mul (387.07k/387.07k flops)\n",
      "  block7b_activation/mul_1 (387.07k/387.07k flops)\n",
      "  block7b_expand_activation/mul (387.07k/387.07k flops)\n",
      "  block7b_expand_activation/mul_1 (387.07k/387.07k flops)\n",
      "  block7b_se_excite/mul (387.07k/387.07k flops)\n",
      "  block7b_se_squeeze/Mean (387.07k/387.07k flops)\n",
      "  avg_pool/Mean (258.05k/258.05k flops)\n",
      "  top_activation/mul (258.05k/258.05k flops)\n",
      "  top_activation/mul_1 (258.05k/258.05k flops)\n",
      "  block6b_activation/mul (235.01k/235.01k flops)\n",
      "  block6b_activation/mul_1 (235.01k/235.01k flops)\n",
      "  block6b_expand_activation/mul (235.01k/235.01k flops)\n",
      "  block6b_expand_activation/mul_1 (235.01k/235.01k flops)\n",
      "  block6b_se_excite/mul (235.01k/235.01k flops)\n",
      "  block6b_se_squeeze/Mean (235.01k/235.01k flops)\n",
      "  block6c_activation/mul (235.01k/235.01k flops)\n",
      "  block6c_activation/mul_1 (235.01k/235.01k flops)\n",
      "  block6c_expand_activation/mul (235.01k/235.01k flops)\n",
      "  block6c_expand_activation/mul_1 (235.01k/235.01k flops)\n",
      "  block6c_se_excite/mul (235.01k/235.01k flops)\n",
      "  block6c_se_squeeze/Mean (235.01k/235.01k flops)\n",
      "  block6d_activation/mul (235.01k/235.01k flops)\n",
      "  block6d_activation/mul_1 (235.01k/235.01k flops)\n",
      "  block6d_expand_activation/mul (235.01k/235.01k flops)\n",
      "  block6d_expand_activation/mul_1 (235.01k/235.01k flops)\n",
      "  block6d_se_excite/mul (235.01k/235.01k flops)\n",
      "  block6d_se_squeeze/Mean (235.01k/235.01k flops)\n",
      "  block6e_activation/mul (235.01k/235.01k flops)\n",
      "  block6e_activation/mul_1 (235.01k/235.01k flops)\n",
      "  block6e_expand_activation/mul (235.01k/235.01k flops)\n",
      "  block6e_expand_activation/mul_1 (235.01k/235.01k flops)\n",
      "  block6e_se_excite/mul (235.01k/235.01k flops)\n",
      "  block6e_se_squeeze/Mean (235.01k/235.01k flops)\n",
      "  block6f_activation/mul (235.01k/235.01k flops)\n",
      "  block6f_activation/mul_1 (235.01k/235.01k flops)\n",
      "  block6f_expand_activation/mul (235.01k/235.01k flops)\n",
      "  block6f_expand_activation/mul_1 (235.01k/235.01k flops)\n",
      "  block6f_se_excite/mul (235.01k/235.01k flops)\n",
      "  block6f_se_squeeze/Mean (235.01k/235.01k flops)\n",
      "  block6g_activation/mul (235.01k/235.01k flops)\n",
      "  block6g_activation/mul_1 (235.01k/235.01k flops)\n",
      "  block6g_expand_activation/mul (235.01k/235.01k flops)\n",
      "  block6g_expand_activation/mul_1 (235.01k/235.01k flops)\n",
      "  block6g_se_excite/mul (235.01k/235.01k flops)\n",
      "  block6g_se_squeeze/Mean (235.01k/235.01k flops)\n",
      "  block6h_activation/mul (235.01k/235.01k flops)\n",
      "  block6h_activation/mul_1 (235.01k/235.01k flops)\n",
      "  block6h_expand_activation/mul (235.01k/235.01k flops)\n",
      "  block6h_expand_activation/mul_1 (235.01k/235.01k flops)\n",
      "  block6h_se_excite/mul (235.01k/235.01k flops)\n",
      "  block6h_se_squeeze/Mean (235.01k/235.01k flops)\n",
      "  block7a_activation/mul (235.01k/235.01k flops)\n",
      "  block7a_activation/mul_1 (235.01k/235.01k flops)\n",
      "  block7a_expand_activation/mul (235.01k/235.01k flops)\n",
      "  block7a_expand_activation/mul_1 (235.01k/235.01k flops)\n",
      "  block7a_se_excite/mul (235.01k/235.01k flops)\n",
      "  block7a_se_squeeze/Mean (235.01k/235.01k flops)\n",
      "  block6b_se_expand/Conv2D (221.95k/221.95k flops)\n",
      "  block6b_se_reduce/Conv2D (221.95k/221.95k flops)\n",
      "  block6c_se_expand/Conv2D (221.95k/221.95k flops)\n",
      "  block6c_se_reduce/Conv2D (221.95k/221.95k flops)\n",
      "  block6d_se_expand/Conv2D (221.95k/221.95k flops)\n",
      "  block6d_se_reduce/Conv2D (221.95k/221.95k flops)\n",
      "  block6e_se_expand/Conv2D (221.95k/221.95k flops)\n",
      "  block6e_se_reduce/Conv2D (221.95k/221.95k flops)\n",
      "  block6f_se_expand/Conv2D (221.95k/221.95k flops)\n",
      "  block6f_se_reduce/Conv2D (221.95k/221.95k flops)\n",
      "  block6g_se_expand/Conv2D (221.95k/221.95k flops)\n",
      "  block6g_se_reduce/Conv2D (221.95k/221.95k flops)\n",
      "  block6h_se_expand/Conv2D (221.95k/221.95k flops)\n",
      "  block6h_se_reduce/Conv2D (221.95k/221.95k flops)\n",
      "  block7a_se_expand/Conv2D (221.95k/221.95k flops)\n",
      "  block7a_se_reduce/Conv2D (221.95k/221.95k flops)\n",
      "  block4a_activation/mul (193.54k/193.54k flops)\n",
      "  block4a_activation/mul_1 (193.54k/193.54k flops)\n",
      "  block4a_se_excite/mul (193.54k/193.54k flops)\n",
      "  block4a_se_squeeze/Mean (193.54k/193.54k flops)\n",
      "  block6a_activation/mul (138.24k/138.24k flops)\n",
      "  block6a_activation/mul_1 (138.24k/138.24k flops)\n",
      "  block6a_se_excite/mul (138.24k/138.24k flops)\n",
      "  block6a_se_squeeze/Mean (138.24k/138.24k flops)\n",
      "  block5b_se_expand/Conv2D (76.80k/76.80k flops)\n",
      "  block5b_se_reduce/Conv2D (76.80k/76.80k flops)\n",
      "  block5c_se_expand/Conv2D (76.80k/76.80k flops)\n",
      "  block5c_se_reduce/Conv2D (76.80k/76.80k flops)\n",
      "  block5d_se_expand/Conv2D (76.80k/76.80k flops)\n",
      "  block5d_se_reduce/Conv2D (76.80k/76.80k flops)\n",
      "  block5e_se_expand/Conv2D (76.80k/76.80k flops)\n",
      "  block5e_se_reduce/Conv2D (76.80k/76.80k flops)\n",
      "  block5f_se_expand/Conv2D (76.80k/76.80k flops)\n",
      "  block5f_se_reduce/Conv2D (76.80k/76.80k flops)\n",
      "  block6a_se_expand/Conv2D (76.80k/76.80k flops)\n",
      "  block6a_se_reduce/Conv2D (76.80k/76.80k flops)\n",
      "  block4b_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  block4b_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  block4c_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  block4c_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  block4d_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  block4d_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  block4e_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  block4e_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  block4f_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  block4f_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  block5a_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  block5a_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  block3b_se_expand/Conv2D (9.41k/9.41k flops)\n",
      "  block3b_se_reduce/Conv2D (9.41k/9.41k flops)\n",
      "  block3c_se_expand/Conv2D (9.41k/9.41k flops)\n",
      "  block3c_se_reduce/Conv2D (9.41k/9.41k flops)\n",
      "  block3d_se_expand/Conv2D (9.41k/9.41k flops)\n",
      "  block3d_se_reduce/Conv2D (9.41k/9.41k flops)\n",
      "  block4a_se_expand/Conv2D (9.41k/9.41k flops)\n",
      "  block4a_se_reduce/Conv2D (9.41k/9.41k flops)\n",
      "  predictions/Softmax (5.00k/5.00k flops)\n",
      "  block2b_se_expand/Conv2D (3.07k/3.07k flops)\n",
      "  block2b_se_reduce/Conv2D (3.07k/3.07k flops)\n",
      "  block2c_se_expand/Conv2D (3.07k/3.07k flops)\n",
      "  block2c_se_reduce/Conv2D (3.07k/3.07k flops)\n",
      "  block2d_se_expand/Conv2D (3.07k/3.07k flops)\n",
      "  block2d_se_reduce/Conv2D (3.07k/3.07k flops)\n",
      "  block3a_se_expand/Conv2D (3.07k/3.07k flops)\n",
      "  block3a_se_reduce/Conv2D (3.07k/3.07k flops)\n",
      "  block7b_se_expand/BiasAdd (2.69k/2.69k flops)\n",
      "  block2a_se_expand/Conv2D (1.73k/1.73k flops)\n",
      "  block2a_se_reduce/Conv2D (1.73k/1.73k flops)\n",
      "  block6b_se_expand/BiasAdd (1.63k/1.63k flops)\n",
      "  block6c_se_expand/BiasAdd (1.63k/1.63k flops)\n",
      "  block6d_se_expand/BiasAdd (1.63k/1.63k flops)\n",
      "  block6e_se_expand/BiasAdd (1.63k/1.63k flops)\n",
      "  block6f_se_expand/BiasAdd (1.63k/1.63k flops)\n",
      "  block6g_se_expand/BiasAdd (1.63k/1.63k flops)\n",
      "  block6h_se_expand/BiasAdd (1.63k/1.63k flops)\n",
      "  block7a_se_expand/BiasAdd (1.63k/1.63k flops)\n",
      "  block1a_se_expand/Conv2D (1.15k/1.15k flops)\n",
      "  block1a_se_reduce/Conv2D (1.15k/1.15k flops)\n",
      "  predictions/BiasAdd (1.00k/1.00k flops)\n",
      "  block5b_se_expand/BiasAdd (960/960 flops)\n",
      "  block5c_se_expand/BiasAdd (960/960 flops)\n",
      "  block5d_se_expand/BiasAdd (960/960 flops)\n",
      "  block5e_se_expand/BiasAdd (960/960 flops)\n",
      "  block5f_se_expand/BiasAdd (960/960 flops)\n",
      "  block6a_se_expand/BiasAdd (960/960 flops)\n",
      "  block4b_se_expand/BiasAdd (672/672 flops)\n",
      "  block4c_se_expand/BiasAdd (672/672 flops)\n",
      "  block4d_se_expand/BiasAdd (672/672 flops)\n",
      "  block4e_se_expand/BiasAdd (672/672 flops)\n",
      "  block4f_se_expand/BiasAdd (672/672 flops)\n",
      "  block5a_se_expand/BiasAdd (672/672 flops)\n",
      "  block3b_se_expand/BiasAdd (336/336 flops)\n",
      "  block3c_se_expand/BiasAdd (336/336 flops)\n",
      "  block3d_se_expand/BiasAdd (336/336 flops)\n",
      "  block4a_se_expand/BiasAdd (336/336 flops)\n",
      "  block1b_se_expand/Conv2D (288/288 flops)\n",
      "  block1b_se_reduce/Conv2D (288/288 flops)\n",
      "  block2b_se_expand/BiasAdd (192/192 flops)\n",
      "  block2c_se_expand/BiasAdd (192/192 flops)\n",
      "  block2d_se_expand/BiasAdd (192/192 flops)\n",
      "  block3a_se_expand/BiasAdd (192/192 flops)\n",
      "  block2a_se_expand/BiasAdd (144/144 flops)\n",
      "  block7b_se_reduce/BiasAdd (112/112 flops)\n",
      "  block7b_se_reduce/mul (112/112 flops)\n",
      "  block7b_se_reduce/mul_1 (112/112 flops)\n",
      "  block6b_se_reduce/BiasAdd (68/68 flops)\n",
      "  block6b_se_reduce/mul (68/68 flops)\n",
      "  block6b_se_reduce/mul_1 (68/68 flops)\n",
      "  block6c_se_reduce/BiasAdd (68/68 flops)\n",
      "  block6c_se_reduce/mul (68/68 flops)\n",
      "  block6c_se_reduce/mul_1 (68/68 flops)\n",
      "  block6d_se_reduce/BiasAdd (68/68 flops)\n",
      "  block6d_se_reduce/mul (68/68 flops)\n",
      "  block6d_se_reduce/mul_1 (68/68 flops)\n",
      "  block6e_se_reduce/BiasAdd (68/68 flops)\n",
      "  block6e_se_reduce/mul (68/68 flops)\n",
      "  block6e_se_reduce/mul_1 (68/68 flops)\n",
      "  block6f_se_reduce/BiasAdd (68/68 flops)\n",
      "  block6f_se_reduce/mul (68/68 flops)\n",
      "  block6f_se_reduce/mul_1 (68/68 flops)\n",
      "  block6g_se_reduce/BiasAdd (68/68 flops)\n",
      "  block6g_se_reduce/mul (68/68 flops)\n",
      "  block6g_se_reduce/mul_1 (68/68 flops)\n",
      "  block6h_se_reduce/BiasAdd (68/68 flops)\n",
      "  block6h_se_reduce/mul (68/68 flops)\n",
      "  block6h_se_reduce/mul_1 (68/68 flops)\n",
      "  block7a_se_reduce/BiasAdd (68/68 flops)\n",
      "  block7a_se_reduce/mul (68/68 flops)\n",
      "  block7a_se_reduce/mul_1 (68/68 flops)\n",
      "  block1a_se_expand/BiasAdd (48/48 flops)\n",
      "  block5b_se_reduce/BiasAdd (40/40 flops)\n",
      "  block5b_se_reduce/mul (40/40 flops)\n",
      "  block5b_se_reduce/mul_1 (40/40 flops)\n",
      "  block5c_se_reduce/BiasAdd (40/40 flops)\n",
      "  block5c_se_reduce/mul (40/40 flops)\n",
      "  block5c_se_reduce/mul_1 (40/40 flops)\n",
      "  block5d_se_reduce/BiasAdd (40/40 flops)\n",
      "  block5d_se_reduce/mul (40/40 flops)\n",
      "  block5d_se_reduce/mul_1 (40/40 flops)\n",
      "  block5e_se_reduce/BiasAdd (40/40 flops)\n",
      "  block5e_se_reduce/mul (40/40 flops)\n",
      "  block5e_se_reduce/mul_1 (40/40 flops)\n",
      "  block5f_se_reduce/BiasAdd (40/40 flops)\n",
      "  block5f_se_reduce/mul (40/40 flops)\n",
      "  block5f_se_reduce/mul_1 (40/40 flops)\n",
      "  block6a_se_reduce/BiasAdd (40/40 flops)\n",
      "  block6a_se_reduce/mul (40/40 flops)\n",
      "  block6a_se_reduce/mul_1 (40/40 flops)\n",
      "  block4b_se_reduce/BiasAdd (28/28 flops)\n",
      "  block4b_se_reduce/mul (28/28 flops)\n",
      "  block4b_se_reduce/mul_1 (28/28 flops)\n",
      "  block4c_se_reduce/BiasAdd (28/28 flops)\n",
      "  block4c_se_reduce/mul (28/28 flops)\n",
      "  block4c_se_reduce/mul_1 (28/28 flops)\n",
      "  block4d_se_reduce/BiasAdd (28/28 flops)\n",
      "  block4d_se_reduce/mul (28/28 flops)\n",
      "  block4d_se_reduce/mul_1 (28/28 flops)\n",
      "  block4e_se_reduce/BiasAdd (28/28 flops)\n",
      "  block4e_se_reduce/mul (28/28 flops)\n",
      "  block4e_se_reduce/mul_1 (28/28 flops)\n",
      "  block4f_se_reduce/BiasAdd (28/28 flops)\n",
      "  block4f_se_reduce/mul (28/28 flops)\n",
      "  block4f_se_reduce/mul_1 (28/28 flops)\n",
      "  block5a_se_reduce/BiasAdd (28/28 flops)\n",
      "  block5a_se_reduce/mul (28/28 flops)\n",
      "  block5a_se_reduce/mul_1 (28/28 flops)\n",
      "  block1b_se_expand/BiasAdd (24/24 flops)\n",
      "  block3b_se_reduce/BiasAdd (14/14 flops)\n",
      "  block3b_se_reduce/mul (14/14 flops)\n",
      "  block3b_se_reduce/mul_1 (14/14 flops)\n",
      "  block3c_se_reduce/BiasAdd (14/14 flops)\n",
      "  block3c_se_reduce/mul (14/14 flops)\n",
      "  block3c_se_reduce/mul_1 (14/14 flops)\n",
      "  block3d_se_reduce/BiasAdd (14/14 flops)\n",
      "  block3d_se_reduce/mul (14/14 flops)\n",
      "  block3d_se_reduce/mul_1 (14/14 flops)\n",
      "  block4a_se_reduce/BiasAdd (14/14 flops)\n",
      "  block4a_se_reduce/mul (14/14 flops)\n",
      "  block4a_se_reduce/mul_1 (14/14 flops)\n",
      "  block1a_se_reduce/BiasAdd (12/12 flops)\n",
      "  block1a_se_reduce/mul (12/12 flops)\n",
      "  block1a_se_reduce/mul_1 (12/12 flops)\n",
      "  block2b_se_reduce/BiasAdd (8/8 flops)\n",
      "  block2b_se_reduce/mul (8/8 flops)\n",
      "  block2b_se_reduce/mul_1 (8/8 flops)\n",
      "  block2c_se_reduce/BiasAdd (8/8 flops)\n",
      "  block2c_se_reduce/mul (8/8 flops)\n",
      "  block2c_se_reduce/mul_1 (8/8 flops)\n",
      "  block2d_se_reduce/BiasAdd (8/8 flops)\n",
      "  block2d_se_reduce/mul (8/8 flops)\n",
      "  block2d_se_reduce/mul_1 (8/8 flops)\n",
      "  block3a_se_reduce/BiasAdd (8/8 flops)\n",
      "  block3a_se_reduce/mul (8/8 flops)\n",
      "  block3a_se_reduce/mul_1 (8/8 flops)\n",
      "  block1b_se_reduce/BiasAdd (6/6 flops)\n",
      "  block1b_se_reduce/mul (6/6 flops)\n",
      "  block1b_se_reduce/mul_1 (6/6 flops)\n",
      "  block2a_se_reduce/BiasAdd (6/6 flops)\n",
      "  block2a_se_reduce/mul (6/6 flops)\n",
      "  block2a_se_reduce/mul_1 (6/6 flops)\n",
      "  normalization_4/Maximum (3/3 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.45b flops)\n",
      "  block2b_expand_conv/Conv2D (231.21m/231.21m flops)\n",
      "  block3b_expand_conv/Conv2D (130.06m/130.06m flops)\n",
      "  block1a_project_conv/Conv2D (115.61m/115.61m flops)\n",
      "  block2a_expand_conv/Conv2D (57.80m/57.80m flops)\n",
      "  block3a_expand_conv/Conv2D (57.80m/57.80m flops)\n",
      "  block5b_expand_conv/Conv2D (29.50m/29.50m flops)\n",
      "  block5b_project_conv/Conv2D (29.50m/29.50m flops)\n",
      "  block5c_expand_conv/Conv2D (29.50m/29.50m flops)\n",
      "  block5c_project_conv/Conv2D (29.50m/29.50m flops)\n",
      "  block5d_expand_conv/Conv2D (29.50m/29.50m flops)\n",
      "  block5d_project_conv/Conv2D (29.50m/29.50m flops)\n",
      "  block5e_expand_conv/Conv2D (29.50m/29.50m flops)\n",
      "  block5e_project_conv/Conv2D (29.50m/29.50m flops)\n",
      "  block6a_expand_conv/Conv2D (29.50m/29.50m flops)\n",
      "  block2b_project_conv/Conv2D (25.69m/25.69m flops)\n",
      "  block5a_project_conv/Conv2D (25.29m/25.29m flops)\n",
      "  top_conv/Conv2D (24.08m/24.08m flops)\n",
      "  block5a_expand_conv/Conv2D (21.68m/21.68m flops)\n",
      "  block6b_expand_conv/Conv2D (21.68m/21.68m flops)\n",
      "  block6b_project_conv/Conv2D (21.68m/21.68m flops)\n",
      "  block6c_expand_conv/Conv2D (21.68m/21.68m flops)\n",
      "  block6c_project_conv/Conv2D (21.68m/21.68m flops)\n",
      "  block6d_expand_conv/Conv2D (21.68m/21.68m flops)\n",
      "  block6d_project_conv/Conv2D (21.68m/21.68m flops)\n",
      "  block6e_expand_conv/Conv2D (21.68m/21.68m flops)\n",
      "  block6e_project_conv/Conv2D (21.68m/21.68m flops)\n",
      "  block6f_expand_conv/Conv2D (21.68m/21.68m flops)\n",
      "  block6f_project_conv/Conv2D (21.68m/21.68m flops)\n",
      "  block6g_expand_conv/Conv2D (21.68m/21.68m flops)\n",
      "  block6g_project_conv/Conv2D (21.68m/21.68m flops)\n",
      "  block6h_expand_conv/Conv2D (21.68m/21.68m flops)\n",
      "  block6h_project_conv/Conv2D (21.68m/21.68m flops)\n",
      "  stem_conv/Conv2D (21.68m/21.68m flops)\n",
      "  block3b_project_conv/Conv2D (14.45m/14.45m flops)\n",
      "  block4a_expand_conv/Conv2D (14.45m/14.45m flops)\n",
      "  block4b_expand_conv/Conv2D (14.45m/14.45m flops)\n",
      "  block4b_project_conv/Conv2D (14.45m/14.45m flops)\n",
      "  block4c_expand_conv/Conv2D (14.45m/14.45m flops)\n",
      "  block4c_project_conv/Conv2D (14.45m/14.45m flops)\n",
      "  block2a_project_conv/Conv2D (12.85m/12.85m flops)\n",
      "  block6a_project_conv/Conv2D (12.64m/12.64m flops)\n",
      "  block3a_project_conv/Conv2D (9.63m/9.63m flops)\n",
      "  block4a_project_conv/Conv2D (7.23m/7.23m flops)\n",
      "  predictions/MatMul (2.56m/2.56m flops)\n",
      "  block5b_dwconv2/depthwise (2.37m/2.37m flops)\n",
      "  block5c_dwconv2/depthwise (2.37m/2.37m flops)\n",
      "  block5d_dwconv2/depthwise (2.37m/2.37m flops)\n",
      "  block5e_dwconv2/depthwise (2.37m/2.37m flops)\n",
      "  block5a_dwconv2/depthwise (2.03m/2.03m flops)\n",
      "  block4b_dwconv2/depthwise (1.35m/1.35m flops)\n",
      "  block4c_dwconv2/depthwise (1.35m/1.35m flops)\n",
      "  block6b_dwconv2/depthwise (1.02m/1.02m flops)\n",
      "  block6c_dwconv2/depthwise (1.02m/1.02m flops)\n",
      "  block6d_dwconv2/depthwise (1.02m/1.02m flops)\n",
      "  block6e_dwconv2/depthwise (1.02m/1.02m flops)\n",
      "  block6f_dwconv2/depthwise (1.02m/1.02m flops)\n",
      "  block6g_dwconv2/depthwise (1.02m/1.02m flops)\n",
      "  block6h_dwconv2/depthwise (1.02m/1.02m flops)\n",
      "  block4a_dwconv2/depthwise (677.38k/677.38k flops)\n",
      "  block6a_dwconv2/depthwise (592.70k/592.70k flops)\n",
      "  block2b_expand_activation/mul (401.41k/401.41k flops)\n",
      "  block2b_expand_activation/mul_1 (401.41k/401.41k flops)\n",
      "  stem_activation/mul (401.41k/401.41k flops)\n",
      "  stem_activation/mul_1 (401.41k/401.41k flops)\n",
      "  block1a_project_activation/mul (200.70k/200.70k flops)\n",
      "  block1a_project_activation/mul_1 (200.70k/200.70k flops)\n",
      "  block2a_expand_activation/mul (200.70k/200.70k flops)\n",
      "  block2a_expand_activation/mul_1 (200.70k/200.70k flops)\n",
      "  block3b_expand_activation/mul (150.53k/150.53k flops)\n",
      "  block3b_expand_activation/mul_1 (150.53k/150.53k flops)\n",
      "  block4a_expand_activation/mul (150.53k/150.53k flops)\n",
      "  block4a_expand_activation/mul_1 (150.53k/150.53k flops)\n",
      "  normalization_8/sub (150.53k/150.53k flops)\n",
      "  normalization_8/truediv (150.53k/150.53k flops)\n",
      "  rescaling_8/mul (150.53k/150.53k flops)\n",
      "  block5b_activation/mul (131.71k/131.71k flops)\n",
      "  block5b_activation/mul_1 (131.71k/131.71k flops)\n",
      "  block5b_expand_activation/mul (131.71k/131.71k flops)\n",
      "  block5b_expand_activation/mul_1 (131.71k/131.71k flops)\n",
      "  block5b_se_excite/mul (131.71k/131.71k flops)\n",
      "  block5b_se_squeeze/Mean (131.71k/131.71k flops)\n",
      "  block5c_activation/mul (131.71k/131.71k flops)\n",
      "  block5c_activation/mul_1 (131.71k/131.71k flops)\n",
      "  block5c_expand_activation/mul (131.71k/131.71k flops)\n",
      "  block5c_expand_activation/mul_1 (131.71k/131.71k flops)\n",
      "  block5c_se_excite/mul (131.71k/131.71k flops)\n",
      "  block5c_se_squeeze/Mean (131.71k/131.71k flops)\n",
      "  block5d_activation/mul (131.71k/131.71k flops)\n",
      "  block5d_activation/mul_1 (131.71k/131.71k flops)\n",
      "  block5d_expand_activation/mul (131.71k/131.71k flops)\n",
      "  block5d_expand_activation/mul_1 (131.71k/131.71k flops)\n",
      "  block5d_se_excite/mul (131.71k/131.71k flops)\n",
      "  block5d_se_squeeze/Mean (131.71k/131.71k flops)\n",
      "  block5e_activation/mul (131.71k/131.71k flops)\n",
      "  block5e_activation/mul_1 (131.71k/131.71k flops)\n",
      "  block5e_expand_activation/mul (131.71k/131.71k flops)\n",
      "  block5e_expand_activation/mul_1 (131.71k/131.71k flops)\n",
      "  block5e_se_excite/mul (131.71k/131.71k flops)\n",
      "  block5e_se_squeeze/Mean (131.71k/131.71k flops)\n",
      "  block6a_expand_activation/mul (131.71k/131.71k flops)\n",
      "  block6a_expand_activation/mul_1 (131.71k/131.71k flops)\n",
      "  block5a_activation/mul (112.90k/112.90k flops)\n",
      "  block5a_activation/mul_1 (112.90k/112.90k flops)\n",
      "  block5a_expand_activation/mul (112.90k/112.90k flops)\n",
      "  block5a_expand_activation/mul_1 (112.90k/112.90k flops)\n",
      "  block5a_se_excite/mul (112.90k/112.90k flops)\n",
      "  block5a_se_squeeze/Mean (112.90k/112.90k flops)\n",
      "  block6b_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  block6b_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  block6c_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  block6c_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  block6d_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  block6d_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  block6e_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  block6e_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  block6f_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  block6f_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  block6g_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  block6g_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  block6h_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  block6h_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  block3a_expand_activation/mul (100.35k/100.35k flops)\n",
      "  block3a_expand_activation/mul_1 (100.35k/100.35k flops)\n",
      "  block4b_activation/mul (75.26k/75.26k flops)\n",
      "  block4b_activation/mul_1 (75.26k/75.26k flops)\n",
      "  block4b_expand_activation/mul (75.26k/75.26k flops)\n",
      "  block4b_expand_activation/mul_1 (75.26k/75.26k flops)\n",
      "  block4b_se_excite/mul (75.26k/75.26k flops)\n",
      "  block4b_se_squeeze/Mean (75.26k/75.26k flops)\n",
      "  block4c_activation/mul (75.26k/75.26k flops)\n",
      "  block4c_activation/mul_1 (75.26k/75.26k flops)\n",
      "  block4c_expand_activation/mul (75.26k/75.26k flops)\n",
      "  block4c_expand_activation/mul_1 (75.26k/75.26k flops)\n",
      "  block4c_se_excite/mul (75.26k/75.26k flops)\n",
      "  block4c_se_squeeze/Mean (75.26k/75.26k flops)\n",
      "  avg_pool/Mean (62.72k/62.72k flops)\n",
      "  top_activation/mul (62.72k/62.72k flops)\n",
      "  top_activation/mul_1 (62.72k/62.72k flops)\n",
      "  block6b_activation/mul (56.45k/56.45k flops)\n",
      "  block6b_activation/mul_1 (56.45k/56.45k flops)\n",
      "  block6b_expand_activation/mul (56.45k/56.45k flops)\n",
      "  block6b_expand_activation/mul_1 (56.45k/56.45k flops)\n",
      "  block6b_se_excite/mul (56.45k/56.45k flops)\n",
      "  block6b_se_squeeze/Mean (56.45k/56.45k flops)\n",
      "  block6c_activation/mul (56.45k/56.45k flops)\n",
      "  block6c_activation/mul_1 (56.45k/56.45k flops)\n",
      "  block6c_expand_activation/mul (56.45k/56.45k flops)\n",
      "  block6c_expand_activation/mul_1 (56.45k/56.45k flops)\n",
      "  block6c_se_excite/mul (56.45k/56.45k flops)\n",
      "  block6c_se_squeeze/Mean (56.45k/56.45k flops)\n",
      "  block6d_activation/mul (56.45k/56.45k flops)\n",
      "  block6d_activation/mul_1 (56.45k/56.45k flops)\n",
      "  block6d_expand_activation/mul (56.45k/56.45k flops)\n",
      "  block6d_expand_activation/mul_1 (56.45k/56.45k flops)\n",
      "  block6d_se_excite/mul (56.45k/56.45k flops)\n",
      "  block6d_se_squeeze/Mean (56.45k/56.45k flops)\n",
      "  block6e_activation/mul (56.45k/56.45k flops)\n",
      "  block6e_activation/mul_1 (56.45k/56.45k flops)\n",
      "  block6e_expand_activation/mul (56.45k/56.45k flops)\n",
      "  block6e_expand_activation/mul_1 (56.45k/56.45k flops)\n",
      "  block6e_se_excite/mul (56.45k/56.45k flops)\n",
      "  block6e_se_squeeze/Mean (56.45k/56.45k flops)\n",
      "  block6f_activation/mul (56.45k/56.45k flops)\n",
      "  block6f_activation/mul_1 (56.45k/56.45k flops)\n",
      "  block6f_expand_activation/mul (56.45k/56.45k flops)\n",
      "  block6f_expand_activation/mul_1 (56.45k/56.45k flops)\n",
      "  block6f_se_excite/mul (56.45k/56.45k flops)\n",
      "  block6f_se_squeeze/Mean (56.45k/56.45k flops)\n",
      "  block6g_activation/mul (56.45k/56.45k flops)\n",
      "  block6g_activation/mul_1 (56.45k/56.45k flops)\n",
      "  block6g_expand_activation/mul (56.45k/56.45k flops)\n",
      "  block6g_expand_activation/mul_1 (56.45k/56.45k flops)\n",
      "  block6g_se_excite/mul (56.45k/56.45k flops)\n",
      "  block6g_se_squeeze/Mean (56.45k/56.45k flops)\n",
      "  block6h_activation/mul (56.45k/56.45k flops)\n",
      "  block6h_activation/mul_1 (56.45k/56.45k flops)\n",
      "  block6h_expand_activation/mul (56.45k/56.45k flops)\n",
      "  block6h_expand_activation/mul_1 (56.45k/56.45k flops)\n",
      "  block6h_se_excite/mul (56.45k/56.45k flops)\n",
      "  block6h_se_squeeze/Mean (56.45k/56.45k flops)\n",
      "  block4a_activation/mul (37.63k/37.63k flops)\n",
      "  block4a_activation/mul_1 (37.63k/37.63k flops)\n",
      "  block4a_se_excite/mul (37.63k/37.63k flops)\n",
      "  block4a_se_squeeze/Mean (37.63k/37.63k flops)\n",
      "  block5b_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  block5b_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  block5c_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  block5c_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  block5d_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  block5d_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  block5e_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  block5e_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  block6a_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  block6a_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  block6a_activation/mul (32.93k/32.93k flops)\n",
      "  block6a_activation/mul_1 (32.93k/32.93k flops)\n",
      "  block6a_se_excite/mul (32.93k/32.93k flops)\n",
      "  block6a_se_squeeze/Mean (32.93k/32.93k flops)\n",
      "  block5a_se_expand/Conv2D (27.65k/27.65k flops)\n",
      "  block5a_se_reduce/Conv2D (27.65k/27.65k flops)\n",
      "  block4b_se_expand/Conv2D (18.43k/18.43k flops)\n",
      "  block4b_se_reduce/Conv2D (18.43k/18.43k flops)\n",
      "  block4c_se_expand/Conv2D (18.43k/18.43k flops)\n",
      "  block4c_se_reduce/Conv2D (18.43k/18.43k flops)\n",
      "  predictions/Softmax (5.00k/5.00k flops)\n",
      "  block4a_se_expand/Conv2D (4.61k/4.61k flops)\n",
      "  block4a_se_reduce/Conv2D (4.61k/4.61k flops)\n",
      "  block6b_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  block6c_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  block6d_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  block6e_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  block6f_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  block6g_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  block6h_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  predictions/BiasAdd (1.00k/1.00k flops)\n",
      "  block5b_se_expand/BiasAdd (672/672 flops)\n",
      "  block5c_se_expand/BiasAdd (672/672 flops)\n",
      "  block5d_se_expand/BiasAdd (672/672 flops)\n",
      "  block5e_se_expand/BiasAdd (672/672 flops)\n",
      "  block6a_se_expand/BiasAdd (672/672 flops)\n",
      "  block5a_se_expand/BiasAdd (576/576 flops)\n",
      "  block4b_se_expand/BiasAdd (384/384 flops)\n",
      "  block4c_se_expand/BiasAdd (384/384 flops)\n",
      "  block4a_se_expand/BiasAdd (192/192 flops)\n",
      "  block6b_se_reduce/BiasAdd (48/48 flops)\n",
      "  block6b_se_reduce/mul (48/48 flops)\n",
      "  block6b_se_reduce/mul_1 (48/48 flops)\n",
      "  block6c_se_reduce/BiasAdd (48/48 flops)\n",
      "  block6c_se_reduce/mul (48/48 flops)\n",
      "  block6c_se_reduce/mul_1 (48/48 flops)\n",
      "  block6d_se_reduce/BiasAdd (48/48 flops)\n",
      "  block6d_se_reduce/mul (48/48 flops)\n",
      "  block6d_se_reduce/mul_1 (48/48 flops)\n",
      "  block6e_se_reduce/BiasAdd (48/48 flops)\n",
      "  block6e_se_reduce/mul (48/48 flops)\n",
      "  block6e_se_reduce/mul_1 (48/48 flops)\n",
      "  block6f_se_reduce/BiasAdd (48/48 flops)\n",
      "  block6f_se_reduce/mul (48/48 flops)\n",
      "  block6f_se_reduce/mul_1 (48/48 flops)\n",
      "  block6g_se_reduce/BiasAdd (48/48 flops)\n",
      "  block6g_se_reduce/mul (48/48 flops)\n",
      "  block6g_se_reduce/mul_1 (48/48 flops)\n",
      "  block6h_se_reduce/BiasAdd (48/48 flops)\n",
      "  block6h_se_reduce/mul (48/48 flops)\n",
      "  block6h_se_reduce/mul_1 (48/48 flops)\n",
      "  block5b_se_reduce/BiasAdd (28/28 flops)\n",
      "  block5b_se_reduce/mul (28/28 flops)\n",
      "  block5b_se_reduce/mul_1 (28/28 flops)\n",
      "  block5c_se_reduce/BiasAdd (28/28 flops)\n",
      "  block5c_se_reduce/mul (28/28 flops)\n",
      "  block5c_se_reduce/mul_1 (28/28 flops)\n",
      "  block5d_se_reduce/BiasAdd (28/28 flops)\n",
      "  block5d_se_reduce/mul (28/28 flops)\n",
      "  block5d_se_reduce/mul_1 (28/28 flops)\n",
      "  block5e_se_reduce/BiasAdd (28/28 flops)\n",
      "  block5e_se_reduce/mul (28/28 flops)\n",
      "  block5e_se_reduce/mul_1 (28/28 flops)\n",
      "  block6a_se_reduce/BiasAdd (28/28 flops)\n",
      "  block6a_se_reduce/mul (28/28 flops)\n",
      "  block6a_se_reduce/mul_1 (28/28 flops)\n",
      "  block4b_se_reduce/BiasAdd (24/24 flops)\n",
      "  block4b_se_reduce/mul (24/24 flops)\n",
      "  block4b_se_reduce/mul_1 (24/24 flops)\n",
      "  block4c_se_reduce/BiasAdd (24/24 flops)\n",
      "  block4c_se_reduce/mul (24/24 flops)\n",
      "  block4c_se_reduce/mul_1 (24/24 flops)\n",
      "  block5a_se_reduce/BiasAdd (24/24 flops)\n",
      "  block5a_se_reduce/mul (24/24 flops)\n",
      "  block5a_se_reduce/mul_1 (24/24 flops)\n",
      "  block4a_se_reduce/BiasAdd (12/12 flops)\n",
      "  block4a_se_reduce/mul (12/12 flops)\n",
      "  block4a_se_reduce/mul_1 (12/12 flops)\n",
      "  normalization_8/Maximum (3/3 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/2.41b flops)\n",
      "  block2b_expand_conv/Conv2D (265.42m/265.42m flops)\n",
      "  block2c_expand_conv/Conv2D (265.42m/265.42m flops)\n",
      "  block3b_expand_conv/Conv2D (149.30m/149.30m flops)\n",
      "  block3c_expand_conv/Conv2D (149.30m/149.30m flops)\n",
      "  block1a_project_conv/Conv2D (132.71m/132.71m flops)\n",
      "  block1b_project_conv/Conv2D (66.36m/66.36m flops)\n",
      "  block2a_expand_conv/Conv2D (66.36m/66.36m flops)\n",
      "  block3a_expand_conv/Conv2D (66.36m/66.36m flops)\n",
      "  block5b_expand_conv/Conv2D (33.87m/33.87m flops)\n",
      "  block5b_project_conv/Conv2D (33.87m/33.87m flops)\n",
      "  block5c_expand_conv/Conv2D (33.87m/33.87m flops)\n",
      "  block5c_project_conv/Conv2D (33.87m/33.87m flops)\n",
      "  block5d_expand_conv/Conv2D (33.87m/33.87m flops)\n",
      "  block5d_project_conv/Conv2D (33.87m/33.87m flops)\n",
      "  block5e_expand_conv/Conv2D (33.87m/33.87m flops)\n",
      "  block5e_project_conv/Conv2D (33.87m/33.87m flops)\n",
      "  block5f_expand_conv/Conv2D (33.87m/33.87m flops)\n",
      "  block5f_project_conv/Conv2D (33.87m/33.87m flops)\n",
      "  block6a_expand_conv/Conv2D (33.87m/33.87m flops)\n",
      "  top_conv/Conv2D (31.46m/31.46m flops)\n",
      "  block2b_project_conv/Conv2D (29.49m/29.49m flops)\n",
      "  block2c_project_conv/Conv2D (29.49m/29.49m flops)\n",
      "  block5a_project_conv/Conv2D (29.03m/29.03m flops)\n",
      "  block6b_expand_conv/Conv2D (28.31m/28.31m flops)\n",
      "  block6b_project_conv/Conv2D (28.31m/28.31m flops)\n",
      "  block6c_expand_conv/Conv2D (28.31m/28.31m flops)\n",
      "  block6c_project_conv/Conv2D (28.31m/28.31m flops)\n",
      "  block6d_expand_conv/Conv2D (28.31m/28.31m flops)\n",
      "  block6d_project_conv/Conv2D (28.31m/28.31m flops)\n",
      "  block6e_expand_conv/Conv2D (28.31m/28.31m flops)\n",
      "  block6e_project_conv/Conv2D (28.31m/28.31m flops)\n",
      "  block6f_expand_conv/Conv2D (28.31m/28.31m flops)\n",
      "  block6f_project_conv/Conv2D (28.31m/28.31m flops)\n",
      "  block6g_expand_conv/Conv2D (28.31m/28.31m flops)\n",
      "  block6g_project_conv/Conv2D (28.31m/28.31m flops)\n",
      "  block6h_expand_conv/Conv2D (28.31m/28.31m flops)\n",
      "  block6h_project_conv/Conv2D (28.31m/28.31m flops)\n",
      "  block6i_expand_conv/Conv2D (28.31m/28.31m flops)\n",
      "  block6i_project_conv/Conv2D (28.31m/28.31m flops)\n",
      "  block5a_expand_conv/Conv2D (24.88m/24.88m flops)\n",
      "  stem_conv/Conv2D (24.88m/24.88m flops)\n",
      "  block3b_project_conv/Conv2D (16.59m/16.59m flops)\n",
      "  block3c_project_conv/Conv2D (16.59m/16.59m flops)\n",
      "  block4a_expand_conv/Conv2D (16.59m/16.59m flops)\n",
      "  block4b_expand_conv/Conv2D (16.59m/16.59m flops)\n",
      "  block4b_project_conv/Conv2D (16.59m/16.59m flops)\n",
      "  block4c_expand_conv/Conv2D (16.59m/16.59m flops)\n",
      "  block4c_project_conv/Conv2D (16.59m/16.59m flops)\n",
      "  block4d_expand_conv/Conv2D (16.59m/16.59m flops)\n",
      "  block4d_project_conv/Conv2D (16.59m/16.59m flops)\n",
      "  block6a_project_conv/Conv2D (16.52m/16.52m flops)\n",
      "  block2a_project_conv/Conv2D (14.75m/14.75m flops)\n",
      "  block3a_project_conv/Conv2D (11.06m/11.06m flops)\n",
      "  block4a_project_conv/Conv2D (8.29m/8.29m flops)\n",
      "  block5b_dwconv2/depthwise (2.72m/2.72m flops)\n",
      "  block5c_dwconv2/depthwise (2.72m/2.72m flops)\n",
      "  block5d_dwconv2/depthwise (2.72m/2.72m flops)\n",
      "  block5e_dwconv2/depthwise (2.72m/2.72m flops)\n",
      "  block5f_dwconv2/depthwise (2.72m/2.72m flops)\n",
      "  predictions/MatMul (2.56m/2.56m flops)\n",
      "  block5a_dwconv2/depthwise (2.33m/2.33m flops)\n",
      "  block4b_dwconv2/depthwise (1.56m/1.56m flops)\n",
      "  block4c_dwconv2/depthwise (1.56m/1.56m flops)\n",
      "  block4d_dwconv2/depthwise (1.56m/1.56m flops)\n",
      "  block6b_dwconv2/depthwise (1.33m/1.33m flops)\n",
      "  block6c_dwconv2/depthwise (1.33m/1.33m flops)\n",
      "  block6d_dwconv2/depthwise (1.33m/1.33m flops)\n",
      "  block6e_dwconv2/depthwise (1.33m/1.33m flops)\n",
      "  block6f_dwconv2/depthwise (1.33m/1.33m flops)\n",
      "  block6g_dwconv2/depthwise (1.33m/1.33m flops)\n",
      "  block6h_dwconv2/depthwise (1.33m/1.33m flops)\n",
      "  block6i_dwconv2/depthwise (1.33m/1.33m flops)\n",
      "  block4a_dwconv2/depthwise (777.60k/777.60k flops)\n",
      "  block6a_dwconv2/depthwise (774.14k/774.14k flops)\n",
      "  block2b_expand_activation/mul (460.80k/460.80k flops)\n",
      "  block2b_expand_activation/mul_1 (460.80k/460.80k flops)\n",
      "  block2c_expand_activation/mul (460.80k/460.80k flops)\n",
      "  block2c_expand_activation/mul_1 (460.80k/460.80k flops)\n",
      "  stem_activation/mul (460.80k/460.80k flops)\n",
      "  stem_activation/mul_1 (460.80k/460.80k flops)\n",
      "  block1a_project_activation/mul (230.40k/230.40k flops)\n",
      "  block1a_project_activation/mul_1 (230.40k/230.40k flops)\n",
      "  block1b_project_activation/mul (230.40k/230.40k flops)\n",
      "  block1b_project_activation/mul_1 (230.40k/230.40k flops)\n",
      "  block2a_expand_activation/mul (230.40k/230.40k flops)\n",
      "  block2a_expand_activation/mul_1 (230.40k/230.40k flops)\n",
      "  block3b_expand_activation/mul (172.80k/172.80k flops)\n",
      "  block3b_expand_activation/mul_1 (172.80k/172.80k flops)\n",
      "  block3c_expand_activation/mul (172.80k/172.80k flops)\n",
      "  block3c_expand_activation/mul_1 (172.80k/172.80k flops)\n",
      "  block4a_expand_activation/mul (172.80k/172.80k flops)\n",
      "  block4a_expand_activation/mul_1 (172.80k/172.80k flops)\n",
      "  normalization_9/sub (172.80k/172.80k flops)\n",
      "  normalization_9/truediv (172.80k/172.80k flops)\n",
      "  rescaling_9/mul (172.80k/172.80k flops)\n",
      "  block5b_activation/mul (151.20k/151.20k flops)\n",
      "  block5b_activation/mul_1 (151.20k/151.20k flops)\n",
      "  block5b_expand_activation/mul (151.20k/151.20k flops)\n",
      "  block5b_expand_activation/mul_1 (151.20k/151.20k flops)\n",
      "  block5b_se_excite/mul (151.20k/151.20k flops)\n",
      "  block5b_se_squeeze/Mean (151.20k/151.20k flops)\n",
      "  block5c_activation/mul (151.20k/151.20k flops)\n",
      "  block5c_activation/mul_1 (151.20k/151.20k flops)\n",
      "  block5c_expand_activation/mul (151.20k/151.20k flops)\n",
      "  block5c_expand_activation/mul_1 (151.20k/151.20k flops)\n",
      "  block5c_se_excite/mul (151.20k/151.20k flops)\n",
      "  block5c_se_squeeze/Mean (151.20k/151.20k flops)\n",
      "  block5d_activation/mul (151.20k/151.20k flops)\n",
      "  block5d_activation/mul_1 (151.20k/151.20k flops)\n",
      "  block5d_expand_activation/mul (151.20k/151.20k flops)\n",
      "  block5d_expand_activation/mul_1 (151.20k/151.20k flops)\n",
      "  block5d_se_excite/mul (151.20k/151.20k flops)\n",
      "  block5d_se_squeeze/Mean (151.20k/151.20k flops)\n",
      "  block5e_activation/mul (151.20k/151.20k flops)\n",
      "  block5e_activation/mul_1 (151.20k/151.20k flops)\n",
      "  block5e_expand_activation/mul (151.20k/151.20k flops)\n",
      "  block5e_expand_activation/mul_1 (151.20k/151.20k flops)\n",
      "  block5e_se_excite/mul (151.20k/151.20k flops)\n",
      "  block5e_se_squeeze/Mean (151.20k/151.20k flops)\n",
      "  block5f_activation/mul (151.20k/151.20k flops)\n",
      "  block5f_activation/mul_1 (151.20k/151.20k flops)\n",
      "  block5f_expand_activation/mul (151.20k/151.20k flops)\n",
      "  block5f_expand_activation/mul_1 (151.20k/151.20k flops)\n",
      "  block5f_se_excite/mul (151.20k/151.20k flops)\n",
      "  block5f_se_squeeze/Mean (151.20k/151.20k flops)\n",
      "  block6a_expand_activation/mul (151.20k/151.20k flops)\n",
      "  block6a_expand_activation/mul_1 (151.20k/151.20k flops)\n",
      "  block5a_activation/mul (129.60k/129.60k flops)\n",
      "  block5a_activation/mul_1 (129.60k/129.60k flops)\n",
      "  block5a_expand_activation/mul (129.60k/129.60k flops)\n",
      "  block5a_expand_activation/mul_1 (129.60k/129.60k flops)\n",
      "  block5a_se_excite/mul (129.60k/129.60k flops)\n",
      "  block5a_se_squeeze/Mean (129.60k/129.60k flops)\n",
      "  block3a_expand_activation/mul (115.20k/115.20k flops)\n",
      "  block3a_expand_activation/mul_1 (115.20k/115.20k flops)\n",
      "  block6b_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  block6b_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  block6c_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  block6c_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  block6d_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  block6d_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  block6e_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  block6e_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  block6f_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  block6f_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  block6g_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  block6g_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  block6h_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  block6h_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  block6i_se_expand/Conv2D (110.59k/110.59k flops)\n",
      "  block6i_se_reduce/Conv2D (110.59k/110.59k flops)\n",
      "  block4b_activation/mul (86.40k/86.40k flops)\n",
      "  block4b_activation/mul_1 (86.40k/86.40k flops)\n",
      "  block4b_expand_activation/mul (86.40k/86.40k flops)\n",
      "  block4b_expand_activation/mul_1 (86.40k/86.40k flops)\n",
      "  block4b_se_excite/mul (86.40k/86.40k flops)\n",
      "  block4b_se_squeeze/Mean (86.40k/86.40k flops)\n",
      "  block4c_activation/mul (86.40k/86.40k flops)\n",
      "  block4c_activation/mul_1 (86.40k/86.40k flops)\n",
      "  block4c_expand_activation/mul (86.40k/86.40k flops)\n",
      "  block4c_expand_activation/mul_1 (86.40k/86.40k flops)\n",
      "  block4c_se_excite/mul (86.40k/86.40k flops)\n",
      "  block4c_se_squeeze/Mean (86.40k/86.40k flops)\n",
      "  block4d_activation/mul (86.40k/86.40k flops)\n",
      "  block4d_activation/mul_1 (86.40k/86.40k flops)\n",
      "  block4d_expand_activation/mul (86.40k/86.40k flops)\n",
      "  block4d_expand_activation/mul_1 (86.40k/86.40k flops)\n",
      "  block4d_se_excite/mul (86.40k/86.40k flops)\n",
      "  block4d_se_squeeze/Mean (86.40k/86.40k flops)\n",
      "  avg_pool/Mean (81.92k/81.92k flops)\n",
      "  top_activation/mul (81.92k/81.92k flops)\n",
      "  top_activation/mul_1 (81.92k/81.92k flops)\n",
      "  block6b_activation/mul (73.73k/73.73k flops)\n",
      "  block6b_activation/mul_1 (73.73k/73.73k flops)\n",
      "  block6b_expand_activation/mul (73.73k/73.73k flops)\n",
      "  block6b_expand_activation/mul_1 (73.73k/73.73k flops)\n",
      "  block6b_se_excite/mul (73.73k/73.73k flops)\n",
      "  block6b_se_squeeze/Mean (73.73k/73.73k flops)\n",
      "  block6c_activation/mul (73.73k/73.73k flops)\n",
      "  block6c_activation/mul_1 (73.73k/73.73k flops)\n",
      "  block6c_expand_activation/mul (73.73k/73.73k flops)\n",
      "  block6c_expand_activation/mul_1 (73.73k/73.73k flops)\n",
      "  block6c_se_excite/mul (73.73k/73.73k flops)\n",
      "  block6c_se_squeeze/Mean (73.73k/73.73k flops)\n",
      "  block6d_activation/mul (73.73k/73.73k flops)\n",
      "  block6d_activation/mul_1 (73.73k/73.73k flops)\n",
      "  block6d_expand_activation/mul (73.73k/73.73k flops)\n",
      "  block6d_expand_activation/mul_1 (73.73k/73.73k flops)\n",
      "  block6d_se_excite/mul (73.73k/73.73k flops)\n",
      "  block6d_se_squeeze/Mean (73.73k/73.73k flops)\n",
      "  block6e_activation/mul (73.73k/73.73k flops)\n",
      "  block6e_activation/mul_1 (73.73k/73.73k flops)\n",
      "  block6e_expand_activation/mul (73.73k/73.73k flops)\n",
      "  block6e_expand_activation/mul_1 (73.73k/73.73k flops)\n",
      "  block6e_se_excite/mul (73.73k/73.73k flops)\n",
      "  block6e_se_squeeze/Mean (73.73k/73.73k flops)\n",
      "  block6f_activation/mul (73.73k/73.73k flops)\n",
      "  block6f_activation/mul_1 (73.73k/73.73k flops)\n",
      "  block6f_expand_activation/mul (73.73k/73.73k flops)\n",
      "  block6f_expand_activation/mul_1 (73.73k/73.73k flops)\n",
      "  block6f_se_excite/mul (73.73k/73.73k flops)\n",
      "  block6f_se_squeeze/Mean (73.73k/73.73k flops)\n",
      "  block6g_activation/mul (73.73k/73.73k flops)\n",
      "  block6g_activation/mul_1 (73.73k/73.73k flops)\n",
      "  block6g_expand_activation/mul (73.73k/73.73k flops)\n",
      "  block6g_expand_activation/mul_1 (73.73k/73.73k flops)\n",
      "  block6g_se_excite/mul (73.73k/73.73k flops)\n",
      "  block6g_se_squeeze/Mean (73.73k/73.73k flops)\n",
      "  block6h_activation/mul (73.73k/73.73k flops)\n",
      "  block6h_activation/mul_1 (73.73k/73.73k flops)\n",
      "  block6h_expand_activation/mul (73.73k/73.73k flops)\n",
      "  block6h_expand_activation/mul_1 (73.73k/73.73k flops)\n",
      "  block6h_se_excite/mul (73.73k/73.73k flops)\n",
      "  block6h_se_squeeze/Mean (73.73k/73.73k flops)\n",
      "  block6i_activation/mul (73.73k/73.73k flops)\n",
      "  block6i_activation/mul_1 (73.73k/73.73k flops)\n",
      "  block6i_expand_activation/mul (73.73k/73.73k flops)\n",
      "  block6i_expand_activation/mul_1 (73.73k/73.73k flops)\n",
      "  block6i_se_excite/mul (73.73k/73.73k flops)\n",
      "  block6i_se_squeeze/Mean (73.73k/73.73k flops)\n",
      "  block4a_activation/mul (43.20k/43.20k flops)\n",
      "  block4a_activation/mul_1 (43.20k/43.20k flops)\n",
      "  block4a_se_excite/mul (43.20k/43.20k flops)\n",
      "  block4a_se_squeeze/Mean (43.20k/43.20k flops)\n",
      "  block6a_activation/mul (43.01k/43.01k flops)\n",
      "  block6a_activation/mul_1 (43.01k/43.01k flops)\n",
      "  block6a_se_excite/mul (43.01k/43.01k flops)\n",
      "  block6a_se_squeeze/Mean (43.01k/43.01k flops)\n",
      "  block5b_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  block5b_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  block5c_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  block5c_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  block5d_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  block5d_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  block5e_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  block5e_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  block5f_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  block5f_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  block6a_se_expand/Conv2D (37.63k/37.63k flops)\n",
      "  block6a_se_reduce/Conv2D (37.63k/37.63k flops)\n",
      "  block5a_se_expand/Conv2D (27.65k/27.65k flops)\n",
      "  block5a_se_reduce/Conv2D (27.65k/27.65k flops)\n",
      "  block4b_se_expand/Conv2D (18.43k/18.43k flops)\n",
      "  block4b_se_reduce/Conv2D (18.43k/18.43k flops)\n",
      "  block4c_se_expand/Conv2D (18.43k/18.43k flops)\n",
      "  block4c_se_reduce/Conv2D (18.43k/18.43k flops)\n",
      "  block4d_se_expand/Conv2D (18.43k/18.43k flops)\n",
      "  block4d_se_reduce/Conv2D (18.43k/18.43k flops)\n",
      "  predictions/Softmax (5.00k/5.00k flops)\n",
      "  block4a_se_expand/Conv2D (4.61k/4.61k flops)\n",
      "  block4a_se_reduce/Conv2D (4.61k/4.61k flops)\n",
      "  block6b_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  block6c_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  block6d_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  block6e_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  block6f_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  block6g_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  block6h_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  block6i_se_expand/BiasAdd (1.15k/1.15k flops)\n",
      "  predictions/BiasAdd (1.00k/1.00k flops)\n",
      "  block5b_se_expand/BiasAdd (672/672 flops)\n",
      "  block5c_se_expand/BiasAdd (672/672 flops)\n",
      "  block5d_se_expand/BiasAdd (672/672 flops)\n",
      "  block5e_se_expand/BiasAdd (672/672 flops)\n",
      "  block5f_se_expand/BiasAdd (672/672 flops)\n",
      "  block6a_se_expand/BiasAdd (672/672 flops)\n",
      "  block5a_se_expand/BiasAdd (576/576 flops)\n",
      "  block4b_se_expand/BiasAdd (384/384 flops)\n",
      "  block4c_se_expand/BiasAdd (384/384 flops)\n",
      "  block4d_se_expand/BiasAdd (384/384 flops)\n",
      "  block4a_se_expand/BiasAdd (192/192 flops)\n",
      "  block6b_se_reduce/BiasAdd (48/48 flops)\n",
      "  block6b_se_reduce/mul (48/48 flops)\n",
      "  block6b_se_reduce/mul_1 (48/48 flops)\n",
      "  block6c_se_reduce/BiasAdd (48/48 flops)\n",
      "  block6c_se_reduce/mul (48/48 flops)\n",
      "  block6c_se_reduce/mul_1 (48/48 flops)\n",
      "  block6d_se_reduce/BiasAdd (48/48 flops)\n",
      "  block6d_se_reduce/mul (48/48 flops)\n",
      "  block6d_se_reduce/mul_1 (48/48 flops)\n",
      "  block6e_se_reduce/BiasAdd (48/48 flops)\n",
      "  block6e_se_reduce/mul (48/48 flops)\n",
      "  block6e_se_reduce/mul_1 (48/48 flops)\n",
      "  block6f_se_reduce/BiasAdd (48/48 flops)\n",
      "  block6f_se_reduce/mul (48/48 flops)\n",
      "  block6f_se_reduce/mul_1 (48/48 flops)\n",
      "  block6g_se_reduce/BiasAdd (48/48 flops)\n",
      "  block6g_se_reduce/mul (48/48 flops)\n",
      "  block6g_se_reduce/mul_1 (48/48 flops)\n",
      "  block6h_se_reduce/BiasAdd (48/48 flops)\n",
      "  block6h_se_reduce/mul (48/48 flops)\n",
      "  block6h_se_reduce/mul_1 (48/48 flops)\n",
      "  block6i_se_reduce/BiasAdd (48/48 flops)\n",
      "  block6i_se_reduce/mul (48/48 flops)\n",
      "  block6i_se_reduce/mul_1 (48/48 flops)\n",
      "  block5b_se_reduce/BiasAdd (28/28 flops)\n",
      "  block5b_se_reduce/mul (28/28 flops)\n",
      "  block5b_se_reduce/mul_1 (28/28 flops)\n",
      "  block5c_se_reduce/BiasAdd (28/28 flops)\n",
      "  block5c_se_reduce/mul (28/28 flops)\n",
      "  block5c_se_reduce/mul_1 (28/28 flops)\n",
      "  block5d_se_reduce/BiasAdd (28/28 flops)\n",
      "  block5d_se_reduce/mul (28/28 flops)\n",
      "  block5d_se_reduce/mul_1 (28/28 flops)\n",
      "  block5e_se_reduce/BiasAdd (28/28 flops)\n",
      "  block5e_se_reduce/mul (28/28 flops)\n",
      "  block5e_se_reduce/mul_1 (28/28 flops)\n",
      "  block5f_se_reduce/BiasAdd (28/28 flops)\n",
      "  block5f_se_reduce/mul (28/28 flops)\n",
      "  block5f_se_reduce/mul_1 (28/28 flops)\n",
      "  block6a_se_reduce/BiasAdd (28/28 flops)\n",
      "  block6a_se_reduce/mul (28/28 flops)\n",
      "  block6a_se_reduce/mul_1 (28/28 flops)\n",
      "  block4b_se_reduce/BiasAdd (24/24 flops)\n",
      "  block4b_se_reduce/mul (24/24 flops)\n",
      "  block4b_se_reduce/mul_1 (24/24 flops)\n",
      "  block4c_se_reduce/BiasAdd (24/24 flops)\n",
      "  block4c_se_reduce/mul (24/24 flops)\n",
      "  block4c_se_reduce/mul_1 (24/24 flops)\n",
      "  block4d_se_reduce/BiasAdd (24/24 flops)\n",
      "  block4d_se_reduce/mul (24/24 flops)\n",
      "  block4d_se_reduce/mul_1 (24/24 flops)\n",
      "  block5a_se_reduce/BiasAdd (24/24 flops)\n",
      "  block5a_se_reduce/mul (24/24 flops)\n",
      "  block5a_se_reduce/mul_1 (24/24 flops)\n",
      "  block4a_se_reduce/BiasAdd (12/12 flops)\n",
      "  block4a_se_reduce/mul (12/12 flops)\n",
      "  block4a_se_reduce/mul_1 (12/12 flops)\n",
      "  normalization_9/Maximum (3/3 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/3.42b flops)\n",
      "  block2b_expand_conv/Conv2D (311.50m/311.50m flops)\n",
      "  block2c_expand_conv/Conv2D (311.50m/311.50m flops)\n",
      "  block3b_expand_conv/Conv2D (245.89m/245.89m flops)\n",
      "  block3c_expand_conv/Conv2D (245.89m/245.89m flops)\n",
      "  block1a_project_conv/Conv2D (155.75m/155.75m flops)\n",
      "  block3a_expand_conv/Conv2D (80.29m/80.29m flops)\n",
      "  block1b_project_conv/Conv2D (77.88m/77.88m flops)\n",
      "  block2a_expand_conv/Conv2D (77.88m/77.88m flops)\n",
      "  block5b_expand_conv/Conv2D (49.94m/49.94m flops)\n",
      "  block5b_project_conv/Conv2D (49.94m/49.94m flops)\n",
      "  block5c_expand_conv/Conv2D (49.94m/49.94m flops)\n",
      "  block5c_project_conv/Conv2D (49.94m/49.94m flops)\n",
      "  block5d_expand_conv/Conv2D (49.94m/49.94m flops)\n",
      "  block5d_project_conv/Conv2D (49.94m/49.94m flops)\n",
      "  block5e_expand_conv/Conv2D (49.94m/49.94m flops)\n",
      "  block5e_project_conv/Conv2D (49.94m/49.94m flops)\n",
      "  block5f_expand_conv/Conv2D (49.94m/49.94m flops)\n",
      "  block5f_project_conv/Conv2D (49.94m/49.94m flops)\n",
      "  block6a_expand_conv/Conv2D (49.94m/49.94m flops)\n",
      "  top_conv/Conv2D (47.44m/47.44m flops)\n",
      "  block5a_project_conv/Conv2D (43.28m/43.28m flops)\n",
      "  block6b_expand_conv/Conv2D (42.05m/42.05m flops)\n",
      "  block6b_project_conv/Conv2D (42.05m/42.05m flops)\n",
      "  block6c_expand_conv/Conv2D (42.05m/42.05m flops)\n",
      "  block6c_project_conv/Conv2D (42.05m/42.05m flops)\n",
      "  block6d_expand_conv/Conv2D (42.05m/42.05m flops)\n",
      "  block6d_project_conv/Conv2D (42.05m/42.05m flops)\n",
      "  block6e_expand_conv/Conv2D (42.05m/42.05m flops)\n",
      "  block6e_project_conv/Conv2D (42.05m/42.05m flops)\n",
      "  block6f_expand_conv/Conv2D (42.05m/42.05m flops)\n",
      "  block6f_project_conv/Conv2D (42.05m/42.05m flops)\n",
      "  block6g_expand_conv/Conv2D (42.05m/42.05m flops)\n",
      "  block6g_project_conv/Conv2D (42.05m/42.05m flops)\n",
      "  block6h_expand_conv/Conv2D (42.05m/42.05m flops)\n",
      "  block6h_project_conv/Conv2D (42.05m/42.05m flops)\n",
      "  block6i_expand_conv/Conv2D (42.05m/42.05m flops)\n",
      "  block6i_project_conv/Conv2D (42.05m/42.05m flops)\n",
      "  block6j_expand_conv/Conv2D (42.05m/42.05m flops)\n",
      "  block6j_project_conv/Conv2D (42.05m/42.05m flops)\n",
      "  block5a_expand_conv/Conv2D (37.51m/37.51m flops)\n",
      "  block2b_project_conv/Conv2D (34.61m/34.61m flops)\n",
      "  block2c_project_conv/Conv2D (34.61m/34.61m flops)\n",
      "  stem_conv/Conv2D (29.20m/29.20m flops)\n",
      "  block3b_project_conv/Conv2D (27.32m/27.32m flops)\n",
      "  block3c_project_conv/Conv2D (27.32m/27.32m flops)\n",
      "  block4a_expand_conv/Conv2D (27.32m/27.32m flops)\n",
      "  block4b_expand_conv/Conv2D (25.01m/25.01m flops)\n",
      "  block4b_project_conv/Conv2D (25.01m/25.01m flops)\n",
      "  block4c_expand_conv/Conv2D (25.01m/25.01m flops)\n",
      "  block4c_project_conv/Conv2D (25.01m/25.01m flops)\n",
      "  block4d_expand_conv/Conv2D (25.01m/25.01m flops)\n",
      "  block4d_project_conv/Conv2D (25.01m/25.01m flops)\n",
      "  block6a_project_conv/Conv2D (24.26m/24.26m flops)\n",
      "  block2a_project_conv/Conv2D (17.31m/17.31m flops)\n",
      "  block3a_project_conv/Conv2D (15.61m/15.61m flops)\n",
      "  block4a_project_conv/Conv2D (13.47m/13.47m flops)\n",
      "  block5b_dwconv2/depthwise (3.75m/3.75m flops)\n",
      "  block5c_dwconv2/depthwise (3.75m/3.75m flops)\n",
      "  block5d_dwconv2/depthwise (3.75m/3.75m flops)\n",
      "  block5e_dwconv2/depthwise (3.75m/3.75m flops)\n",
      "  block5f_dwconv2/depthwise (3.75m/3.75m flops)\n",
      "  block5a_dwconv2/depthwise (3.25m/3.25m flops)\n",
      "  predictions/MatMul (2.82m/2.82m flops)\n",
      "  block4b_dwconv2/depthwise (2.16m/2.16m flops)\n",
      "  block4c_dwconv2/depthwise (2.16m/2.16m flops)\n",
      "  block4d_dwconv2/depthwise (2.16m/2.16m flops)\n",
      "  block6b_dwconv2/depthwise (1.82m/1.82m flops)\n",
      "  block6c_dwconv2/depthwise (1.82m/1.82m flops)\n",
      "  block6d_dwconv2/depthwise (1.82m/1.82m flops)\n",
      "  block6e_dwconv2/depthwise (1.82m/1.82m flops)\n",
      "  block6f_dwconv2/depthwise (1.82m/1.82m flops)\n",
      "  block6g_dwconv2/depthwise (1.82m/1.82m flops)\n",
      "  block6h_dwconv2/depthwise (1.82m/1.82m flops)\n",
      "  block6i_dwconv2/depthwise (1.82m/1.82m flops)\n",
      "  block6j_dwconv2/depthwise (1.82m/1.82m flops)\n",
      "  block4a_dwconv2/depthwise (1.17m/1.17m flops)\n",
      "  block6a_dwconv2/depthwise (1.05m/1.05m flops)\n",
      "  block2b_expand_activation/mul (540.80k/540.80k flops)\n",
      "  block2b_expand_activation/mul_1 (540.80k/540.80k flops)\n",
      "  block2c_expand_activation/mul (540.80k/540.80k flops)\n",
      "  block2c_expand_activation/mul_1 (540.80k/540.80k flops)\n",
      "  stem_activation/mul (540.80k/540.80k flops)\n",
      "  stem_activation/mul_1 (540.80k/540.80k flops)\n",
      "  block1a_project_activation/mul (270.40k/270.40k flops)\n",
      "  block1a_project_activation/mul_1 (270.40k/270.40k flops)\n",
      "  block1b_project_activation/mul (270.40k/270.40k flops)\n",
      "  block1b_project_activation/mul_1 (270.40k/270.40k flops)\n",
      "  block2a_expand_activation/mul (270.40k/270.40k flops)\n",
      "  block2a_expand_activation/mul_1 (270.40k/270.40k flops)\n",
      "  block3b_expand_activation/mul (243.94k/243.94k flops)\n",
      "  block3b_expand_activation/mul_1 (243.94k/243.94k flops)\n",
      "  block3c_expand_activation/mul (243.94k/243.94k flops)\n",
      "  block3c_expand_activation/mul_1 (243.94k/243.94k flops)\n",
      "  block4a_expand_activation/mul (243.94k/243.94k flops)\n",
      "  block4a_expand_activation/mul_1 (243.94k/243.94k flops)\n",
      "  block5b_activation/mul (208.08k/208.08k flops)\n",
      "  block5b_activation/mul_1 (208.08k/208.08k flops)\n",
      "  block5b_expand_activation/mul (208.08k/208.08k flops)\n",
      "  block5b_expand_activation/mul_1 (208.08k/208.08k flops)\n",
      "  block5b_se_excite/mul (208.08k/208.08k flops)\n",
      "  block5b_se_squeeze/Mean (208.08k/208.08k flops)\n",
      "  block5c_activation/mul (208.08k/208.08k flops)\n",
      "  block5c_activation/mul_1 (208.08k/208.08k flops)\n",
      "  block5c_expand_activation/mul (208.08k/208.08k flops)\n",
      "  block5c_expand_activation/mul_1 (208.08k/208.08k flops)\n",
      "  block5c_se_excite/mul (208.08k/208.08k flops)\n",
      "  block5c_se_squeeze/Mean (208.08k/208.08k flops)\n",
      "  block5d_activation/mul (208.08k/208.08k flops)\n",
      "  block5d_activation/mul_1 (208.08k/208.08k flops)\n",
      "  block5d_expand_activation/mul (208.08k/208.08k flops)\n",
      "  block5d_expand_activation/mul_1 (208.08k/208.08k flops)\n",
      "  block5d_se_excite/mul (208.08k/208.08k flops)\n",
      "  block5d_se_squeeze/Mean (208.08k/208.08k flops)\n",
      "  block5e_activation/mul (208.08k/208.08k flops)\n",
      "  block5e_activation/mul_1 (208.08k/208.08k flops)\n",
      "  block5e_expand_activation/mul (208.08k/208.08k flops)\n",
      "  block5e_expand_activation/mul_1 (208.08k/208.08k flops)\n",
      "  block5e_se_excite/mul (208.08k/208.08k flops)\n",
      "  block5e_se_squeeze/Mean (208.08k/208.08k flops)\n",
      "  block5f_activation/mul (208.08k/208.08k flops)\n",
      "  block5f_activation/mul_1 (208.08k/208.08k flops)\n",
      "  block5f_expand_activation/mul (208.08k/208.08k flops)\n",
      "  block5f_expand_activation/mul_1 (208.08k/208.08k flops)\n",
      "  block5f_se_excite/mul (208.08k/208.08k flops)\n",
      "  block5f_se_squeeze/Mean (208.08k/208.08k flops)\n",
      "  block6a_expand_activation/mul (208.08k/208.08k flops)\n",
      "  block6a_expand_activation/mul_1 (208.08k/208.08k flops)\n",
      "  normalization_10/sub (202.80k/202.80k flops)\n",
      "  normalization_10/truediv (202.80k/202.80k flops)\n",
      "  rescaling_10/mul (202.80k/202.80k flops)\n",
      "  block5a_activation/mul (180.34k/180.34k flops)\n",
      "  block5a_activation/mul_1 (180.34k/180.34k flops)\n",
      "  block5a_expand_activation/mul (180.34k/180.34k flops)\n",
      "  block5a_expand_activation/mul_1 (180.34k/180.34k flops)\n",
      "  block5a_se_excite/mul (180.34k/180.34k flops)\n",
      "  block5a_se_squeeze/Mean (180.34k/180.34k flops)\n",
      "  block3a_expand_activation/mul (139.39k/139.39k flops)\n",
      "  block3a_expand_activation/mul_1 (139.39k/139.39k flops)\n",
      "  block6b_se_expand/Conv2D (129.79k/129.79k flops)\n",
      "  block6b_se_reduce/Conv2D (129.79k/129.79k flops)\n",
      "  block6c_se_expand/Conv2D (129.79k/129.79k flops)\n",
      "  block6c_se_reduce/Conv2D (129.79k/129.79k flops)\n",
      "  block6d_se_expand/Conv2D (129.79k/129.79k flops)\n",
      "  block6d_se_reduce/Conv2D (129.79k/129.79k flops)\n",
      "  block6e_se_expand/Conv2D (129.79k/129.79k flops)\n",
      "  block6e_se_reduce/Conv2D (129.79k/129.79k flops)\n",
      "  block6f_se_expand/Conv2D (129.79k/129.79k flops)\n",
      "  block6f_se_reduce/Conv2D (129.79k/129.79k flops)\n",
      "  block6g_se_expand/Conv2D (129.79k/129.79k flops)\n",
      "  block6g_se_reduce/Conv2D (129.79k/129.79k flops)\n",
      "  block6h_se_expand/Conv2D (129.79k/129.79k flops)\n",
      "  block6h_se_reduce/Conv2D (129.79k/129.79k flops)\n",
      "  block6i_se_expand/Conv2D (129.79k/129.79k flops)\n",
      "  block6i_se_reduce/Conv2D (129.79k/129.79k flops)\n",
      "  block6j_se_expand/Conv2D (129.79k/129.79k flops)\n",
      "  block6j_se_reduce/Conv2D (129.79k/129.79k flops)\n",
      "  block4b_activation/mul (120.22k/120.22k flops)\n",
      "  block4b_activation/mul_1 (120.22k/120.22k flops)\n",
      "  block4b_expand_activation/mul (120.22k/120.22k flops)\n",
      "  block4b_expand_activation/mul_1 (120.22k/120.22k flops)\n",
      "  block4b_se_excite/mul (120.22k/120.22k flops)\n",
      "  block4b_se_squeeze/Mean (120.22k/120.22k flops)\n",
      "  block4c_activation/mul (120.22k/120.22k flops)\n",
      "  block4c_activation/mul_1 (120.22k/120.22k flops)\n",
      "  block4c_expand_activation/mul (120.22k/120.22k flops)\n",
      "  block4c_expand_activation/mul_1 (120.22k/120.22k flops)\n",
      "  block4c_se_excite/mul (120.22k/120.22k flops)\n",
      "  block4c_se_squeeze/Mean (120.22k/120.22k flops)\n",
      "  block4d_activation/mul (120.22k/120.22k flops)\n",
      "  block4d_activation/mul_1 (120.22k/120.22k flops)\n",
      "  block4d_expand_activation/mul (120.22k/120.22k flops)\n",
      "  block4d_expand_activation/mul_1 (120.22k/120.22k flops)\n",
      "  block4d_se_excite/mul (120.22k/120.22k flops)\n",
      "  block4d_se_squeeze/Mean (120.22k/120.22k flops)\n",
      "  avg_pool/Mean (114.05k/114.05k flops)\n",
      "  top_activation/mul (114.05k/114.05k flops)\n",
      "  top_activation/mul_1 (114.05k/114.05k flops)\n",
      "  block6b_activation/mul (101.09k/101.09k flops)\n",
      "  block6b_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block6b_expand_activation/mul (101.09k/101.09k flops)\n",
      "  block6b_expand_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block6b_se_excite/mul (101.09k/101.09k flops)\n",
      "  block6b_se_squeeze/Mean (101.09k/101.09k flops)\n",
      "  block6c_activation/mul (101.09k/101.09k flops)\n",
      "  block6c_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block6c_expand_activation/mul (101.09k/101.09k flops)\n",
      "  block6c_expand_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block6c_se_excite/mul (101.09k/101.09k flops)\n",
      "  block6c_se_squeeze/Mean (101.09k/101.09k flops)\n",
      "  block6d_activation/mul (101.09k/101.09k flops)\n",
      "  block6d_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block6d_expand_activation/mul (101.09k/101.09k flops)\n",
      "  block6d_expand_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block6d_se_excite/mul (101.09k/101.09k flops)\n",
      "  block6d_se_squeeze/Mean (101.09k/101.09k flops)\n",
      "  block6e_activation/mul (101.09k/101.09k flops)\n",
      "  block6e_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block6e_expand_activation/mul (101.09k/101.09k flops)\n",
      "  block6e_expand_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block6e_se_excite/mul (101.09k/101.09k flops)\n",
      "  block6e_se_squeeze/Mean (101.09k/101.09k flops)\n",
      "  block6f_activation/mul (101.09k/101.09k flops)\n",
      "  block6f_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block6f_expand_activation/mul (101.09k/101.09k flops)\n",
      "  block6f_expand_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block6f_se_excite/mul (101.09k/101.09k flops)\n",
      "  block6f_se_squeeze/Mean (101.09k/101.09k flops)\n",
      "  block6g_activation/mul (101.09k/101.09k flops)\n",
      "  block6g_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block6g_expand_activation/mul (101.09k/101.09k flops)\n",
      "  block6g_expand_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block6g_se_excite/mul (101.09k/101.09k flops)\n",
      "  block6g_se_squeeze/Mean (101.09k/101.09k flops)\n",
      "  block6h_activation/mul (101.09k/101.09k flops)\n",
      "  block6h_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block6h_expand_activation/mul (101.09k/101.09k flops)\n",
      "  block6h_expand_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block6h_se_excite/mul (101.09k/101.09k flops)\n",
      "  block6h_se_squeeze/Mean (101.09k/101.09k flops)\n",
      "  block6i_activation/mul (101.09k/101.09k flops)\n",
      "  block6i_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block6i_expand_activation/mul (101.09k/101.09k flops)\n",
      "  block6i_expand_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block6i_se_excite/mul (101.09k/101.09k flops)\n",
      "  block6i_se_squeeze/Mean (101.09k/101.09k flops)\n",
      "  block6j_activation/mul (101.09k/101.09k flops)\n",
      "  block6j_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block6j_expand_activation/mul (101.09k/101.09k flops)\n",
      "  block6j_expand_activation/mul_1 (101.09k/101.09k flops)\n",
      "  block6j_se_excite/mul (101.09k/101.09k flops)\n",
      "  block6j_se_squeeze/Mean (101.09k/101.09k flops)\n",
      "  block4a_activation/mul (64.74k/64.74k flops)\n",
      "  block4a_activation/mul_1 (64.74k/64.74k flops)\n",
      "  block4a_se_excite/mul (64.74k/64.74k flops)\n",
      "  block4a_se_squeeze/Mean (64.74k/64.74k flops)\n",
      "  block6a_activation/mul (58.32k/58.32k flops)\n",
      "  block6a_activation/mul_1 (58.32k/58.32k flops)\n",
      "  block6a_se_excite/mul (58.32k/58.32k flops)\n",
      "  block6a_se_squeeze/Mean (58.32k/58.32k flops)\n",
      "  block5b_se_expand/Conv2D (43.20k/43.20k flops)\n",
      "  block5b_se_reduce/Conv2D (43.20k/43.20k flops)\n",
      "  block5c_se_expand/Conv2D (43.20k/43.20k flops)\n",
      "  block5c_se_reduce/Conv2D (43.20k/43.20k flops)\n",
      "  block5d_se_expand/Conv2D (43.20k/43.20k flops)\n",
      "  block5d_se_reduce/Conv2D (43.20k/43.20k flops)\n",
      "  block5e_se_expand/Conv2D (43.20k/43.20k flops)\n",
      "  block5e_se_reduce/Conv2D (43.20k/43.20k flops)\n",
      "  block5f_se_expand/Conv2D (43.20k/43.20k flops)\n",
      "  block5f_se_reduce/Conv2D (43.20k/43.20k flops)\n",
      "  block6a_se_expand/Conv2D (43.20k/43.20k flops)\n",
      "  block6a_se_reduce/Conv2D (43.20k/43.20k flops)\n",
      "  block5a_se_expand/Conv2D (32.45k/32.45k flops)\n",
      "  block5a_se_reduce/Conv2D (32.45k/32.45k flops)\n",
      "  block4b_se_expand/Conv2D (21.63k/21.63k flops)\n",
      "  block4b_se_reduce/Conv2D (21.63k/21.63k flops)\n",
      "  block4c_se_expand/Conv2D (21.63k/21.63k flops)\n",
      "  block4c_se_reduce/Conv2D (21.63k/21.63k flops)\n",
      "  block4d_se_expand/Conv2D (21.63k/21.63k flops)\n",
      "  block4d_se_reduce/Conv2D (21.63k/21.63k flops)\n",
      "  block4a_se_expand/Conv2D (6.27k/6.27k flops)\n",
      "  block4a_se_reduce/Conv2D (6.27k/6.27k flops)\n",
      "  predictions/Softmax (5.00k/5.00k flops)\n",
      "  block6b_se_expand/BiasAdd (1.25k/1.25k flops)\n",
      "  block6c_se_expand/BiasAdd (1.25k/1.25k flops)\n",
      "  block6d_se_expand/BiasAdd (1.25k/1.25k flops)\n",
      "  block6e_se_expand/BiasAdd (1.25k/1.25k flops)\n",
      "  block6f_se_expand/BiasAdd (1.25k/1.25k flops)\n",
      "  block6g_se_expand/BiasAdd (1.25k/1.25k flops)\n",
      "  block6h_se_expand/BiasAdd (1.25k/1.25k flops)\n",
      "  block6i_se_expand/BiasAdd (1.25k/1.25k flops)\n",
      "  block6j_se_expand/BiasAdd (1.25k/1.25k flops)\n",
      "  predictions/BiasAdd (1.00k/1.00k flops)\n",
      "  block5b_se_expand/BiasAdd (720/720 flops)\n",
      "  block5c_se_expand/BiasAdd (720/720 flops)\n",
      "  block5d_se_expand/BiasAdd (720/720 flops)\n",
      "  block5e_se_expand/BiasAdd (720/720 flops)\n",
      "  block5f_se_expand/BiasAdd (720/720 flops)\n",
      "  block6a_se_expand/BiasAdd (720/720 flops)\n",
      "  block5a_se_expand/BiasAdd (624/624 flops)\n",
      "  block4b_se_expand/BiasAdd (416/416 flops)\n",
      "  block4c_se_expand/BiasAdd (416/416 flops)\n",
      "  block4d_se_expand/BiasAdd (416/416 flops)\n",
      "  block4a_se_expand/BiasAdd (224/224 flops)\n",
      "  block6b_se_reduce/BiasAdd (52/52 flops)\n",
      "  block6b_se_reduce/mul (52/52 flops)\n",
      "  block6b_se_reduce/mul_1 (52/52 flops)\n",
      "  block6c_se_reduce/BiasAdd (52/52 flops)\n",
      "  block6c_se_reduce/mul (52/52 flops)\n",
      "  block6c_se_reduce/mul_1 (52/52 flops)\n",
      "  block6d_se_reduce/BiasAdd (52/52 flops)\n",
      "  block6d_se_reduce/mul (52/52 flops)\n",
      "  block6d_se_reduce/mul_1 (52/52 flops)\n",
      "  block6e_se_reduce/BiasAdd (52/52 flops)\n",
      "  block6e_se_reduce/mul (52/52 flops)\n",
      "  block6e_se_reduce/mul_1 (52/52 flops)\n",
      "  block6f_se_reduce/BiasAdd (52/52 flops)\n",
      "  block6f_se_reduce/mul (52/52 flops)\n",
      "  block6f_se_reduce/mul_1 (52/52 flops)\n",
      "  block6g_se_reduce/BiasAdd (52/52 flops)\n",
      "  block6g_se_reduce/mul (52/52 flops)\n",
      "  block6g_se_reduce/mul_1 (52/52 flops)\n",
      "  block6h_se_reduce/BiasAdd (52/52 flops)\n",
      "  block6h_se_reduce/mul (52/52 flops)\n",
      "  block6h_se_reduce/mul_1 (52/52 flops)\n",
      "  block6i_se_reduce/BiasAdd (52/52 flops)\n",
      "  block6i_se_reduce/mul (52/52 flops)\n",
      "  block6i_se_reduce/mul_1 (52/52 flops)\n",
      "  block6j_se_reduce/BiasAdd (52/52 flops)\n",
      "  block6j_se_reduce/mul (52/52 flops)\n",
      "  block6j_se_reduce/mul_1 (52/52 flops)\n",
      "  block5b_se_reduce/BiasAdd (30/30 flops)\n",
      "  block5b_se_reduce/mul (30/30 flops)\n",
      "  block5b_se_reduce/mul_1 (30/30 flops)\n",
      "  block5c_se_reduce/BiasAdd (30/30 flops)\n",
      "  block5c_se_reduce/mul (30/30 flops)\n",
      "  block5c_se_reduce/mul_1 (30/30 flops)\n",
      "  block5d_se_reduce/BiasAdd (30/30 flops)\n",
      "  block5d_se_reduce/mul (30/30 flops)\n",
      "  block5d_se_reduce/mul_1 (30/30 flops)\n",
      "  block5e_se_reduce/BiasAdd (30/30 flops)\n",
      "  block5e_se_reduce/mul (30/30 flops)\n",
      "  block5e_se_reduce/mul_1 (30/30 flops)\n",
      "  block5f_se_reduce/BiasAdd (30/30 flops)\n",
      "  block5f_se_reduce/mul (30/30 flops)\n",
      "  block5f_se_reduce/mul_1 (30/30 flops)\n",
      "  block6a_se_reduce/BiasAdd (30/30 flops)\n",
      "  block6a_se_reduce/mul (30/30 flops)\n",
      "  block6a_se_reduce/mul_1 (30/30 flops)\n",
      "  block4b_se_reduce/BiasAdd (26/26 flops)\n",
      "  block4b_se_reduce/mul (26/26 flops)\n",
      "  block4b_se_reduce/mul_1 (26/26 flops)\n",
      "  block4c_se_reduce/BiasAdd (26/26 flops)\n",
      "  block4c_se_reduce/mul (26/26 flops)\n",
      "  block4c_se_reduce/mul_1 (26/26 flops)\n",
      "  block4d_se_reduce/BiasAdd (26/26 flops)\n",
      "  block4d_se_reduce/mul (26/26 flops)\n",
      "  block4d_se_reduce/mul_1 (26/26 flops)\n",
      "  block5a_se_reduce/BiasAdd (26/26 flops)\n",
      "  block5a_se_reduce/mul (26/26 flops)\n",
      "  block5a_se_reduce/mul_1 (26/26 flops)\n",
      "  block4a_se_reduce/BiasAdd (14/14 flops)\n",
      "  block4a_se_reduce/mul (14/14 flops)\n",
      "  block4a_se_reduce/mul_1 (14/14 flops)\n",
      "  normalization_10/Maximum (3/3 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/16.81b flops)\n",
      "  block2b_expand_conv/Conv2D (1.53b/1.53b flops)\n",
      "  block2c_expand_conv/Conv2D (1.53b/1.53b flops)\n",
      "  block2d_expand_conv/Conv2D (1.53b/1.53b flops)\n",
      "  block3b_expand_conv/Conv2D (679.48m/679.48m flops)\n",
      "  block3c_expand_conv/Conv2D (679.48m/679.48m flops)\n",
      "  block3d_expand_conv/Conv2D (679.48m/679.48m flops)\n",
      "  block1a_project_conv/Conv2D (382.21m/382.21m flops)\n",
      "  block1b_project_conv/Conv2D (382.21m/382.21m flops)\n",
      "  block2a_expand_conv/Conv2D (382.21m/382.21m flops)\n",
      "  block3a_expand_conv/Conv2D (382.21m/382.21m flops)\n",
      "  block5b_expand_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block5b_project_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block5c_expand_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block5c_project_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block5d_expand_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block5d_project_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block5e_expand_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block5e_project_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block5f_expand_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block5f_project_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block5g_expand_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block5g_project_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block5h_expand_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block5h_project_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block5i_expand_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block5i_project_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block6a_expand_conv/Conv2D (176.95m/176.95m flops)\n",
      "  block2b_project_conv/Conv2D (169.87m/169.87m flops)\n",
      "  block2c_project_conv/Conv2D (169.87m/169.87m flops)\n",
      "  block2d_project_conv/Conv2D (169.87m/169.87m flops)\n",
      "  block5a_project_conv/Conv2D (141.56m/141.56m flops)\n",
      "  block5a_expand_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6b_expand_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6b_project_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6c_expand_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6c_project_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6d_expand_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6d_project_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6e_expand_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6e_project_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6f_expand_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6f_project_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6g_expand_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6g_project_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6h_expand_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6h_project_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6i_expand_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6i_project_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6j_expand_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6j_project_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6k_expand_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6k_project_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6l_expand_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6l_project_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6m_expand_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6m_project_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6n_expand_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6n_project_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6o_expand_conv/Conv2D (113.25m/113.25m flops)\n",
      "  block6o_project_conv/Conv2D (113.25m/113.25m flops)\n",
      "  top_conv/Conv2D (94.37m/94.37m flops)\n",
      "  block2a_project_conv/Conv2D (84.93m/84.93m flops)\n",
      "  block3b_project_conv/Conv2D (75.50m/75.50m flops)\n",
      "  block3c_project_conv/Conv2D (75.50m/75.50m flops)\n",
      "  block3d_project_conv/Conv2D (75.50m/75.50m flops)\n",
      "  block4a_expand_conv/Conv2D (75.50m/75.50m flops)\n",
      "  block4b_expand_conv/Conv2D (75.50m/75.50m flops)\n",
      "  block4b_project_conv/Conv2D (75.50m/75.50m flops)\n",
      "  block4c_expand_conv/Conv2D (75.50m/75.50m flops)\n",
      "  block4c_project_conv/Conv2D (75.50m/75.50m flops)\n",
      "  block4d_expand_conv/Conv2D (75.50m/75.50m flops)\n",
      "  block4d_project_conv/Conv2D (75.50m/75.50m flops)\n",
      "  block4e_expand_conv/Conv2D (75.50m/75.50m flops)\n",
      "  block4e_project_conv/Conv2D (75.50m/75.50m flops)\n",
      "  block4f_expand_conv/Conv2D (75.50m/75.50m flops)\n",
      "  block4f_project_conv/Conv2D (75.50m/75.50m flops)\n",
      "  block6a_project_conv/Conv2D (70.78m/70.78m flops)\n",
      "  block3a_project_conv/Conv2D (56.62m/56.62m flops)\n",
      "  stem_conv/Conv2D (47.78m/47.78m flops)\n",
      "  block4a_project_conv/Conv2D (37.75m/37.75m flops)\n",
      "  block5b_dwconv2/depthwise (9.95m/9.95m flops)\n",
      "  block5c_dwconv2/depthwise (9.95m/9.95m flops)\n",
      "  block5d_dwconv2/depthwise (9.95m/9.95m flops)\n",
      "  block5e_dwconv2/depthwise (9.95m/9.95m flops)\n",
      "  block5f_dwconv2/depthwise (9.95m/9.95m flops)\n",
      "  block5g_dwconv2/depthwise (9.95m/9.95m flops)\n",
      "  block5h_dwconv2/depthwise (9.95m/9.95m flops)\n",
      "  block5i_dwconv2/depthwise (9.95m/9.95m flops)\n",
      "  block5a_dwconv2/depthwise (7.96m/7.96m flops)\n",
      "  block4b_dwconv2/depthwise (5.31m/5.31m flops)\n",
      "  block4c_dwconv2/depthwise (5.31m/5.31m flops)\n",
      "  block4d_dwconv2/depthwise (5.31m/5.31m flops)\n",
      "  block4e_dwconv2/depthwise (5.31m/5.31m flops)\n",
      "  block4f_dwconv2/depthwise (5.31m/5.31m flops)\n",
      "  block6b_dwconv2/depthwise (3.98m/3.98m flops)\n",
      "  block6c_dwconv2/depthwise (3.98m/3.98m flops)\n",
      "  block6d_dwconv2/depthwise (3.98m/3.98m flops)\n",
      "  block6e_dwconv2/depthwise (3.98m/3.98m flops)\n",
      "  block6f_dwconv2/depthwise (3.98m/3.98m flops)\n",
      "  block6g_dwconv2/depthwise (3.98m/3.98m flops)\n",
      "  block6h_dwconv2/depthwise (3.98m/3.98m flops)\n",
      "  block6i_dwconv2/depthwise (3.98m/3.98m flops)\n",
      "  block6j_dwconv2/depthwise (3.98m/3.98m flops)\n",
      "  block6k_dwconv2/depthwise (3.98m/3.98m flops)\n",
      "  block6l_dwconv2/depthwise (3.98m/3.98m flops)\n",
      "  block6m_dwconv2/depthwise (3.98m/3.98m flops)\n",
      "  block6n_dwconv2/depthwise (3.98m/3.98m flops)\n",
      "  block6o_dwconv2/depthwise (3.98m/3.98m flops)\n",
      "  block4a_dwconv2/depthwise (2.65m/2.65m flops)\n",
      "  predictions/MatMul (2.56m/2.56m flops)\n",
      "  block6a_dwconv2/depthwise (2.49m/2.49m flops)\n",
      "  block2b_expand_activation/mul (1.77m/1.77m flops)\n",
      "  block2b_expand_activation/mul_1 (1.77m/1.77m flops)\n",
      "  block2c_expand_activation/mul (1.77m/1.77m flops)\n",
      "  block2c_expand_activation/mul_1 (1.77m/1.77m flops)\n",
      "  block2d_expand_activation/mul (1.77m/1.77m flops)\n",
      "  block2d_expand_activation/mul_1 (1.77m/1.77m flops)\n",
      "  block1a_project_activation/mul (884.74k/884.74k flops)\n",
      "  block1a_project_activation/mul_1 (884.74k/884.74k flops)\n",
      "  block1b_project_activation/mul (884.74k/884.74k flops)\n",
      "  block1b_project_activation/mul_1 (884.74k/884.74k flops)\n",
      "  block2a_expand_activation/mul (884.74k/884.74k flops)\n",
      "  block2a_expand_activation/mul_1 (884.74k/884.74k flops)\n",
      "  stem_activation/mul (884.74k/884.74k flops)\n",
      "  stem_activation/mul_1 (884.74k/884.74k flops)\n",
      "  block3b_expand_activation/mul (589.82k/589.82k flops)\n",
      "  block3b_expand_activation/mul_1 (589.82k/589.82k flops)\n",
      "  block3c_expand_activation/mul (589.82k/589.82k flops)\n",
      "  block3c_expand_activation/mul_1 (589.82k/589.82k flops)\n",
      "  block3d_expand_activation/mul (589.82k/589.82k flops)\n",
      "  block3d_expand_activation/mul_1 (589.82k/589.82k flops)\n",
      "  block4a_expand_activation/mul (589.82k/589.82k flops)\n",
      "  block4a_expand_activation/mul_1 (589.82k/589.82k flops)\n",
      "  block5b_activation/mul (552.96k/552.96k flops)\n",
      "  block5b_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block5b_expand_activation/mul (552.96k/552.96k flops)\n",
      "  block5b_expand_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block5b_se_excite/mul (552.96k/552.96k flops)\n",
      "  block5b_se_squeeze/Mean (552.96k/552.96k flops)\n",
      "  block5c_activation/mul (552.96k/552.96k flops)\n",
      "  block5c_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block5c_expand_activation/mul (552.96k/552.96k flops)\n",
      "  block5c_expand_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block5c_se_excite/mul (552.96k/552.96k flops)\n",
      "  block5c_se_squeeze/Mean (552.96k/552.96k flops)\n",
      "  block5d_activation/mul (552.96k/552.96k flops)\n",
      "  block5d_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block5d_expand_activation/mul (552.96k/552.96k flops)\n",
      "  block5d_expand_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block5d_se_excite/mul (552.96k/552.96k flops)\n",
      "  block5d_se_squeeze/Mean (552.96k/552.96k flops)\n",
      "  block5e_activation/mul (552.96k/552.96k flops)\n",
      "  block5e_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block5e_expand_activation/mul (552.96k/552.96k flops)\n",
      "  block5e_expand_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block5e_se_excite/mul (552.96k/552.96k flops)\n",
      "  block5e_se_squeeze/Mean (552.96k/552.96k flops)\n",
      "  block5f_activation/mul (552.96k/552.96k flops)\n",
      "  block5f_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block5f_expand_activation/mul (552.96k/552.96k flops)\n",
      "  block5f_expand_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block5f_se_excite/mul (552.96k/552.96k flops)\n",
      "  block5f_se_squeeze/Mean (552.96k/552.96k flops)\n",
      "  block5g_activation/mul (552.96k/552.96k flops)\n",
      "  block5g_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block5g_expand_activation/mul (552.96k/552.96k flops)\n",
      "  block5g_expand_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block5g_se_excite/mul (552.96k/552.96k flops)\n",
      "  block5g_se_squeeze/Mean (552.96k/552.96k flops)\n",
      "  block5h_activation/mul (552.96k/552.96k flops)\n",
      "  block5h_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block5h_expand_activation/mul (552.96k/552.96k flops)\n",
      "  block5h_expand_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block5h_se_excite/mul (552.96k/552.96k flops)\n",
      "  block5h_se_squeeze/Mean (552.96k/552.96k flops)\n",
      "  block5i_activation/mul (552.96k/552.96k flops)\n",
      "  block5i_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block5i_expand_activation/mul (552.96k/552.96k flops)\n",
      "  block5i_expand_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block5i_se_excite/mul (552.96k/552.96k flops)\n",
      "  block5i_se_squeeze/Mean (552.96k/552.96k flops)\n",
      "  block6a_expand_activation/mul (552.96k/552.96k flops)\n",
      "  block6a_expand_activation/mul_1 (552.96k/552.96k flops)\n",
      "  block3a_expand_activation/mul (442.37k/442.37k flops)\n",
      "  block3a_expand_activation/mul_1 (442.37k/442.37k flops)\n",
      "  block5a_activation/mul (442.37k/442.37k flops)\n",
      "  block5a_activation/mul_1 (442.37k/442.37k flops)\n",
      "  block5a_expand_activation/mul (442.37k/442.37k flops)\n",
      "  block5a_expand_activation/mul_1 (442.37k/442.37k flops)\n",
      "  block5a_se_excite/mul (442.37k/442.37k flops)\n",
      "  block5a_se_squeeze/Mean (442.37k/442.37k flops)\n",
      "  rescaling_14/mul (442.37k/442.37k flops)\n",
      "  block4b_activation/mul (294.91k/294.91k flops)\n",
      "  block4b_activation/mul_1 (294.91k/294.91k flops)\n",
      "  block4b_expand_activation/mul (294.91k/294.91k flops)\n",
      "  block4b_expand_activation/mul_1 (294.91k/294.91k flops)\n",
      "  block4b_se_excite/mul (294.91k/294.91k flops)\n",
      "  block4b_se_squeeze/Mean (294.91k/294.91k flops)\n",
      "  block4c_activation/mul (294.91k/294.91k flops)\n",
      "  block4c_activation/mul_1 (294.91k/294.91k flops)\n",
      "  block4c_expand_activation/mul (294.91k/294.91k flops)\n",
      "  block4c_expand_activation/mul_1 (294.91k/294.91k flops)\n",
      "  block4c_se_excite/mul (294.91k/294.91k flops)\n",
      "  block4c_se_squeeze/Mean (294.91k/294.91k flops)\n",
      "  block4d_activation/mul (294.91k/294.91k flops)\n",
      "  block4d_activation/mul_1 (294.91k/294.91k flops)\n",
      "  block4d_expand_activation/mul (294.91k/294.91k flops)\n",
      "  block4d_expand_activation/mul_1 (294.91k/294.91k flops)\n",
      "  block4d_se_excite/mul (294.91k/294.91k flops)\n",
      "  block4d_se_squeeze/Mean (294.91k/294.91k flops)\n",
      "  block4e_activation/mul (294.91k/294.91k flops)\n",
      "  block4e_activation/mul_1 (294.91k/294.91k flops)\n",
      "  block4e_expand_activation/mul (294.91k/294.91k flops)\n",
      "  block4e_expand_activation/mul_1 (294.91k/294.91k flops)\n",
      "  block4e_se_excite/mul (294.91k/294.91k flops)\n",
      "  block4e_se_squeeze/Mean (294.91k/294.91k flops)\n",
      "  block4f_activation/mul (294.91k/294.91k flops)\n",
      "  block4f_activation/mul_1 (294.91k/294.91k flops)\n",
      "  block4f_expand_activation/mul (294.91k/294.91k flops)\n",
      "  block4f_expand_activation/mul_1 (294.91k/294.91k flops)\n",
      "  block4f_se_excite/mul (294.91k/294.91k flops)\n",
      "  block4f_se_squeeze/Mean (294.91k/294.91k flops)\n",
      "  block6b_activation/mul (221.18k/221.18k flops)\n",
      "  block6b_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6b_expand_activation/mul (221.18k/221.18k flops)\n",
      "  block6b_expand_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6b_se_excite/mul (221.18k/221.18k flops)\n",
      "  block6b_se_squeeze/Mean (221.18k/221.18k flops)\n",
      "  block6c_activation/mul (221.18k/221.18k flops)\n",
      "  block6c_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6c_expand_activation/mul (221.18k/221.18k flops)\n",
      "  block6c_expand_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6c_se_excite/mul (221.18k/221.18k flops)\n",
      "  block6c_se_squeeze/Mean (221.18k/221.18k flops)\n",
      "  block6d_activation/mul (221.18k/221.18k flops)\n",
      "  block6d_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6d_expand_activation/mul (221.18k/221.18k flops)\n",
      "  block6d_expand_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6d_se_excite/mul (221.18k/221.18k flops)\n",
      "  block6d_se_squeeze/Mean (221.18k/221.18k flops)\n",
      "  block6e_activation/mul (221.18k/221.18k flops)\n",
      "  block6e_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6e_expand_activation/mul (221.18k/221.18k flops)\n",
      "  block6e_expand_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6e_se_excite/mul (221.18k/221.18k flops)\n",
      "  block6e_se_squeeze/Mean (221.18k/221.18k flops)\n",
      "  block6f_activation/mul (221.18k/221.18k flops)\n",
      "  block6f_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6f_expand_activation/mul (221.18k/221.18k flops)\n",
      "  block6f_expand_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6f_se_excite/mul (221.18k/221.18k flops)\n",
      "  block6f_se_squeeze/Mean (221.18k/221.18k flops)\n",
      "  block6g_activation/mul (221.18k/221.18k flops)\n",
      "  block6g_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6g_expand_activation/mul (221.18k/221.18k flops)\n",
      "  block6g_expand_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6g_se_excite/mul (221.18k/221.18k flops)\n",
      "  block6g_se_squeeze/Mean (221.18k/221.18k flops)\n",
      "  block6h_activation/mul (221.18k/221.18k flops)\n",
      "  block6h_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6h_expand_activation/mul (221.18k/221.18k flops)\n",
      "  block6h_expand_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6h_se_excite/mul (221.18k/221.18k flops)\n",
      "  block6h_se_squeeze/Mean (221.18k/221.18k flops)\n",
      "  block6i_activation/mul (221.18k/221.18k flops)\n",
      "  block6i_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6i_expand_activation/mul (221.18k/221.18k flops)\n",
      "  block6i_expand_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6i_se_excite/mul (221.18k/221.18k flops)\n",
      "  block6i_se_squeeze/Mean (221.18k/221.18k flops)\n",
      "  block6j_activation/mul (221.18k/221.18k flops)\n",
      "  block6j_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6j_expand_activation/mul (221.18k/221.18k flops)\n",
      "  block6j_expand_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6j_se_excite/mul (221.18k/221.18k flops)\n",
      "  block6j_se_squeeze/Mean (221.18k/221.18k flops)\n",
      "  block6k_activation/mul (221.18k/221.18k flops)\n",
      "  block6k_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6k_expand_activation/mul (221.18k/221.18k flops)\n",
      "  block6k_expand_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6k_se_excite/mul (221.18k/221.18k flops)\n",
      "  block6k_se_squeeze/Mean (221.18k/221.18k flops)\n",
      "  block6l_activation/mul (221.18k/221.18k flops)\n",
      "  block6l_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6l_expand_activation/mul (221.18k/221.18k flops)\n",
      "  block6l_expand_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6l_se_excite/mul (221.18k/221.18k flops)\n",
      "  block6l_se_squeeze/Mean (221.18k/221.18k flops)\n",
      "  block6m_activation/mul (221.18k/221.18k flops)\n",
      "  block6m_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6m_expand_activation/mul (221.18k/221.18k flops)\n",
      "  block6m_expand_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6m_se_excite/mul (221.18k/221.18k flops)\n",
      "  block6m_se_squeeze/Mean (221.18k/221.18k flops)\n",
      "  block6n_activation/mul (221.18k/221.18k flops)\n",
      "  block6n_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6n_expand_activation/mul (221.18k/221.18k flops)\n",
      "  block6n_expand_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6n_se_excite/mul (221.18k/221.18k flops)\n",
      "  block6n_se_squeeze/Mean (221.18k/221.18k flops)\n",
      "  block6o_activation/mul (221.18k/221.18k flops)\n",
      "  block6o_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6o_expand_activation/mul (221.18k/221.18k flops)\n",
      "  block6o_expand_activation/mul_1 (221.18k/221.18k flops)\n",
      "  block6o_se_excite/mul (221.18k/221.18k flops)\n",
      "  block6o_se_squeeze/Mean (221.18k/221.18k flops)\n",
      "  block6b_se_expand/Conv2D (196.61k/196.61k flops)\n",
      "  block6b_se_reduce/Conv2D (196.61k/196.61k flops)\n",
      "  block6c_se_expand/Conv2D (196.61k/196.61k flops)\n",
      "  block6c_se_reduce/Conv2D (196.61k/196.61k flops)\n",
      "  block6d_se_expand/Conv2D (196.61k/196.61k flops)\n",
      "  block6d_se_reduce/Conv2D (196.61k/196.61k flops)\n",
      "  block6e_se_expand/Conv2D (196.61k/196.61k flops)\n",
      "  block6e_se_reduce/Conv2D (196.61k/196.61k flops)\n",
      "  block6f_se_expand/Conv2D (196.61k/196.61k flops)\n",
      "  block6f_se_reduce/Conv2D (196.61k/196.61k flops)\n",
      "  block6g_se_expand/Conv2D (196.61k/196.61k flops)\n",
      "  block6g_se_reduce/Conv2D (196.61k/196.61k flops)\n",
      "  block6h_se_expand/Conv2D (196.61k/196.61k flops)\n",
      "  block6h_se_reduce/Conv2D (196.61k/196.61k flops)\n",
      "  block6i_se_expand/Conv2D (196.61k/196.61k flops)\n",
      "  block6i_se_reduce/Conv2D (196.61k/196.61k flops)\n",
      "  block6j_se_expand/Conv2D (196.61k/196.61k flops)\n",
      "  block6j_se_reduce/Conv2D (196.61k/196.61k flops)\n",
      "  block6k_se_expand/Conv2D (196.61k/196.61k flops)\n",
      "  block6k_se_reduce/Conv2D (196.61k/196.61k flops)\n",
      "  block6l_se_expand/Conv2D (196.61k/196.61k flops)\n",
      "  block6l_se_reduce/Conv2D (196.61k/196.61k flops)\n",
      "  block6m_se_expand/Conv2D (196.61k/196.61k flops)\n",
      "  block6m_se_reduce/Conv2D (196.61k/196.61k flops)\n",
      "  block6n_se_expand/Conv2D (196.61k/196.61k flops)\n",
      "  block6n_se_reduce/Conv2D (196.61k/196.61k flops)\n",
      "  block6o_se_expand/Conv2D (196.61k/196.61k flops)\n",
      "  block6o_se_reduce/Conv2D (196.61k/196.61k flops)\n",
      "  avg_pool/Mean (184.32k/184.32k flops)\n",
      "  top_activation/mul (184.32k/184.32k flops)\n",
      "  top_activation/mul_1 (184.32k/184.32k flops)\n",
      "  block4a_activation/mul (147.46k/147.46k flops)\n",
      "  block4a_activation/mul_1 (147.46k/147.46k flops)\n",
      "  block4a_se_excite/mul (147.46k/147.46k flops)\n",
      "  block4a_se_squeeze/Mean (147.46k/147.46k flops)\n",
      "  block6a_activation/mul (138.24k/138.24k flops)\n",
      "  block6a_activation/mul_1 (138.24k/138.24k flops)\n",
      "  block6a_se_excite/mul (138.24k/138.24k flops)\n",
      "  block6a_se_squeeze/Mean (138.24k/138.24k flops)\n",
      "  block5b_se_expand/Conv2D (76.80k/76.80k flops)\n",
      "  block5b_se_reduce/Conv2D (76.80k/76.80k flops)\n",
      "  block5c_se_expand/Conv2D (76.80k/76.80k flops)\n",
      "  block5c_se_reduce/Conv2D (76.80k/76.80k flops)\n",
      "  block5d_se_expand/Conv2D (76.80k/76.80k flops)\n",
      "  block5d_se_reduce/Conv2D (76.80k/76.80k flops)\n",
      "  block5e_se_expand/Conv2D (76.80k/76.80k flops)\n",
      "  block5e_se_reduce/Conv2D (76.80k/76.80k flops)\n",
      "  block5f_se_expand/Conv2D (76.80k/76.80k flops)\n",
      "  block5f_se_reduce/Conv2D (76.80k/76.80k flops)\n",
      "  block5g_se_expand/Conv2D (76.80k/76.80k flops)\n",
      "  block5g_se_reduce/Conv2D (76.80k/76.80k flops)\n",
      "  block5h_se_expand/Conv2D (76.80k/76.80k flops)\n",
      "  block5h_se_reduce/Conv2D (76.80k/76.80k flops)\n",
      "  block5i_se_expand/Conv2D (76.80k/76.80k flops)\n",
      "  block5i_se_reduce/Conv2D (76.80k/76.80k flops)\n",
      "  block6a_se_expand/Conv2D (76.80k/76.80k flops)\n",
      "  block6a_se_reduce/Conv2D (76.80k/76.80k flops)\n",
      "  block5a_se_expand/Conv2D (49.15k/49.15k flops)\n",
      "  block5a_se_reduce/Conv2D (49.15k/49.15k flops)\n",
      "  block4b_se_expand/Conv2D (32.77k/32.77k flops)\n",
      "  block4b_se_reduce/Conv2D (32.77k/32.77k flops)\n",
      "  block4c_se_expand/Conv2D (32.77k/32.77k flops)\n",
      "  block4c_se_reduce/Conv2D (32.77k/32.77k flops)\n",
      "  block4d_se_expand/Conv2D (32.77k/32.77k flops)\n",
      "  block4d_se_reduce/Conv2D (32.77k/32.77k flops)\n",
      "  block4e_se_expand/Conv2D (32.77k/32.77k flops)\n",
      "  block4e_se_reduce/Conv2D (32.77k/32.77k flops)\n",
      "  block4f_se_expand/Conv2D (32.77k/32.77k flops)\n",
      "  block4f_se_reduce/Conv2D (32.77k/32.77k flops)\n",
      "  block4a_se_expand/Conv2D (8.19k/8.19k flops)\n",
      "  block4a_se_reduce/Conv2D (8.19k/8.19k flops)\n",
      "  predictions/Softmax (5.00k/5.00k flops)\n",
      "  block6b_se_expand/BiasAdd (1.54k/1.54k flops)\n",
      "  block6c_se_expand/BiasAdd (1.54k/1.54k flops)\n",
      "  block6d_se_expand/BiasAdd (1.54k/1.54k flops)\n",
      "  block6e_se_expand/BiasAdd (1.54k/1.54k flops)\n",
      "  block6f_se_expand/BiasAdd (1.54k/1.54k flops)\n",
      "  block6g_se_expand/BiasAdd (1.54k/1.54k flops)\n",
      "  block6h_se_expand/BiasAdd (1.54k/1.54k flops)\n",
      "  block6i_se_expand/BiasAdd (1.54k/1.54k flops)\n",
      "  block6j_se_expand/BiasAdd (1.54k/1.54k flops)\n",
      "  block6k_se_expand/BiasAdd (1.54k/1.54k flops)\n",
      "  block6l_se_expand/BiasAdd (1.54k/1.54k flops)\n",
      "  block6m_se_expand/BiasAdd (1.54k/1.54k flops)\n",
      "  block6n_se_expand/BiasAdd (1.54k/1.54k flops)\n",
      "  block6o_se_expand/BiasAdd (1.54k/1.54k flops)\n",
      "  predictions/BiasAdd (1.00k/1.00k flops)\n",
      "  block5b_se_expand/BiasAdd (960/960 flops)\n",
      "  block5c_se_expand/BiasAdd (960/960 flops)\n",
      "  block5d_se_expand/BiasAdd (960/960 flops)\n",
      "  block5e_se_expand/BiasAdd (960/960 flops)\n",
      "  block5f_se_expand/BiasAdd (960/960 flops)\n",
      "  block5g_se_expand/BiasAdd (960/960 flops)\n",
      "  block5h_se_expand/BiasAdd (960/960 flops)\n",
      "  block5i_se_expand/BiasAdd (960/960 flops)\n",
      "  block6a_se_expand/BiasAdd (960/960 flops)\n",
      "  block5a_se_expand/BiasAdd (768/768 flops)\n",
      "  block4b_se_expand/BiasAdd (512/512 flops)\n",
      "  block4c_se_expand/BiasAdd (512/512 flops)\n",
      "  block4d_se_expand/BiasAdd (512/512 flops)\n",
      "  block4e_se_expand/BiasAdd (512/512 flops)\n",
      "  block4f_se_expand/BiasAdd (512/512 flops)\n",
      "  block4a_se_expand/BiasAdd (256/256 flops)\n",
      "  block6b_se_reduce/BiasAdd (64/64 flops)\n",
      "  block6b_se_reduce/mul (64/64 flops)\n",
      "  block6b_se_reduce/mul_1 (64/64 flops)\n",
      "  block6c_se_reduce/BiasAdd (64/64 flops)\n",
      "  block6c_se_reduce/mul (64/64 flops)\n",
      "  block6c_se_reduce/mul_1 (64/64 flops)\n",
      "  block6d_se_reduce/BiasAdd (64/64 flops)\n",
      "  block6d_se_reduce/mul (64/64 flops)\n",
      "  block6d_se_reduce/mul_1 (64/64 flops)\n",
      "  block6e_se_reduce/BiasAdd (64/64 flops)\n",
      "  block6e_se_reduce/mul (64/64 flops)\n",
      "  block6e_se_reduce/mul_1 (64/64 flops)\n",
      "  block6f_se_reduce/BiasAdd (64/64 flops)\n",
      "  block6f_se_reduce/mul (64/64 flops)\n",
      "  block6f_se_reduce/mul_1 (64/64 flops)\n",
      "  block6g_se_reduce/BiasAdd (64/64 flops)\n",
      "  block6g_se_reduce/mul (64/64 flops)\n",
      "  block6g_se_reduce/mul_1 (64/64 flops)\n",
      "  block6h_se_reduce/BiasAdd (64/64 flops)\n",
      "  block6h_se_reduce/mul (64/64 flops)\n",
      "  block6h_se_reduce/mul_1 (64/64 flops)\n",
      "  block6i_se_reduce/BiasAdd (64/64 flops)\n",
      "  block6i_se_reduce/mul (64/64 flops)\n",
      "  block6i_se_reduce/mul_1 (64/64 flops)\n",
      "  block6j_se_reduce/BiasAdd (64/64 flops)\n",
      "  block6j_se_reduce/mul (64/64 flops)\n",
      "  block6j_se_reduce/mul_1 (64/64 flops)\n",
      "  block6k_se_reduce/BiasAdd (64/64 flops)\n",
      "  block6k_se_reduce/mul (64/64 flops)\n",
      "  block6k_se_reduce/mul_1 (64/64 flops)\n",
      "  block6l_se_reduce/BiasAdd (64/64 flops)\n",
      "  block6l_se_reduce/mul (64/64 flops)\n",
      "  block6l_se_reduce/mul_1 (64/64 flops)\n",
      "  block6m_se_reduce/BiasAdd (64/64 flops)\n",
      "  block6m_se_reduce/mul (64/64 flops)\n",
      "  block6m_se_reduce/mul_1 (64/64 flops)\n",
      "  block6n_se_reduce/BiasAdd (64/64 flops)\n",
      "  block6n_se_reduce/mul (64/64 flops)\n",
      "  block6n_se_reduce/mul_1 (64/64 flops)\n",
      "  block6o_se_reduce/BiasAdd (64/64 flops)\n",
      "  block6o_se_reduce/mul (64/64 flops)\n",
      "  block6o_se_reduce/mul_1 (64/64 flops)\n",
      "  block5b_se_reduce/BiasAdd (40/40 flops)\n",
      "  block5b_se_reduce/mul (40/40 flops)\n",
      "  block5b_se_reduce/mul_1 (40/40 flops)\n",
      "  block5c_se_reduce/BiasAdd (40/40 flops)\n",
      "  block5c_se_reduce/mul (40/40 flops)\n",
      "  block5c_se_reduce/mul_1 (40/40 flops)\n",
      "  block5d_se_reduce/BiasAdd (40/40 flops)\n",
      "  block5d_se_reduce/mul (40/40 flops)\n",
      "  block5d_se_reduce/mul_1 (40/40 flops)\n",
      "  block5e_se_reduce/BiasAdd (40/40 flops)\n",
      "  block5e_se_reduce/mul (40/40 flops)\n",
      "  block5e_se_reduce/mul_1 (40/40 flops)\n",
      "  block5f_se_reduce/BiasAdd (40/40 flops)\n",
      "  block5f_se_reduce/mul (40/40 flops)\n",
      "  block5f_se_reduce/mul_1 (40/40 flops)\n",
      "  block5g_se_reduce/BiasAdd (40/40 flops)\n",
      "  block5g_se_reduce/mul (40/40 flops)\n",
      "  block5g_se_reduce/mul_1 (40/40 flops)\n",
      "  block5h_se_reduce/BiasAdd (40/40 flops)\n",
      "  block5h_se_reduce/mul (40/40 flops)\n",
      "  block5h_se_reduce/mul_1 (40/40 flops)\n",
      "  block5i_se_reduce/BiasAdd (40/40 flops)\n",
      "  block5i_se_reduce/mul (40/40 flops)\n",
      "  block5i_se_reduce/mul_1 (40/40 flops)\n",
      "  block6a_se_reduce/BiasAdd (40/40 flops)\n",
      "  block6a_se_reduce/mul (40/40 flops)\n",
      "  block6a_se_reduce/mul_1 (40/40 flops)\n",
      "  block4b_se_reduce/BiasAdd (32/32 flops)\n",
      "  block4b_se_reduce/mul (32/32 flops)\n",
      "  block4b_se_reduce/mul_1 (32/32 flops)\n",
      "  block4c_se_reduce/BiasAdd (32/32 flops)\n",
      "  block4c_se_reduce/mul (32/32 flops)\n",
      "  block4c_se_reduce/mul_1 (32/32 flops)\n",
      "  block4d_se_reduce/BiasAdd (32/32 flops)\n",
      "  block4d_se_reduce/mul (32/32 flops)\n",
      "  block4d_se_reduce/mul_1 (32/32 flops)\n",
      "  block4e_se_reduce/BiasAdd (32/32 flops)\n",
      "  block4e_se_reduce/mul (32/32 flops)\n",
      "  block4e_se_reduce/mul_1 (32/32 flops)\n",
      "  block4f_se_reduce/BiasAdd (32/32 flops)\n",
      "  block4f_se_reduce/mul (32/32 flops)\n",
      "  block4f_se_reduce/mul_1 (32/32 flops)\n",
      "  block5a_se_reduce/BiasAdd (32/32 flops)\n",
      "  block5a_se_reduce/mul (32/32 flops)\n",
      "  block5a_se_reduce/mul_1 (32/32 flops)\n",
      "  block4a_se_reduce/BiasAdd (16/16 flops)\n",
      "  block4a_se_reduce/mul (16/16 flops)\n",
      "  block4a_se_reduce/mul_1 (16/16 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/11.45b flops)\n",
      "  conv2d_207/Conv2D (1.39b/1.39b flops)\n",
      "  conv2d_205/Conv2D (796.59m/796.59m flops)\n",
      "  conv2d_229/Conv2D (575.30m/575.30m flops)\n",
      "  conv2d_204/Conv2D (398.30m/398.30m flops)\n",
      "  conv2d_213/Conv2D (203.21m/203.21m flops)\n",
      "  conv2d_220/Conv2D (203.21m/203.21m flops)\n",
      "  conv2d_227/Conv2D (203.21m/203.21m flops)\n",
      "  conv2d_284/Conv2D (198.18m/198.18m flops)\n",
      "  conv2d_293/Conv2D (198.18m/198.18m flops)\n",
      "  conv2d_210/Conv2D (188.16m/188.16m flops)\n",
      "  conv2d_217/Conv2D (188.16m/188.16m flops)\n",
      "  conv2d_224/Conv2D (188.16m/188.16m flops)\n",
      "  conv2d_265/Conv2D (149.15m/149.15m flops)\n",
      "  conv2d_266/Conv2D (149.15m/149.15m flops)\n",
      "  conv2d_268/Conv2D (149.15m/149.15m flops)\n",
      "  conv2d_269/Conv2D (149.15m/149.15m flops)\n",
      "  conv2d_270/Conv2D (149.15m/149.15m flops)\n",
      "  conv2d_271/Conv2D (149.15m/149.15m flops)\n",
      "  conv2d_276/Conv2D (149.15m/149.15m flops)\n",
      "  conv2d_277/Conv2D (149.15m/149.15m flops)\n",
      "  conv2d_212/Conv2D (135.48m/135.48m flops)\n",
      "  conv2d_219/Conv2D (135.48m/135.48m flops)\n",
      "  conv2d_226/Conv2D (135.48m/135.48m flops)\n",
      "  conv2d_231/Conv2D (135.48m/135.48m flops)\n",
      "  conv2d_246/Conv2D (124.29m/124.29m flops)\n",
      "  conv2d_251/Conv2D (124.29m/124.29m flops)\n",
      "  conv2d_256/Conv2D (124.29m/124.29m flops)\n",
      "  conv2d_261/Conv2D (124.29m/124.29m flops)\n",
      "  conv2d_292/Conv2D (117.44m/117.44m flops)\n",
      "  conv2d_245/Conv2D (103.58m/103.58m flops)\n",
      "  conv2d_248/Conv2D (103.58m/103.58m flops)\n",
      "  conv2d_249/Conv2D (103.58m/103.58m flops)\n",
      "  conv2d_250/Conv2D (103.58m/103.58m flops)\n",
      "  conv2d_255/Conv2D (103.58m/103.58m flops)\n",
      "  conv2d_258/Conv2D (103.58m/103.58m flops)\n",
      "  conv2d_259/Conv2D (103.58m/103.58m flops)\n",
      "  conv2d_260/Conv2D (103.58m/103.58m flops)\n",
      "  conv2d_289/Conv2D (100.66m/100.66m flops)\n",
      "  conv2d_236/Conv2D (99.43m/99.43m flops)\n",
      "  conv2d_241/Conv2D (99.43m/99.43m flops)\n",
      "  conv2d_233/Conv2D (85.23m/85.23m flops)\n",
      "  conv2d_242/Conv2D (85.23m/85.23m flops)\n",
      "  conv2d_243/Conv2D (85.23m/85.23m flops)\n",
      "  conv2d_252/Conv2D (85.23m/85.23m flops)\n",
      "  conv2d_253/Conv2D (85.23m/85.23m flops)\n",
      "  conv2d_262/Conv2D (85.23m/85.23m flops)\n",
      "  conv2d_263/Conv2D (85.23m/85.23m flops)\n",
      "  conv2d_264/Conv2D (85.23m/85.23m flops)\n",
      "  conv2d_267/Conv2D (85.23m/85.23m flops)\n",
      "  conv2d_272/Conv2D (85.23m/85.23m flops)\n",
      "  conv2d_273/Conv2D (85.23m/85.23m flops)\n",
      "  conv2d_275/Conv2D (85.23m/85.23m flops)\n",
      "  conv2d_288/Conv2D (83.89m/83.89m flops)\n",
      "  conv2d_283/Conv2D (73.40m/73.40m flops)\n",
      "  conv2d_244/Conv2D (71.02m/71.02m flops)\n",
      "  conv2d_247/Conv2D (71.02m/71.02m flops)\n",
      "  conv2d_254/Conv2D (71.02m/71.02m flops)\n",
      "  conv2d_257/Conv2D (71.02m/71.02m flops)\n",
      "  conv2d_274/Conv2D (70.78m/70.78m flops)\n",
      "  conv2d_235/Conv2D (66.29m/66.29m flops)\n",
      "  conv2d_238/Conv2D (66.29m/66.29m flops)\n",
      "  conv2d_239/Conv2D (66.29m/66.29m flops)\n",
      "  conv2d_240/Conv2D (66.29m/66.29m flops)\n",
      "  conv2d_280/Conv2D (62.91m/62.91m flops)\n",
      "  conv2d_234/Conv2D (56.82m/56.82m flops)\n",
      "  conv2d_237/Conv2D (56.82m/56.82m flops)\n",
      "  conv2d_281/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_282/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_285/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_286/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_290/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_291/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_294/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_295/Conv2D (56.62m/56.62m flops)\n",
      "  conv2d_206/Conv2D (54.57m/54.57m flops)\n",
      "  conv2d_279/Conv2D (52.43m/52.43m flops)\n",
      "  conv2d_296/Conv2D (50.33m/50.33m flops)\n",
      "  conv2d_232/Conv2D (47.94m/47.94m flops)\n",
      "  conv2d_222/Conv2D (45.16m/45.16m flops)\n",
      "  conv2d_225/Conv2D (45.16m/45.16m flops)\n",
      "  conv2d_228/Conv2D (45.16m/45.16m flops)\n",
      "  conv2d_230/Conv2D (45.16m/45.16m flops)\n",
      "  conv2d_278/Conv2D (42.47m/42.47m flops)\n",
      "  conv2d_215/Conv2D (40.14m/40.14m flops)\n",
      "  conv2d_218/Conv2D (40.14m/40.14m flops)\n",
      "  conv2d_221/Conv2D (40.14m/40.14m flops)\n",
      "  conv2d_203/Conv2D (38.36m/38.36m flops)\n",
      "  conv2d_223/Conv2D (33.87m/33.87m flops)\n",
      "  conv2d_287/Conv2D (31.46m/31.46m flops)\n",
      "  conv2d_208/Conv2D (30.11m/30.11m flops)\n",
      "  conv2d_211/Conv2D (30.11m/30.11m flops)\n",
      "  conv2d_216/Conv2D (30.11m/30.11m flops)\n",
      "  conv2d_209/Conv2D (22.58m/22.58m flops)\n",
      "  conv2d_214/Conv2D (15.05m/15.05m flops)\n",
      "  predictions/MatMul (4.10m/4.10m flops)\n",
      "  average_pooling2d_3/AvgPool (3.18m/3.18m flops)\n",
      "  max_pooling2d_4/MaxPool (3.07m/3.07m flops)\n",
      "  average_pooling2d_2/AvgPool (2.82m/2.82m flops)\n",
      "  average_pooling2d_1/AvgPool (2.12m/2.12m flops)\n",
      "  max_pooling2d_5/MaxPool (2.12m/2.12m flops)\n",
      "  average_pooling2d_4/AvgPool (2.00m/2.00m flops)\n",
      "  average_pooling2d_5/AvgPool (2.00m/2.00m flops)\n",
      "  average_pooling2d_6/AvgPool (2.00m/2.00m flops)\n",
      "  average_pooling2d_7/AvgPool (2.00m/2.00m flops)\n",
      "  average_pooling2d_9/AvgPool (1.18m/1.18m flops)\n",
      "  max_pooling2d_6/MaxPool (749.09k/749.09k flops)\n",
      "  average_pooling2d_8/AvgPool (737.28k/737.28k flops)\n",
      "  max_pooling2d_7/MaxPool (442.37k/442.37k flops)\n",
      "  avg_pool/Mean (131.07k/131.07k flops)\n",
      "  predictions/Softmax (5.00k/5.00k flops)\n",
      "  predictions/BiasAdd (1.00k/1.00k flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/1.14b flops)\n",
      "  conv_pw_10/Conv2D (102.76m/102.76m flops)\n",
      "  conv_pw_11/Conv2D (102.76m/102.76m flops)\n",
      "  conv_pw_13/Conv2D (102.76m/102.76m flops)\n",
      "  conv_pw_3/Conv2D (102.76m/102.76m flops)\n",
      "  conv_pw_5/Conv2D (102.76m/102.76m flops)\n",
      "  conv_pw_7/Conv2D (102.76m/102.76m flops)\n",
      "  conv_pw_8/Conv2D (102.76m/102.76m flops)\n",
      "  conv_pw_9/Conv2D (102.76m/102.76m flops)\n",
      "  conv_pw_1/Conv2D (51.38m/51.38m flops)\n",
      "  conv_pw_12/Conv2D (51.38m/51.38m flops)\n",
      "  conv_pw_2/Conv2D (51.38m/51.38m flops)\n",
      "  conv_pw_4/Conv2D (51.38m/51.38m flops)\n",
      "  conv_pw_6/Conv2D (51.38m/51.38m flops)\n",
      "  conv1/Conv2D (21.68m/21.68m flops)\n",
      "  conv_dw_1/depthwise (7.23m/7.23m flops)\n",
      "  conv_dw_3/depthwise (7.23m/7.23m flops)\n",
      "  conv_dw_2/depthwise (3.61m/3.61m flops)\n",
      "  conv_dw_5/depthwise (3.61m/3.61m flops)\n",
      "  conv_preds/Conv2D (2.05m/2.05m flops)\n",
      "  conv_dw_10/depthwise (1.81m/1.81m flops)\n",
      "  conv_dw_11/depthwise (1.81m/1.81m flops)\n",
      "  conv_dw_4/depthwise (1.81m/1.81m flops)\n",
      "  conv_dw_7/depthwise (1.81m/1.81m flops)\n",
      "  conv_dw_8/depthwise (1.81m/1.81m flops)\n",
      "  conv_dw_9/depthwise (1.81m/1.81m flops)\n",
      "  conv_dw_13/depthwise (903.17k/903.17k flops)\n",
      "  conv_dw_6/depthwise (903.17k/903.17k flops)\n",
      "  conv_dw_12/depthwise (451.58k/451.58k flops)\n",
      "  global_average_pooling2d/Mean (50.18k/50.18k flops)\n",
      "  predictions/Softmax (5.00k/5.00k flops)\n",
      "  conv_preds/BiasAdd (1.00k/1.00k flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/601.62m flops)\n",
      "  Conv_1/Conv2D (40.14m/40.14m flops)\n",
      "  block_1_expand/Conv2D (38.54m/38.54m flops)\n",
      "  block_16_project/Conv2D (30.11m/30.11m flops)\n",
      "  Conv1/Conv2D (21.68m/21.68m flops)\n",
      "  block_11_expand/Conv2D (21.68m/21.68m flops)\n",
      "  block_11_project/Conv2D (21.68m/21.68m flops)\n",
      "  block_12_expand/Conv2D (21.68m/21.68m flops)\n",
      "  block_12_project/Conv2D (21.68m/21.68m flops)\n",
      "  block_13_expand/Conv2D (21.68m/21.68m flops)\n",
      "  block_2_expand/Conv2D (21.68m/21.68m flops)\n",
      "  block_2_project/Conv2D (21.68m/21.68m flops)\n",
      "  block_3_expand/Conv2D (21.68m/21.68m flops)\n",
      "  block_14_expand/Conv2D (15.05m/15.05m flops)\n",
      "  block_14_project/Conv2D (15.05m/15.05m flops)\n",
      "  block_15_expand/Conv2D (15.05m/15.05m flops)\n",
      "  block_15_project/Conv2D (15.05m/15.05m flops)\n",
      "  block_16_expand/Conv2D (15.05m/15.05m flops)\n",
      "  block_10_project/Conv2D (14.45m/14.45m flops)\n",
      "  block_1_project/Conv2D (14.45m/14.45m flops)\n",
      "  expanded_conv_project/Conv2D (12.85m/12.85m flops)\n",
      "  block_10_expand/Conv2D (9.63m/9.63m flops)\n",
      "  block_4_expand/Conv2D (9.63m/9.63m flops)\n",
      "  block_4_project/Conv2D (9.63m/9.63m flops)\n",
      "  block_5_expand/Conv2D (9.63m/9.63m flops)\n",
      "  block_5_project/Conv2D (9.63m/9.63m flops)\n",
      "  block_6_expand/Conv2D (9.63m/9.63m flops)\n",
      "  block_7_expand/Conv2D (9.63m/9.63m flops)\n",
      "  block_7_project/Conv2D (9.63m/9.63m flops)\n",
      "  block_8_expand/Conv2D (9.63m/9.63m flops)\n",
      "  block_8_project/Conv2D (9.63m/9.63m flops)\n",
      "  block_9_expand/Conv2D (9.63m/9.63m flops)\n",
      "  block_9_project/Conv2D (9.63m/9.63m flops)\n",
      "  block_13_project/Conv2D (9.03m/9.03m flops)\n",
      "  block_2_depthwise/depthwise (8.13m/8.13m flops)\n",
      "  block_3_project/Conv2D (7.23m/7.23m flops)\n",
      "  expanded_conv_depthwise/depthwise (7.23m/7.23m flops)\n",
      "  block_1_depthwise/depthwise (5.42m/5.42m flops)\n",
      "  block_6_project/Conv2D (4.82m/4.82m flops)\n",
      "  block_4_depthwise/depthwise (2.71m/2.71m flops)\n",
      "  block_5_depthwise/depthwise (2.71m/2.71m flops)\n",
      "  predictions/MatMul (2.56m/2.56m flops)\n",
      "  block_11_depthwise/depthwise (2.03m/2.03m flops)\n",
      "  block_12_depthwise/depthwise (2.03m/2.03m flops)\n",
      "  block_3_depthwise/depthwise (2.03m/2.03m flops)\n",
      "  block_10_depthwise/depthwise (1.35m/1.35m flops)\n",
      "  block_7_depthwise/depthwise (1.35m/1.35m flops)\n",
      "  block_8_depthwise/depthwise (1.35m/1.35m flops)\n",
      "  block_9_depthwise/depthwise (1.35m/1.35m flops)\n",
      "  block_14_depthwise/depthwise (846.72k/846.72k flops)\n",
      "  block_15_depthwise/depthwise (846.72k/846.72k flops)\n",
      "  block_16_depthwise/depthwise (846.72k/846.72k flops)\n",
      "  block_6_depthwise/depthwise (677.38k/677.38k flops)\n",
      "  block_13_depthwise/depthwise (508.03k/508.03k flops)\n",
      "  global_average_pooling2d_1/Mean (62.72k/62.72k flops)\n",
      "  predictions/Softmax (5.00k/5.00k flops)\n",
      "  predictions/BiasAdd (1.00k/1.00k flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/15.16b flops)\n",
      "  conv1_conv/Conv2D (236.03m/236.03m flops)\n",
      "  conv2_block1_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv2_block2_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv2_block3_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block1_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block2_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block3_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block4_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block10_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block11_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block12_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block13_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block14_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block15_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block16_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block17_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block18_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block19_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block1_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block20_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block21_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block22_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block23_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block2_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block3_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block4_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block5_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block6_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block7_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block8_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block9_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv5_block1_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv5_block2_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv5_block3_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block1_0_conv/Conv2D (205.52m/205.52m flops)\n",
      "  conv4_block1_0_conv/Conv2D (205.52m/205.52m flops)\n",
      "  conv5_block1_0_conv/Conv2D (205.52m/205.52m flops)\n",
      "  conv2_block1_0_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block1_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block2_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block2_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block3_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block3_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block1_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block2_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block2_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block3_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block3_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block4_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block4_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block10_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block10_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block11_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block11_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block12_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block12_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block13_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block13_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block14_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block14_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block15_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block15_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block16_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block16_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block17_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block17_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block18_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block18_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block19_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block19_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block1_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block20_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block20_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block21_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block21_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block22_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block22_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block23_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block23_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block2_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block2_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block3_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block3_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block4_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block4_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block5_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block5_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block6_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block6_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block7_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block7_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block8_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block8_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block9_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block9_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block1_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block2_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block2_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block3_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block3_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block1_1_conv/Conv2D (51.38m/51.38m flops)\n",
      "  conv4_block1_1_conv/Conv2D (51.38m/51.38m flops)\n",
      "  conv5_block1_1_conv/Conv2D (51.38m/51.38m flops)\n",
      "  conv2_block1_1_conv/Conv2D (25.69m/25.69m flops)\n",
      "  predictions/MatMul (4.10m/4.10m flops)\n",
      "  pool1_pool/MaxPool (1.81m/1.81m flops)\n",
      "  conv1_conv/BiasAdd (802.82k/802.82k flops)\n",
      "  conv2_block1_0_conv/BiasAdd (802.82k/802.82k flops)\n",
      "  conv2_block1_3_conv/BiasAdd (802.82k/802.82k flops)\n",
      "  conv2_block2_3_conv/BiasAdd (802.82k/802.82k flops)\n",
      "  conv2_block3_3_conv/BiasAdd (802.82k/802.82k flops)\n",
      "  conv3_block1_0_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block1_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block2_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block3_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block4_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv2_block1_1_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv2_block1_2_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv2_block2_1_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv2_block2_2_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv2_block3_1_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv2_block3_2_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block10_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block11_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block12_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block13_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block14_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block15_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block16_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block17_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block18_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block19_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block1_0_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block1_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block20_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block21_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block22_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block23_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block2_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block3_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block4_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block5_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block6_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block7_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block8_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block9_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  avg_pool/Mean (100.35k/100.35k flops)\n",
      "  conv3_block1_1_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block1_2_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block2_1_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block2_2_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block3_1_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block3_2_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block4_1_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block4_2_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv5_block1_0_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv5_block1_3_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv5_block2_3_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv5_block3_3_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv4_block10_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block10_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block11_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block11_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block12_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block12_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block13_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block13_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block14_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block14_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block15_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block15_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block16_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block16_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block17_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block17_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block18_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block18_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block19_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block19_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block1_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block1_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block20_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block20_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block21_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block21_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block22_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block22_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block23_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block23_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block2_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block2_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block3_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block3_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block4_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block4_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block5_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block5_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block6_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block6_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block7_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block7_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block8_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block8_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block9_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block9_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv5_block1_1_conv/BiasAdd (25.09k/25.09k flops)\n",
      "  conv5_block1_2_conv/BiasAdd (25.09k/25.09k flops)\n",
      "  conv5_block2_1_conv/BiasAdd (25.09k/25.09k flops)\n",
      "  conv5_block2_2_conv/BiasAdd (25.09k/25.09k flops)\n",
      "  conv5_block3_1_conv/BiasAdd (25.09k/25.09k flops)\n",
      "  conv5_block3_2_conv/BiasAdd (25.09k/25.09k flops)\n",
      "  predictions/Softmax (5.00k/5.00k flops)\n",
      "  predictions/BiasAdd (1.00k/1.00k flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/14.40b flops)\n",
      "  conv1_conv/Conv2D (236.03m/236.03m flops)\n",
      "  conv2_block1_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv2_block2_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block1_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block2_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block3_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block10_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block11_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block12_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block13_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block14_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block15_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block16_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block17_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block18_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block19_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block1_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block20_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block21_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block22_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block2_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block3_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block4_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block5_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block6_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block7_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block8_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block9_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv5_block1_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv5_block2_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv5_block3_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block1_0_conv/Conv2D (205.52m/205.52m flops)\n",
      "  conv4_block1_0_conv/Conv2D (205.52m/205.52m flops)\n",
      "  conv5_block1_0_conv/Conv2D (205.52m/205.52m flops)\n",
      "  conv2_block1_0_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block1_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block2_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block2_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block3_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block1_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block2_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block2_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block3_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block3_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block4_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block10_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block10_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block11_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block11_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block12_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block12_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block13_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block13_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block14_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block14_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block15_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block15_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block16_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block16_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block17_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block17_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block18_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block18_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block19_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block19_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block1_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block20_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block20_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block21_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block21_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block22_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block22_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block23_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block2_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block2_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block3_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block3_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block4_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block4_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block5_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block5_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block6_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block6_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block7_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block7_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block8_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block8_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block9_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block9_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block1_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block2_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block2_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block3_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block3_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block3_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block4_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv4_block23_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block1_1_conv/Conv2D (51.38m/51.38m flops)\n",
      "  conv4_block1_1_conv/Conv2D (51.38m/51.38m flops)\n",
      "  conv5_block1_1_conv/Conv2D (51.38m/51.38m flops)\n",
      "  conv2_block1_1_conv/Conv2D (25.69m/25.69m flops)\n",
      "  conv2_block3_3_conv/Conv2D (25.69m/25.69m flops)\n",
      "  conv3_block4_3_conv/Conv2D (25.69m/25.69m flops)\n",
      "  conv4_block23_3_conv/Conv2D (25.69m/25.69m flops)\n",
      "  predictions/MatMul (4.10m/4.10m flops)\n",
      "  pool1_pool/MaxPool (1.81m/1.81m flops)\n",
      "  conv1_conv/BiasAdd (802.82k/802.82k flops)\n",
      "  conv2_block1_0_conv/BiasAdd (802.82k/802.82k flops)\n",
      "  conv2_block1_3_conv/BiasAdd (802.82k/802.82k flops)\n",
      "  conv2_block2_3_conv/BiasAdd (802.82k/802.82k flops)\n",
      "  conv3_block1_0_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block1_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block2_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block3_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv2_block3_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block10_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block11_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block12_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block13_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block14_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block15_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block16_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block17_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block18_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block19_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block1_0_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block1_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block20_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block21_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block22_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block2_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block3_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block4_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block5_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block6_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block7_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block8_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block9_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  max_pooling2d_8/MaxPool (200.70k/200.70k flops)\n",
      "  avg_pool/Mean (100.35k/100.35k flops)\n",
      "  conv3_block4_3_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv5_block1_0_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv5_block1_3_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv5_block2_3_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv5_block3_3_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  max_pooling2d_9/MaxPool (100.35k/100.35k flops)\n",
      "  conv4_block23_3_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  max_pooling2d_10/MaxPool (50.18k/50.18k flops)\n",
      "  predictions/Softmax (5.00k/5.00k flops)\n",
      "  predictions/BiasAdd (1.00k/1.00k flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/22.59b flops)\n",
      "  conv1_conv/Conv2D (236.03m/236.03m flops)\n",
      "  conv2_block1_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv2_block2_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv2_block3_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block1_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block2_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block3_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block4_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block5_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block6_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block7_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block8_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block10_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block11_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block12_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block13_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block14_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block15_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block16_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block17_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block18_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block19_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block1_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block20_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block21_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block22_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block23_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block24_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block25_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block26_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block27_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block28_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block29_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block2_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block30_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block31_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block32_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block33_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block34_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block35_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block36_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block3_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block4_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block5_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block6_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block7_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block8_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block9_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv5_block1_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv5_block2_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv5_block3_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block1_0_conv/Conv2D (205.52m/205.52m flops)\n",
      "  conv4_block1_0_conv/Conv2D (205.52m/205.52m flops)\n",
      "  conv5_block1_0_conv/Conv2D (205.52m/205.52m flops)\n",
      "  conv2_block1_0_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block1_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block2_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block2_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block3_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block3_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block1_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block2_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block2_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block3_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block3_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block4_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block4_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block5_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block5_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block6_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block6_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block7_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block7_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block8_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block8_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block10_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block10_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block11_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block11_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block12_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block12_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block13_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block13_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block14_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block14_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block15_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block15_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block16_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block16_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block17_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block17_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block18_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block18_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block19_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block19_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block1_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block20_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block20_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block21_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block21_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block22_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block22_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block23_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block23_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block24_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block24_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block25_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block25_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block26_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block26_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block27_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block27_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block28_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block28_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block29_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block29_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block2_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block2_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block30_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block30_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block31_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block31_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block32_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block32_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block33_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block33_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block34_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block34_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block35_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block35_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block36_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block36_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block3_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block3_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block4_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block4_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block5_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block5_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block6_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block6_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block7_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block7_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block8_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block8_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block9_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block9_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block1_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block2_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block2_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block3_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block3_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block1_1_conv/Conv2D (51.38m/51.38m flops)\n",
      "  conv4_block1_1_conv/Conv2D (51.38m/51.38m flops)\n",
      "  conv5_block1_1_conv/Conv2D (51.38m/51.38m flops)\n",
      "  conv2_block1_1_conv/Conv2D (25.69m/25.69m flops)\n",
      "  predictions/MatMul (4.10m/4.10m flops)\n",
      "  pool1_pool/MaxPool (1.81m/1.81m flops)\n",
      "  conv1_conv/BiasAdd (802.82k/802.82k flops)\n",
      "  conv2_block1_0_conv/BiasAdd (802.82k/802.82k flops)\n",
      "  conv2_block1_3_conv/BiasAdd (802.82k/802.82k flops)\n",
      "  conv2_block2_3_conv/BiasAdd (802.82k/802.82k flops)\n",
      "  conv2_block3_3_conv/BiasAdd (802.82k/802.82k flops)\n",
      "  conv3_block1_0_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block1_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block2_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block3_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block4_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block5_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block6_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block7_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block8_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv2_block1_1_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv2_block1_2_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv2_block2_1_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv2_block2_2_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv2_block3_1_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv2_block3_2_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block10_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block11_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block12_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block13_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block14_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block15_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block16_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block17_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block18_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block19_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block1_0_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block1_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block20_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block21_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block22_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block23_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block24_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block25_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block26_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block27_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block28_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block29_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block2_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block30_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block31_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block32_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block33_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block34_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block35_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block36_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block3_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block4_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block5_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block6_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block7_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block8_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block9_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  avg_pool/Mean (100.35k/100.35k flops)\n",
      "  conv3_block1_1_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block1_2_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block2_1_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block2_2_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block3_1_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block3_2_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block4_1_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block4_2_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block5_1_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block5_2_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block6_1_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block6_2_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block7_1_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block7_2_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block8_1_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block8_2_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv5_block1_0_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv5_block1_3_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv5_block2_3_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv5_block3_3_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv4_block10_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block10_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block11_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block11_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block12_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block12_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block13_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block13_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block14_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block14_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block15_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block15_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block16_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block16_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block17_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block17_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block18_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block18_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block19_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block19_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block1_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block1_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block20_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block20_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block21_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block21_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block22_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block22_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block23_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block23_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block24_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block24_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block25_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block25_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block26_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block26_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block27_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block27_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block28_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block28_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block29_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block29_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block2_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block2_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block30_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block30_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block31_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block31_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block32_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block32_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block33_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block33_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block34_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block34_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block35_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block35_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block36_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block36_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block3_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block3_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block4_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block4_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block5_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block5_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block6_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block6_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block7_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block7_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block8_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block8_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block9_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block9_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv5_block1_1_conv/BiasAdd (25.09k/25.09k flops)\n",
      "  conv5_block1_2_conv/BiasAdd (25.09k/25.09k flops)\n",
      "  conv5_block2_1_conv/BiasAdd (25.09k/25.09k flops)\n",
      "  conv5_block2_2_conv/BiasAdd (25.09k/25.09k flops)\n",
      "  conv5_block3_1_conv/BiasAdd (25.09k/25.09k flops)\n",
      "  conv5_block3_2_conv/BiasAdd (25.09k/25.09k flops)\n",
      "  predictions/Softmax (5.00k/5.00k flops)\n",
      "  predictions/BiasAdd (1.00k/1.00k flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/21.83b flops)\n",
      "  conv1_conv/Conv2D (236.03m/236.03m flops)\n",
      "  conv2_block1_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv2_block2_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block1_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block2_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block3_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block4_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block5_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block6_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block7_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block10_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block11_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block12_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block13_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block14_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block15_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block16_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block17_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block18_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block19_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block1_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block20_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block21_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block22_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block23_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block24_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block25_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block26_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block27_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block28_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block29_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block2_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block30_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block31_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block32_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block33_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block34_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block35_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block3_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block4_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block5_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block6_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block7_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block8_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block9_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv5_block1_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv5_block2_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv5_block3_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block1_0_conv/Conv2D (205.52m/205.52m flops)\n",
      "  conv4_block1_0_conv/Conv2D (205.52m/205.52m flops)\n",
      "  conv5_block1_0_conv/Conv2D (205.52m/205.52m flops)\n",
      "  conv2_block1_0_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block1_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block2_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block2_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block3_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block1_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block2_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block2_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block3_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block3_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block4_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block4_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block5_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block5_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block6_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block6_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block7_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block7_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block8_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block10_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block10_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block11_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block11_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block12_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block12_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block13_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block13_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block14_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block14_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block15_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block15_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block16_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block16_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block17_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block17_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block18_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block18_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block19_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block19_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block1_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block20_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block20_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block21_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block21_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block22_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block22_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block23_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block23_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block24_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block24_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block25_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block25_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block26_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block26_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block27_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block27_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block28_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block28_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block29_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block29_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block2_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block2_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block30_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block30_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block31_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block31_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block32_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block32_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block33_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block33_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block34_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block34_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block35_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block35_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block36_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block3_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block3_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block4_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block4_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block5_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block5_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block6_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block6_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block7_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block7_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block8_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block8_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block9_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block9_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block1_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block2_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block2_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block3_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block3_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block3_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block8_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv4_block36_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block1_1_conv/Conv2D (51.38m/51.38m flops)\n",
      "  conv4_block1_1_conv/Conv2D (51.38m/51.38m flops)\n",
      "  conv5_block1_1_conv/Conv2D (51.38m/51.38m flops)\n",
      "  conv2_block1_1_conv/Conv2D (25.69m/25.69m flops)\n",
      "  conv2_block3_3_conv/Conv2D (25.69m/25.69m flops)\n",
      "  conv3_block8_3_conv/Conv2D (25.69m/25.69m flops)\n",
      "  conv4_block36_3_conv/Conv2D (25.69m/25.69m flops)\n",
      "  predictions/MatMul (4.10m/4.10m flops)\n",
      "  pool1_pool/MaxPool (1.81m/1.81m flops)\n",
      "  conv1_conv/BiasAdd (802.82k/802.82k flops)\n",
      "  conv2_block1_0_conv/BiasAdd (802.82k/802.82k flops)\n",
      "  conv2_block1_3_conv/BiasAdd (802.82k/802.82k flops)\n",
      "  conv2_block2_3_conv/BiasAdd (802.82k/802.82k flops)\n",
      "  conv3_block1_0_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block1_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block2_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block3_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block4_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block5_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block6_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block7_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv2_block3_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block10_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block11_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block12_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block13_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block14_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block15_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block16_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block17_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block18_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block19_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block1_0_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block1_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block20_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block21_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block22_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block23_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block24_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block25_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block26_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block27_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block28_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block29_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block2_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block30_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block31_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block32_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block33_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block34_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block35_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block3_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block4_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block5_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block6_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block7_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block8_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block9_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  max_pooling2d_11/MaxPool (200.70k/200.70k flops)\n",
      "  avg_pool/Mean (100.35k/100.35k flops)\n",
      "  conv3_block8_3_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv5_block1_0_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv5_block1_3_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv5_block2_3_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv5_block3_3_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  max_pooling2d_12/MaxPool (100.35k/100.35k flops)\n",
      "  conv4_block36_3_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  max_pooling2d_13/MaxPool (50.18k/50.18k flops)\n",
      "  predictions/Softmax (5.00k/5.00k flops)\n",
      "  predictions/BiasAdd (1.00k/1.00k flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/7.73b flops)\n",
      "  conv1_conv/Conv2D (236.03m/236.03m flops)\n",
      "  conv2_block1_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv2_block2_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv2_block3_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block1_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block2_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block3_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block4_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block1_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block2_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block3_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block4_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block5_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block6_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv5_block1_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv5_block2_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv5_block3_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block1_0_conv/Conv2D (205.52m/205.52m flops)\n",
      "  conv4_block1_0_conv/Conv2D (205.52m/205.52m flops)\n",
      "  conv5_block1_0_conv/Conv2D (205.52m/205.52m flops)\n",
      "  conv2_block1_0_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block1_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block2_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block2_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block3_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block3_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block1_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block2_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block2_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block3_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block3_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block4_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block4_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block1_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block2_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block2_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block3_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block3_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block4_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block4_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block5_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block5_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block6_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block6_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block1_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block2_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block2_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block3_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block3_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block1_1_conv/Conv2D (51.38m/51.38m flops)\n",
      "  conv4_block1_1_conv/Conv2D (51.38m/51.38m flops)\n",
      "  conv5_block1_1_conv/Conv2D (51.38m/51.38m flops)\n",
      "  conv2_block1_1_conv/Conv2D (25.69m/25.69m flops)\n",
      "  predictions/MatMul (4.10m/4.10m flops)\n",
      "  pool1_pool/MaxPool (1.81m/1.81m flops)\n",
      "  conv1_conv/BiasAdd (802.82k/802.82k flops)\n",
      "  conv2_block1_0_conv/BiasAdd (802.82k/802.82k flops)\n",
      "  conv2_block1_3_conv/BiasAdd (802.82k/802.82k flops)\n",
      "  conv2_block2_3_conv/BiasAdd (802.82k/802.82k flops)\n",
      "  conv2_block3_3_conv/BiasAdd (802.82k/802.82k flops)\n",
      "  conv3_block1_0_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block1_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block2_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block3_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block4_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv2_block1_1_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv2_block1_2_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv2_block2_1_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv2_block2_2_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv2_block3_1_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv2_block3_2_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block1_0_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block1_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block2_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block3_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block4_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block5_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block6_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  avg_pool/Mean (100.35k/100.35k flops)\n",
      "  conv3_block1_1_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block1_2_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block2_1_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block2_2_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block3_1_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block3_2_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block4_1_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv3_block4_2_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv5_block1_0_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv5_block1_3_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv5_block2_3_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv5_block3_3_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv4_block1_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block1_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block2_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block2_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block3_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block3_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block4_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block4_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block5_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block5_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block6_1_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv4_block6_2_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  conv5_block1_1_conv/BiasAdd (25.09k/25.09k flops)\n",
      "  conv5_block1_2_conv/BiasAdd (25.09k/25.09k flops)\n",
      "  conv5_block2_1_conv/BiasAdd (25.09k/25.09k flops)\n",
      "  conv5_block2_2_conv/BiasAdd (25.09k/25.09k flops)\n",
      "  conv5_block3_1_conv/BiasAdd (25.09k/25.09k flops)\n",
      "  conv5_block3_2_conv/BiasAdd (25.09k/25.09k flops)\n",
      "  predictions/Softmax (5.00k/5.00k flops)\n",
      "  predictions/BiasAdd (1.00k/1.00k flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/6.97b flops)\n",
      "  conv1_conv/Conv2D (236.03m/236.03m flops)\n",
      "  conv2_block1_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv2_block2_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block1_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block2_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block3_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block1_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block2_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block3_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block4_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv4_block5_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv5_block1_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv5_block2_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv5_block3_2_conv/Conv2D (231.21m/231.21m flops)\n",
      "  conv3_block1_0_conv/Conv2D (205.52m/205.52m flops)\n",
      "  conv4_block1_0_conv/Conv2D (205.52m/205.52m flops)\n",
      "  conv5_block1_0_conv/Conv2D (205.52m/205.52m flops)\n",
      "  conv2_block1_0_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block1_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block2_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block2_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block3_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block1_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block2_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block2_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block3_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block3_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv3_block4_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block1_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block2_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block2_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block3_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block3_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block4_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block4_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block5_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block5_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv4_block6_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block1_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block2_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block2_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block3_1_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv5_block3_3_conv/Conv2D (102.76m/102.76m flops)\n",
      "  conv2_block3_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block4_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv4_block6_2_conv/Conv2D (57.80m/57.80m flops)\n",
      "  conv3_block1_1_conv/Conv2D (51.38m/51.38m flops)\n",
      "  conv4_block1_1_conv/Conv2D (51.38m/51.38m flops)\n",
      "  conv5_block1_1_conv/Conv2D (51.38m/51.38m flops)\n",
      "  conv2_block1_1_conv/Conv2D (25.69m/25.69m flops)\n",
      "  conv2_block3_3_conv/Conv2D (25.69m/25.69m flops)\n",
      "  conv3_block4_3_conv/Conv2D (25.69m/25.69m flops)\n",
      "  conv4_block6_3_conv/Conv2D (25.69m/25.69m flops)\n",
      "  predictions/MatMul (4.10m/4.10m flops)\n",
      "  pool1_pool/MaxPool (1.81m/1.81m flops)\n",
      "  conv1_conv/BiasAdd (802.82k/802.82k flops)\n",
      "  conv2_block1_0_conv/BiasAdd (802.82k/802.82k flops)\n",
      "  conv2_block1_3_conv/BiasAdd (802.82k/802.82k flops)\n",
      "  conv2_block2_3_conv/BiasAdd (802.82k/802.82k flops)\n",
      "  conv3_block1_0_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block1_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block2_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv3_block3_3_conv/BiasAdd (401.41k/401.41k flops)\n",
      "  conv2_block3_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block1_0_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block1_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block2_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block3_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block4_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  conv4_block5_3_conv/BiasAdd (200.70k/200.70k flops)\n",
      "  max_pooling2d_14/MaxPool (200.70k/200.70k flops)\n",
      "  avg_pool/Mean (100.35k/100.35k flops)\n",
      "  conv3_block4_3_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv5_block1_0_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv5_block1_3_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv5_block2_3_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  conv5_block3_3_conv/BiasAdd (100.35k/100.35k flops)\n",
      "  max_pooling2d_15/MaxPool (100.35k/100.35k flops)\n",
      "  conv4_block6_3_conv/BiasAdd (50.18k/50.18k flops)\n",
      "  max_pooling2d_16/MaxPool (50.18k/50.18k flops)\n",
      "  predictions/Softmax (5.00k/5.00k flops)\n",
      "  predictions/BiasAdd (1.00k/1.00k flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/16.37b flops)\n",
      "  stem_1_stem_conv_3/Conv2D (462.42m/462.42m flops)\n",
      "  BlockGroup2__block_0__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup2__block_1__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup2__block_2__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup3__block_0__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup3__block_1__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup3__block_2__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup3__block_3__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_0__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_10__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_11__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_12__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_13__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_14__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_15__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_16__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_17__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_18__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_19__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_1__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_20__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_21__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_22__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_2__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_3__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_4__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_5__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_6__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_7__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_8__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_9__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup5__block_0__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup5__block_1__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup5__block_2__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  stem_1_stem_conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  stem_1_stem_conv_4/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup3__block_0__conv_1/Conv2D (205.52m/205.52m flops)\n",
      "  BlockGroup3__block_0__projection_conv/Conv2D (205.52m/205.52m flops)\n",
      "  BlockGroup4__block_0__conv_1/Conv2D (205.52m/205.52m flops)\n",
      "  BlockGroup4__block_0__projection_conv/Conv2D (205.52m/205.52m flops)\n",
      "  BlockGroup5__block_0__conv_1/Conv2D (205.52m/205.52m flops)\n",
      "  BlockGroup5__block_0__projection_conv/Conv2D (205.52m/205.52m flops)\n",
      "  BlockGroup2__block_0__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup2__block_0__projection_conv/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup2__block_1__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup2__block_1__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup2__block_2__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup2__block_2__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup3__block_0__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup3__block_1__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup3__block_1__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup3__block_2__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup3__block_2__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup3__block_3__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup3__block_3__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_0__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_10__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_10__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_11__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_11__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_12__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_12__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_13__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_13__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_14__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_14__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_15__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_15__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_16__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_16__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_17__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_17__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_18__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_18__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_19__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_19__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_1__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_1__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_20__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_20__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_21__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_21__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_22__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_22__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_2__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_2__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_3__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_3__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_4__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_4__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_5__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_5__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_6__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_6__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_7__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_7__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_8__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_8__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_9__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_9__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup5__block_0__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup5__block_1__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup5__block_1__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup5__block_2__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup5__block_2__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup2__block_0__conv_1/Conv2D (25.69m/25.69m flops)\n",
      "  stem_1_stem_conv_1/Conv2D (21.68m/21.68m flops)\n",
      "  predictions/MatMul (4.10m/4.10m flops)\n",
      "  BlockGroup5__block_0__se_se_expand/Conv2D (2.10m/2.10m flops)\n",
      "  BlockGroup5__block_0__se_se_reduce/Conv2D (2.10m/2.10m flops)\n",
      "  BlockGroup5__block_1__se_se_expand/Conv2D (2.10m/2.10m flops)\n",
      "  BlockGroup5__block_1__se_se_reduce/Conv2D (2.10m/2.10m flops)\n",
      "  BlockGroup5__block_2__se_se_expand/Conv2D (2.10m/2.10m flops)\n",
      "  BlockGroup5__block_2__se_se_reduce/Conv2D (2.10m/2.10m flops)\n",
      "  BlockGroup2__block_0__se_se_excite/mul (802.82k/802.82k flops)\n",
      "  BlockGroup2__block_0__se_se_squeeze/Mean (802.82k/802.82k flops)\n",
      "  BlockGroup2__block_1__se_se_excite/mul (802.82k/802.82k flops)\n",
      "  BlockGroup2__block_1__se_se_squeeze/Mean (802.82k/802.82k flops)\n",
      "  BlockGroup2__block_2__se_se_excite/mul (802.82k/802.82k flops)\n",
      "  BlockGroup2__block_2__se_se_squeeze/Mean (802.82k/802.82k flops)\n",
      "  BlockGroup3__block_0__projection_pooling/AvgPool (802.82k/802.82k flops)\n",
      "  BlockGroup4__block_0__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_0__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_10__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_10__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_11__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_11__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_12__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_12__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_13__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_13__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_14__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_14__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_15__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_15__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_16__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_16__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_17__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_17__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_18__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_18__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_19__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_19__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_1__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_1__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_20__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_20__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_21__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_21__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_22__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_22__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_2__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_2__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_3__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_3__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_4__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_4__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_5__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_5__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_6__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_6__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_7__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_7__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_8__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_8__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_9__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_9__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup3__block_0__se_se_excite/mul (401.41k/401.41k flops)\n",
      "  BlockGroup3__block_0__se_se_squeeze/Mean (401.41k/401.41k flops)\n",
      "  BlockGroup3__block_1__se_se_excite/mul (401.41k/401.41k flops)\n",
      "  BlockGroup3__block_1__se_se_squeeze/Mean (401.41k/401.41k flops)\n",
      "  BlockGroup3__block_2__se_se_excite/mul (401.41k/401.41k flops)\n",
      "  BlockGroup3__block_2__se_se_squeeze/Mean (401.41k/401.41k flops)\n",
      "  BlockGroup3__block_3__se_se_excite/mul (401.41k/401.41k flops)\n",
      "  BlockGroup3__block_3__se_se_squeeze/Mean (401.41k/401.41k flops)\n",
      "  BlockGroup4__block_0__projection_pooling/AvgPool (401.41k/401.41k flops)\n",
      "  BlockGroup4__block_0__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_0__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_10__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_10__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_11__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_11__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_12__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_12__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_13__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_13__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_14__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_14__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_15__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_15__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_16__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_16__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_17__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_17__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_18__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_18__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_19__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_19__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_1__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_1__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_20__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_20__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_21__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_21__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_22__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_22__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_2__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_2__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_3__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_3__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_4__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_4__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_5__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_5__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_6__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_6__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_7__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_7__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_8__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_8__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_9__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_9__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup5__block_0__projection_pooling/AvgPool (200.70k/200.70k flops)\n",
      "  normalization_12/sub (150.53k/150.53k flops)\n",
      "  normalization_12/truediv (150.53k/150.53k flops)\n",
      "  rescaling_15/mul (150.53k/150.53k flops)\n",
      "  BlockGroup3__block_0__se_se_expand/Conv2D (131.07k/131.07k flops)\n",
      "  BlockGroup3__block_0__se_se_reduce/Conv2D (131.07k/131.07k flops)\n",
      "  BlockGroup3__block_1__se_se_expand/Conv2D (131.07k/131.07k flops)\n",
      "  BlockGroup3__block_1__se_se_reduce/Conv2D (131.07k/131.07k flops)\n",
      "  BlockGroup3__block_2__se_se_expand/Conv2D (131.07k/131.07k flops)\n",
      "  BlockGroup3__block_2__se_se_reduce/Conv2D (131.07k/131.07k flops)\n",
      "  BlockGroup3__block_3__se_se_expand/Conv2D (131.07k/131.07k flops)\n",
      "  BlockGroup3__block_3__se_se_reduce/Conv2D (131.07k/131.07k flops)\n",
      "  BlockGroup5__block_0__se_se_excite/mul (100.35k/100.35k flops)\n",
      "  BlockGroup5__block_0__se_se_squeeze/Mean (100.35k/100.35k flops)\n",
      "  BlockGroup5__block_1__se_se_excite/mul (100.35k/100.35k flops)\n",
      "  BlockGroup5__block_1__se_se_squeeze/Mean (100.35k/100.35k flops)\n",
      "  BlockGroup5__block_2__se_se_excite/mul (100.35k/100.35k flops)\n",
      "  BlockGroup5__block_2__se_se_squeeze/Mean (100.35k/100.35k flops)\n",
      "  avg_pool/Mean (100.35k/100.35k flops)\n",
      "  BlockGroup2__block_0__se_se_expand/Conv2D (32.77k/32.77k flops)\n",
      "  BlockGroup2__block_0__se_se_reduce/Conv2D (32.77k/32.77k flops)\n",
      "  BlockGroup2__block_1__se_se_expand/Conv2D (32.77k/32.77k flops)\n",
      "  BlockGroup2__block_1__se_se_reduce/Conv2D (32.77k/32.77k flops)\n",
      "  BlockGroup2__block_2__se_se_expand/Conv2D (32.77k/32.77k flops)\n",
      "  BlockGroup2__block_2__se_se_reduce/Conv2D (32.77k/32.77k flops)\n",
      "  predictions/Softmax (5.00k/5.00k flops)\n",
      "  BlockGroup5__block_0__se_se_expand/BiasAdd (2.05k/2.05k flops)\n",
      "  BlockGroup5__block_1__se_se_expand/BiasAdd (2.05k/2.05k flops)\n",
      "  BlockGroup5__block_2__se_se_expand/BiasAdd (2.05k/2.05k flops)\n",
      "  BlockGroup4__block_0__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  BlockGroup4__block_10__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  BlockGroup4__block_11__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  BlockGroup4__block_12__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  BlockGroup4__block_13__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  BlockGroup4__block_14__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  BlockGroup4__block_15__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  BlockGroup4__block_16__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  BlockGroup4__block_17__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  BlockGroup4__block_18__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  BlockGroup4__block_19__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  BlockGroup4__block_1__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  BlockGroup4__block_20__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  BlockGroup4__block_21__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  BlockGroup4__block_22__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  BlockGroup4__block_2__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  BlockGroup4__block_3__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  BlockGroup4__block_4__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  BlockGroup4__block_5__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  BlockGroup4__block_6__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  BlockGroup4__block_7__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  BlockGroup4__block_8__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  BlockGroup4__block_9__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  predictions/BiasAdd (1.00k/1.00k flops)\n",
      "  BlockGroup3__block_0__se_se_expand/BiasAdd (512/512 flops)\n",
      "  BlockGroup3__block_1__se_se_expand/BiasAdd (512/512 flops)\n",
      "  BlockGroup3__block_2__se_se_expand/BiasAdd (512/512 flops)\n",
      "  BlockGroup3__block_3__se_se_expand/BiasAdd (512/512 flops)\n",
      "  BlockGroup5__block_0__se_se_reduce/BiasAdd (512/512 flops)\n",
      "  BlockGroup5__block_1__se_se_reduce/BiasAdd (512/512 flops)\n",
      "  BlockGroup5__block_2__se_se_reduce/BiasAdd (512/512 flops)\n",
      "  BlockGroup2__block_0__se_se_expand/BiasAdd (256/256 flops)\n",
      "  BlockGroup2__block_1__se_se_expand/BiasAdd (256/256 flops)\n",
      "  BlockGroup2__block_2__se_se_expand/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_0__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_10__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_11__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_12__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_13__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_14__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_15__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_16__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_17__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_18__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_19__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_1__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_20__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_21__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_22__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_2__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_3__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_4__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_5__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_6__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_7__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_8__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_9__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup3__block_0__se_se_reduce/BiasAdd (128/128 flops)\n",
      "  BlockGroup3__block_1__se_se_reduce/BiasAdd (128/128 flops)\n",
      "  BlockGroup3__block_2__se_se_reduce/BiasAdd (128/128 flops)\n",
      "  BlockGroup3__block_3__se_se_reduce/BiasAdd (128/128 flops)\n",
      "  BlockGroup2__block_0__se_se_reduce/BiasAdd (64/64 flops)\n",
      "  BlockGroup2__block_1__se_se_reduce/BiasAdd (64/64 flops)\n",
      "  BlockGroup2__block_2__se_se_reduce/BiasAdd (64/64 flops)\n",
      "  normalization_12/Maximum (3/3 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/8.92b flops)\n",
      "  stem_7_stem_conv_3/Conv2D (462.42m/462.42m flops)\n",
      "  BlockGroup2__block_0__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup2__block_1__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup2__block_2__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup3__block_0__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup3__block_1__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup3__block_2__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup3__block_3__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_0__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_1__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_2__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_3__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_4__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup4__block_5__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup5__block_0__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup5__block_1__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup5__block_2__conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  stem_7_stem_conv_2/Conv2D (231.21m/231.21m flops)\n",
      "  stem_7_stem_conv_4/Conv2D (231.21m/231.21m flops)\n",
      "  BlockGroup3__block_0__conv_1/Conv2D (205.52m/205.52m flops)\n",
      "  BlockGroup3__block_0__projection_conv/Conv2D (205.52m/205.52m flops)\n",
      "  BlockGroup4__block_0__conv_1/Conv2D (205.52m/205.52m flops)\n",
      "  BlockGroup4__block_0__projection_conv/Conv2D (205.52m/205.52m flops)\n",
      "  BlockGroup5__block_0__conv_1/Conv2D (205.52m/205.52m flops)\n",
      "  BlockGroup5__block_0__projection_conv/Conv2D (205.52m/205.52m flops)\n",
      "  BlockGroup2__block_0__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup2__block_0__projection_conv/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup2__block_1__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup2__block_1__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup2__block_2__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup2__block_2__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup3__block_0__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup3__block_1__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup3__block_1__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup3__block_2__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup3__block_2__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup3__block_3__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup3__block_3__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_0__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_1__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_1__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_2__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_2__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_3__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_3__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_4__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_4__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_5__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup4__block_5__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup5__block_0__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup5__block_1__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup5__block_1__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup5__block_2__conv_1/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup5__block_2__conv_3/Conv2D (102.76m/102.76m flops)\n",
      "  BlockGroup2__block_0__conv_1/Conv2D (25.69m/25.69m flops)\n",
      "  stem_7_stem_conv_1/Conv2D (21.68m/21.68m flops)\n",
      "  predictions/MatMul (4.10m/4.10m flops)\n",
      "  BlockGroup5__block_0__se_se_expand/Conv2D (2.10m/2.10m flops)\n",
      "  BlockGroup5__block_0__se_se_reduce/Conv2D (2.10m/2.10m flops)\n",
      "  BlockGroup5__block_1__se_se_expand/Conv2D (2.10m/2.10m flops)\n",
      "  BlockGroup5__block_1__se_se_reduce/Conv2D (2.10m/2.10m flops)\n",
      "  BlockGroup5__block_2__se_se_expand/Conv2D (2.10m/2.10m flops)\n",
      "  BlockGroup5__block_2__se_se_reduce/Conv2D (2.10m/2.10m flops)\n",
      "  BlockGroup2__block_0__se_se_excite/mul (802.82k/802.82k flops)\n",
      "  BlockGroup2__block_0__se_se_squeeze/Mean (802.82k/802.82k flops)\n",
      "  BlockGroup2__block_1__se_se_excite/mul (802.82k/802.82k flops)\n",
      "  BlockGroup2__block_1__se_se_squeeze/Mean (802.82k/802.82k flops)\n",
      "  BlockGroup2__block_2__se_se_excite/mul (802.82k/802.82k flops)\n",
      "  BlockGroup2__block_2__se_se_squeeze/Mean (802.82k/802.82k flops)\n",
      "  BlockGroup3__block_0__projection_pooling/AvgPool (802.82k/802.82k flops)\n",
      "  BlockGroup4__block_0__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_0__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_1__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_1__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_2__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_2__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_3__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_3__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_4__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_4__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_5__se_se_expand/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup4__block_5__se_se_reduce/Conv2D (524.29k/524.29k flops)\n",
      "  BlockGroup3__block_0__se_se_excite/mul (401.41k/401.41k flops)\n",
      "  BlockGroup3__block_0__se_se_squeeze/Mean (401.41k/401.41k flops)\n",
      "  BlockGroup3__block_1__se_se_excite/mul (401.41k/401.41k flops)\n",
      "  BlockGroup3__block_1__se_se_squeeze/Mean (401.41k/401.41k flops)\n",
      "  BlockGroup3__block_2__se_se_excite/mul (401.41k/401.41k flops)\n",
      "  BlockGroup3__block_2__se_se_squeeze/Mean (401.41k/401.41k flops)\n",
      "  BlockGroup3__block_3__se_se_excite/mul (401.41k/401.41k flops)\n",
      "  BlockGroup3__block_3__se_se_squeeze/Mean (401.41k/401.41k flops)\n",
      "  BlockGroup4__block_0__projection_pooling/AvgPool (401.41k/401.41k flops)\n",
      "  BlockGroup4__block_0__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_0__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_1__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_1__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_2__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_2__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_3__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_3__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_4__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_4__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_5__se_se_excite/mul (200.70k/200.70k flops)\n",
      "  BlockGroup4__block_5__se_se_squeeze/Mean (200.70k/200.70k flops)\n",
      "  BlockGroup5__block_0__projection_pooling/AvgPool (200.70k/200.70k flops)\n",
      "  normalization_18/sub (150.53k/150.53k flops)\n",
      "  normalization_18/truediv (150.53k/150.53k flops)\n",
      "  rescaling_21/mul (150.53k/150.53k flops)\n",
      "  BlockGroup3__block_0__se_se_expand/Conv2D (131.07k/131.07k flops)\n",
      "  BlockGroup3__block_0__se_se_reduce/Conv2D (131.07k/131.07k flops)\n",
      "  BlockGroup3__block_1__se_se_expand/Conv2D (131.07k/131.07k flops)\n",
      "  BlockGroup3__block_1__se_se_reduce/Conv2D (131.07k/131.07k flops)\n",
      "  BlockGroup3__block_2__se_se_expand/Conv2D (131.07k/131.07k flops)\n",
      "  BlockGroup3__block_2__se_se_reduce/Conv2D (131.07k/131.07k flops)\n",
      "  BlockGroup3__block_3__se_se_expand/Conv2D (131.07k/131.07k flops)\n",
      "  BlockGroup3__block_3__se_se_reduce/Conv2D (131.07k/131.07k flops)\n",
      "  BlockGroup5__block_0__se_se_excite/mul (100.35k/100.35k flops)\n",
      "  BlockGroup5__block_0__se_se_squeeze/Mean (100.35k/100.35k flops)\n",
      "  BlockGroup5__block_1__se_se_excite/mul (100.35k/100.35k flops)\n",
      "  BlockGroup5__block_1__se_se_squeeze/Mean (100.35k/100.35k flops)\n",
      "  BlockGroup5__block_2__se_se_excite/mul (100.35k/100.35k flops)\n",
      "  BlockGroup5__block_2__se_se_squeeze/Mean (100.35k/100.35k flops)\n",
      "  avg_pool/Mean (100.35k/100.35k flops)\n",
      "  BlockGroup2__block_0__se_se_expand/Conv2D (32.77k/32.77k flops)\n",
      "  BlockGroup2__block_0__se_se_reduce/Conv2D (32.77k/32.77k flops)\n",
      "  BlockGroup2__block_1__se_se_expand/Conv2D (32.77k/32.77k flops)\n",
      "  BlockGroup2__block_1__se_se_reduce/Conv2D (32.77k/32.77k flops)\n",
      "  BlockGroup2__block_2__se_se_expand/Conv2D (32.77k/32.77k flops)\n",
      "  BlockGroup2__block_2__se_se_reduce/Conv2D (32.77k/32.77k flops)\n",
      "  predictions/Softmax (5.00k/5.00k flops)\n",
      "  BlockGroup5__block_0__se_se_expand/BiasAdd (2.05k/2.05k flops)\n",
      "  BlockGroup5__block_1__se_se_expand/BiasAdd (2.05k/2.05k flops)\n",
      "  BlockGroup5__block_2__se_se_expand/BiasAdd (2.05k/2.05k flops)\n",
      "  BlockGroup4__block_0__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  BlockGroup4__block_1__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  BlockGroup4__block_2__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  BlockGroup4__block_3__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  BlockGroup4__block_4__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  BlockGroup4__block_5__se_se_expand/BiasAdd (1.02k/1.02k flops)\n",
      "  predictions/BiasAdd (1.00k/1.00k flops)\n",
      "  BlockGroup3__block_0__se_se_expand/BiasAdd (512/512 flops)\n",
      "  BlockGroup3__block_1__se_se_expand/BiasAdd (512/512 flops)\n",
      "  BlockGroup3__block_2__se_se_expand/BiasAdd (512/512 flops)\n",
      "  BlockGroup3__block_3__se_se_expand/BiasAdd (512/512 flops)\n",
      "  BlockGroup5__block_0__se_se_reduce/BiasAdd (512/512 flops)\n",
      "  BlockGroup5__block_1__se_se_reduce/BiasAdd (512/512 flops)\n",
      "  BlockGroup5__block_2__se_se_reduce/BiasAdd (512/512 flops)\n",
      "  BlockGroup2__block_0__se_se_expand/BiasAdd (256/256 flops)\n",
      "  BlockGroup2__block_1__se_se_expand/BiasAdd (256/256 flops)\n",
      "  BlockGroup2__block_2__se_se_expand/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_0__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_1__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_2__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_3__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_4__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup4__block_5__se_se_reduce/BiasAdd (256/256 flops)\n",
      "  BlockGroup3__block_0__se_se_reduce/BiasAdd (128/128 flops)\n",
      "  BlockGroup3__block_1__se_se_reduce/BiasAdd (128/128 flops)\n",
      "  BlockGroup3__block_2__se_se_reduce/BiasAdd (128/128 flops)\n",
      "  BlockGroup3__block_3__se_se_reduce/BiasAdd (128/128 flops)\n",
      "  BlockGroup2__block_0__se_se_reduce/BiasAdd (64/64 flops)\n",
      "  BlockGroup2__block_1__se_se_reduce/BiasAdd (64/64 flops)\n",
      "  BlockGroup2__block_2__se_se_reduce/BiasAdd (64/64 flops)\n",
      "  normalization_18/Maximum (3/3 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/30.96b flops)\n",
      "  block1_conv2/Conv2D (3.70b/3.70b flops)\n",
      "  block2_conv2/Conv2D (3.70b/3.70b flops)\n",
      "  block3_conv2/Conv2D (3.70b/3.70b flops)\n",
      "  block3_conv3/Conv2D (3.70b/3.70b flops)\n",
      "  block4_conv2/Conv2D (3.70b/3.70b flops)\n",
      "  block4_conv3/Conv2D (3.70b/3.70b flops)\n",
      "  block2_conv1/Conv2D (1.85b/1.85b flops)\n",
      "  block3_conv1/Conv2D (1.85b/1.85b flops)\n",
      "  block4_conv1/Conv2D (1.85b/1.85b flops)\n",
      "  block5_conv1/Conv2D (924.84m/924.84m flops)\n",
      "  block5_conv2/Conv2D (924.84m/924.84m flops)\n",
      "  block5_conv3/Conv2D (924.84m/924.84m flops)\n",
      "  fc1/MatMul (205.52m/205.52m flops)\n",
      "  block1_conv1/Conv2D (173.41m/173.41m flops)\n",
      "  fc2/MatMul (33.55m/33.55m flops)\n",
      "  predictions/MatMul (8.19m/8.19m flops)\n",
      "  block1_conv1/BiasAdd (3.21m/3.21m flops)\n",
      "  block1_conv2/BiasAdd (3.21m/3.21m flops)\n",
      "  block1_pool/MaxPool (3.21m/3.21m flops)\n",
      "  block2_conv1/BiasAdd (1.61m/1.61m flops)\n",
      "  block2_conv2/BiasAdd (1.61m/1.61m flops)\n",
      "  block2_pool/MaxPool (1.61m/1.61m flops)\n",
      "  block3_conv1/BiasAdd (802.82k/802.82k flops)\n",
      "  block3_conv2/BiasAdd (802.82k/802.82k flops)\n",
      "  block3_conv3/BiasAdd (802.82k/802.82k flops)\n",
      "  block3_pool/MaxPool (802.82k/802.82k flops)\n",
      "  block4_conv1/BiasAdd (401.41k/401.41k flops)\n",
      "  block4_conv2/BiasAdd (401.41k/401.41k flops)\n",
      "  block4_conv3/BiasAdd (401.41k/401.41k flops)\n",
      "  block4_pool/MaxPool (401.41k/401.41k flops)\n",
      "  block5_conv1/BiasAdd (100.35k/100.35k flops)\n",
      "  block5_conv2/BiasAdd (100.35k/100.35k flops)\n",
      "  block5_conv3/BiasAdd (100.35k/100.35k flops)\n",
      "  block5_pool/MaxPool (100.35k/100.35k flops)\n",
      "  predictions/Softmax (5.00k/5.00k flops)\n",
      "  fc1/BiasAdd (4.10k/4.10k flops)\n",
      "  fc2/BiasAdd (4.10k/4.10k flops)\n",
      "  predictions/BiasAdd (1.00k/1.00k flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/39.29b flops)\n",
      "  block1_conv2/Conv2D (3.70b/3.70b flops)\n",
      "  block2_conv2/Conv2D (3.70b/3.70b flops)\n",
      "  block3_conv2/Conv2D (3.70b/3.70b flops)\n",
      "  block3_conv3/Conv2D (3.70b/3.70b flops)\n",
      "  block3_conv4/Conv2D (3.70b/3.70b flops)\n",
      "  block4_conv2/Conv2D (3.70b/3.70b flops)\n",
      "  block4_conv3/Conv2D (3.70b/3.70b flops)\n",
      "  block4_conv4/Conv2D (3.70b/3.70b flops)\n",
      "  block2_conv1/Conv2D (1.85b/1.85b flops)\n",
      "  block3_conv1/Conv2D (1.85b/1.85b flops)\n",
      "  block4_conv1/Conv2D (1.85b/1.85b flops)\n",
      "  block5_conv1/Conv2D (924.84m/924.84m flops)\n",
      "  block5_conv2/Conv2D (924.84m/924.84m flops)\n",
      "  block5_conv3/Conv2D (924.84m/924.84m flops)\n",
      "  block5_conv4/Conv2D (924.84m/924.84m flops)\n",
      "  fc1/MatMul (205.52m/205.52m flops)\n",
      "  block1_conv1/Conv2D (173.41m/173.41m flops)\n",
      "  fc2/MatMul (33.55m/33.55m flops)\n",
      "  predictions/MatMul (8.19m/8.19m flops)\n",
      "  block1_conv1/BiasAdd (3.21m/3.21m flops)\n",
      "  block1_conv2/BiasAdd (3.21m/3.21m flops)\n",
      "  block1_pool/MaxPool (3.21m/3.21m flops)\n",
      "  block2_conv1/BiasAdd (1.61m/1.61m flops)\n",
      "  block2_conv2/BiasAdd (1.61m/1.61m flops)\n",
      "  block2_pool/MaxPool (1.61m/1.61m flops)\n",
      "  block3_conv1/BiasAdd (802.82k/802.82k flops)\n",
      "  block3_conv2/BiasAdd (802.82k/802.82k flops)\n",
      "  block3_conv3/BiasAdd (802.82k/802.82k flops)\n",
      "  block3_conv4/BiasAdd (802.82k/802.82k flops)\n",
      "  block3_pool/MaxPool (802.82k/802.82k flops)\n",
      "  block4_conv1/BiasAdd (401.41k/401.41k flops)\n",
      "  block4_conv2/BiasAdd (401.41k/401.41k flops)\n",
      "  block4_conv3/BiasAdd (401.41k/401.41k flops)\n",
      "  block4_conv4/BiasAdd (401.41k/401.41k flops)\n",
      "  block4_pool/MaxPool (401.41k/401.41k flops)\n",
      "  block5_conv1/BiasAdd (100.35k/100.35k flops)\n",
      "  block5_conv2/BiasAdd (100.35k/100.35k flops)\n",
      "  block5_conv3/BiasAdd (100.35k/100.35k flops)\n",
      "  block5_conv4/BiasAdd (100.35k/100.35k flops)\n",
      "  block5_pool/MaxPool (100.35k/100.35k flops)\n",
      "  predictions/Softmax (5.00k/5.00k flops)\n",
      "  fc1/BiasAdd (4.10k/4.10k flops)\n",
      "  fc2/BiasAdd (4.10k/4.10k flops)\n",
      "  predictions/BiasAdd (1.00k/1.00k flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/16.73b flops)\n",
      "  block4_sepconv2/separable_conv2d (1.45b/1.47b flops)\n",
      "    block4_sepconv2/separable_conv2d/depthwise (17.94m/17.94m flops)\n",
      "  block1_conv2/Conv2D (796.59m/796.59m flops)\n",
      "  block2_sepconv2/separable_conv2d (708.08m/757.87m flops)\n",
      "    block2_sepconv2/separable_conv2d/depthwise (49.79m/49.79m flops)\n",
      "  block3_sepconv2/separable_conv2d (717.75m/742.98m flops)\n",
      "    block3_sepconv2/separable_conv2d/depthwise (25.23m/25.23m flops)\n",
      "  block14_sepconv2/separable_conv2d (629.15m/631.91m flops)\n",
      "    block14_sepconv2/separable_conv2d/depthwise (2.76m/2.76m flops)\n",
      "  block13_sepconv2/separable_conv2d (538.23m/542.96m flops)\n",
      "    block13_sepconv2/separable_conv2d/depthwise (4.73m/4.73m flops)\n",
      "  block4_sepconv1/separable_conv2d (510.28m/516.58m flops)\n",
      "    block4_sepconv1/separable_conv2d/depthwise (6.31m/6.31m flops)\n",
      "  block10_sepconv1/separable_conv2d (382.65m/387.38m flops)\n",
      "    block10_sepconv1/separable_conv2d/depthwise (4.73m/4.73m flops)\n",
      "  block10_sepconv2/separable_conv2d (382.65m/387.38m flops)\n",
      "    block10_sepconv2/separable_conv2d/depthwise (4.73m/4.73m flops)\n",
      "  block10_sepconv3/separable_conv2d (382.65m/387.38m flops)\n",
      "    block10_sepconv3/separable_conv2d/depthwise (4.73m/4.73m flops)\n",
      "  block11_sepconv1/separable_conv2d (382.65m/387.38m flops)\n",
      "    block11_sepconv1/separable_conv2d/depthwise (4.73m/4.73m flops)\n",
      "  block11_sepconv2/separable_conv2d (382.65m/387.38m flops)\n",
      "    block11_sepconv2/separable_conv2d/depthwise (4.73m/4.73m flops)\n",
      "  block11_sepconv3/separable_conv2d (382.65m/387.38m flops)\n",
      "    block11_sepconv3/separable_conv2d/depthwise (4.73m/4.73m flops)\n",
      "  block12_sepconv1/separable_conv2d (382.65m/387.38m flops)\n",
      "    block12_sepconv1/separable_conv2d/depthwise (4.73m/4.73m flops)\n",
      "  block12_sepconv2/separable_conv2d (382.65m/387.38m flops)\n",
      "    block12_sepconv2/separable_conv2d/depthwise (4.73m/4.73m flops)\n",
      "  block12_sepconv3/separable_conv2d (382.65m/387.38m flops)\n",
      "    block12_sepconv3/separable_conv2d/depthwise (4.73m/4.73m flops)\n",
      "  block13_sepconv1/separable_conv2d (382.65m/387.38m flops)\n",
      "    block13_sepconv1/separable_conv2d/depthwise (4.73m/4.73m flops)\n",
      "  block5_sepconv1/separable_conv2d (382.65m/387.38m flops)\n",
      "    block5_sepconv1/separable_conv2d/depthwise (4.73m/4.73m flops)\n",
      "  block5_sepconv2/separable_conv2d (382.65m/387.38m flops)\n",
      "    block5_sepconv2/separable_conv2d/depthwise (4.73m/4.73m flops)\n",
      "  block5_sepconv3/separable_conv2d (382.65m/387.38m flops)\n",
      "    block5_sepconv3/separable_conv2d/depthwise (4.73m/4.73m flops)\n",
      "  block6_sepconv1/separable_conv2d (382.65m/387.38m flops)\n",
      "    block6_sepconv1/separable_conv2d/depthwise (4.73m/4.73m flops)\n",
      "  block6_sepconv2/separable_conv2d (382.65m/387.38m flops)\n",
      "    block6_sepconv2/separable_conv2d/depthwise (4.73m/4.73m flops)\n",
      "  block6_sepconv3/separable_conv2d (382.65m/387.38m flops)\n",
      "    block6_sepconv3/separable_conv2d/depthwise (4.73m/4.73m flops)\n",
      "  block7_sepconv1/separable_conv2d (382.65m/387.38m flops)\n",
      "    block7_sepconv1/separable_conv2d/depthwise (4.73m/4.73m flops)\n",
      "  block7_sepconv2/separable_conv2d (382.65m/387.38m flops)\n",
      "    block7_sepconv2/separable_conv2d/depthwise (4.73m/4.73m flops)\n",
      "  block7_sepconv3/separable_conv2d (382.65m/387.38m flops)\n",
      "    block7_sepconv3/separable_conv2d/depthwise (4.73m/4.73m flops)\n",
      "  block8_sepconv1/separable_conv2d (382.65m/387.38m flops)\n",
      "    block8_sepconv1/separable_conv2d/depthwise (4.73m/4.73m flops)\n",
      "  block8_sepconv2/separable_conv2d (382.65m/387.38m flops)\n",
      "    block8_sepconv2/separable_conv2d/depthwise (4.73m/4.73m flops)\n",
      "  block8_sepconv3/separable_conv2d (382.65m/387.38m flops)\n",
      "    block8_sepconv3/separable_conv2d/depthwise (4.73m/4.73m flops)\n",
      "  block9_sepconv1/separable_conv2d (382.65m/387.38m flops)\n",
      "    block9_sepconv1/separable_conv2d/depthwise (4.73m/4.73m flops)\n",
      "  block9_sepconv2/separable_conv2d (382.65m/387.38m flops)\n",
      "    block9_sepconv2/separable_conv2d/depthwise (4.73m/4.73m flops)\n",
      "  block9_sepconv3/separable_conv2d (382.65m/387.38m flops)\n",
      "    block9_sepconv3/separable_conv2d/depthwise (4.73m/4.73m flops)\n",
      "  block2_sepconv1/separable_conv2d (354.04m/378.94m flops)\n",
      "    block2_sepconv1/separable_conv2d/depthwise (24.89m/24.89m flops)\n",
      "  block3_sepconv1/separable_conv2d (358.88m/371.49m flops)\n",
      "    block3_sepconv1/separable_conv2d/depthwise (12.62m/12.62m flops)\n",
      "  block14_sepconv1/separable_conv2d (314.57m/316.42m flops)\n",
      "    block14_sepconv1/separable_conv2d/depthwise (1.84m/1.84m flops)\n",
      "  conv2d_300/Conv2D (149.09m/149.09m flops)\n",
      "  conv2d_299/Conv2D (134.56m/134.56m flops)\n",
      "  conv2d_297/Conv2D (89.72m/89.72m flops)\n",
      "  conv2d_298/Conv2D (89.72m/89.72m flops)\n",
      "  block1_conv1/Conv2D (38.36m/38.36m flops)\n",
      "  block2_pool/MaxPool (6.31m/6.31m flops)\n",
      "  predictions/MatMul (4.10m/4.10m flops)\n",
      "  block3_pool/MaxPool (3.15m/3.15m flops)\n",
      "  block4_pool/MaxPool (2.37m/2.37m flops)\n",
      "  block13_pool/MaxPool (921.60k/921.60k flops)\n",
      "  avg_pool/Mean (204.80k/204.80k flops)\n",
      "  predictions/Softmax (5.00k/5.00k flops)\n",
      "  predictions/BiasAdd (1.00k/1.00k flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    }
   ],
   "source": [
    "result[\"FLOPs\"] = result.apply(lambda x: get_flops(x[\"model\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcff4e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAERCAYAAACZystaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAzj0lEQVR4nO3deXxU1fn48c9DCIYGCyooUUSWWpUliRCQRRZRghIE22K/KF2ouPVXJXVBsbik1rZabBWVKmgVtVZFigpGFJUgCKIshgi4YUQNokQqKAgYwvP7496JkzAzuUnmzmQyz/v1mldmzt2e3EzmmXPOveeIqmKMMSa5NYt3AMYYY+LPkoExxhhLBsYYYywZGGOMwZKBMcYYLBkYY4whQZOBiDwoIttEZH2U9tdRRBaJyDsislFEOkVjv8YYkygSMhkAs4Ezo7i/R4BpqnoS0BfYFsV9G2NMo5eQyUBVlwL/Cy4Tka4i8oKIrBGRZSJyopd9iUg3oLmqvuTue5eqfhv9qI0xpvFKyGQQxizgclXtDVwN/NPjdj8GdojIPBF5S0SmiUiKb1EaY0wj1DzeAUSDiLQCBgBPiUig+BB32U+Bm0NstkVVR+Ccg0HAycAnwJPABOBf/kZtjDGNR5NIBjg1nB2qml1zgarOA+ZF2LYMKFbVUgAReQbohyUDY0wSaRLNRKr6NfCRiJwLII4sj5uvAtqISDv39TBgow9hGmNMo5WQyUBEHgdeB04QkTIRmQiMByaKyDpgAzDGy75UtRKnj+EVEXkbEOB+fyI3xpjGSWwIa2OMMQlZMzDGGBNdCdeB3LZtW+3UqVO8wzDGmISyZs2aL1W1XbjlCZcMOnXqxOrVq+MdhjHGJBQR+TjScmsmMsYYY8nAGGOMJQNjjDEkYJ+BMaZ2FRUVlJWVsXfv3niHYmIsLS2NDh06kJqaWqftLBkY0wSVlZVx6KGH0qlTJ4LG6zJNnKqyfft2ysrK6Ny5c522tWYik1QKSwvJnZtL5sOZ5M7NpbC0MN4h+WLv3r0cccQRlgiSjIhwxBFH1KtGaDUDkzQKSwspWFHA3krnH2Xr7q0UrCgAIK9LXhwj84clguRU37+71QxM0pi+dnpVIgjYW7mX6WunxykiYxoPSwYmaXy++/M6lZuGSUlJITs7m+7du5OVlcXf//53Dhw4EPM4lixZgoiwYMGCqrJRo0axZMkSAIYOHUpOTk7VstWrVzN06NAYRxl/lgxM0mif3r5O5cnkmbe2MPDWxXSeUsjAWxfzzFtbGrzPli1bUlxczIYNG3jppZdYuHAhf/zjH6MQbd116NCBP//5z2GXb9u2jYULF8YwosbHkoFJGvm98klLSatWlpaSRn6v/DhF1Dg889YWrpv3Nlt27EGBLTv2cN28t6OSEAKOPPJIZs2axT333IOqUllZyeTJk+nTpw+ZmZnMnDkTcL7FDx06lLFjx3LiiScyfvx4AiMrT5kyhW7dupGZmcnVV18NQHl5OT/72c/o06cPffr0Yfny5SGPn5WVRevWrXnppZdCLp88eXLIZLFhwwb69u1LdnY2mZmZfPDBB9E4HY2SdSCbpBHoJJ6+djqf7/6c9untye+V3yQ7j+ti2ovvsaeislrZnopKpr34HuecfEzUjtOlSxcqKyvZtm0bzz77LK1bt2bVqlXs27ePgQMHkpubC8Bbb73Fhg0bOProoxk4cCDLly/npJNO4umnn+bdd99FRNixYwcA+fn5XHHFFZx66ql88sknjBgxgnfeeSfk8adOncoNN9zA8OHDD1rWv39/nn76aYqKijj00EOryu+77z7y8/MZP3483333HZWVlQdt21T4lgxE5EFgFLBNVXtEWK8PzkQ141R1rl/xmIMVlhYm3QdjXpe8Jv871tVnO/bUqTwaFi1aRElJCXPnOv/yO3fu5IMPPqBFixb07duXDh06AJCdnc3mzZvp168faWlpTJw4kVGjRjFq1CgAXn75ZTZu/H5iwq+//ppdu3bRqlWrg445ePBgAF577bWQMV1//fXccsst3HbbbVVl/fv3589//jNlZWX89Kc/5fjjj4/OCWiE/Gwmmg2cGWkFEUkBbgMW+RiHCSFwmeXW3VtRtOoyy6Z63b0J7+g2LetUXl+lpaWkpKRw5JFHoqrcfffdFBcXU1xczEcffVRVMzjkkEOqtklJSWH//v00b96cN998k7Fjx/Lcc89x5pnOR8uBAwdYuXJl1X62bNkSMhEETJ06lVtuuSXksmHDhrFnzx5WrlxZVXb++eczf/58WrZsyciRI1m8eHE0TkWj5FsyUNWlwP9qWe1y4L/ANr/iMKHZZZYmYPKIE2iZmlKtrGVqCpNHnBC1Y5SXl3PppZdy2WWXISKMGDGCe++9l4qKCgDef/99du/eHXb7Xbt2sXPnTkaOHMkdd9zBunXrAMjNzeXuu++uWq+4uDhiHLm5uXz11VeUlJSEXH799dfzt7/9rep1aWkpXbp0YdKkSYwZMybsdk1B3PoMROQY4CfAaUCfeMWRrOwySxMQ6BeY9uJ7fLZjD0e3acnkESc0uL9gz549ZGdnU1FRQfPmzfnlL3/JlVdeCcCFF17I5s2b6dWrF6pKu3bteOaZZ8Lu65tvvmHMmDHs3bsXVeUf//gHAHfddRe/+93vyMzMZP/+/QwePJj77rsvYlxTp05lzJjQU6SPHDmSdu2+n/9lzpw5PProo6SmptK+fXv+8Ic/1PEsJA5f50AWkU7Ac6H6DETkKeDvqrpSRGa764XsMxCRi4GLATp27Nj7448jztFgPMidm8vW3VsPKs9Iz2DRWGu1S3TvvPMOJ510UrzDMHES6u8vImtUNSfMJnG9tDQHeEJENgNjgX+KyDmhVlTVWaqao6o5wVnb1J9dZmmMCRa3ZiJVrRpSL6hm8Ey84kk2dpmlMSaYn5eWPg4MBdqKSBlwE5AKoKqRG/VMTNhllsaYAN+SgaqeV4d1J/gVhzHGmNrZcBTGGGMsGRhjjLFkYIzxyeeff864cePo2rUrvXv3ZuTIkbz//vsxOXanTp348ssvI64ze/ZsPvvss6rXF154YbWhLaJh9uzZXHbZZSHLmzVrVu0mth49erB582bAif9nP/tZ1bK5c+cyYcKEqMZWkyUDYwyUzIE7ekBBG+dnyZwG7U5V+clPfsLQoUP58MMPWbNmDX/961/54osvohNvFNRMBg888ADdunWL2fFrG1Z7zZo1UU9OkVgyMCbZlcyBBZNg56eAOj8XTGpQQigqKiI1NZVLL720qiwrK4tBgwahqkyePJkePXrQs2dPnnzySSD88NUvvPAC5557btV+lixZUjVQ3eOPP07Pnj3p0aMH11577UFxbN68mR49vr/n9fbbb6egoIC5c+eyevVqxo8fT3Z2Nnv27GHo0KGsXr064n5btWrF1KlTycrKol+/flXJbcGCBZxyyimcfPLJnHHGGZ6S3qhRo9iwYQPvvfdeyOVXXXVVyGTx6quvkp2dTXZ2NieffDLffPNNrcfywpKBMcnulZuhosYIpRV7nPJ6Wr9+Pb179w65bN68eRQXF7Nu3TpefvllJk+ezNatzt3wb731FnfeeScbN26ktLSU5cuXc8YZZ/DGG29UjV305JNPMm7cOD777DOuvfZaFi9eTHFxMatWrYo4pEWwsWPHkpOTw2OPPUZxcTEtW34/KF+k/e7evZt+/fqxbt06Bg8ezP333w/AqaeeysqVK3nrrbcYN25ctfGNwmnWrBnXXHMNf/nLX0Iu//nPf87atWvZtGlTtfLbb7+dGTNmUFxczLJly6rF3hCWDIxJdjvL6lbeQK+99hrnnXceKSkpHHXUUQwZMoRVq1YBVA1f3axZs6rhq5s3b86ZZ57JggUL2L9/P4WFhYwZM4ZVq1YxdOhQ2rVrR/PmzRk/fjxLly5tcHyR9tuiRYuqWknv3r2r2vjLysoYMWIEPXv2ZNq0aWzYsMHTsc4//3xWrlzJRx99dNCylJQUJk+ezF//+tdq5QMHDuTKK6/krrvuYseOHTRvHp07BCwZGJPsWneoW7kH3bt3Z82aNXXeLtTw1QDjxo1jzpw5LF68mJycnGoT0ETSvHnzavMu7927N8LatUtNTUVEDorv8ssv57LLLuPtt99m5syZno/TvHlzrrrqqmpzKAT75S9/ydKlS/n000+ryqZMmcIDDzzAnj17GDhwIO+++26DfqcASwbGJLvTb4TUGk0NqS2d8noaNmwY+/btY9asWVVlJSUlLFu2jEGDBvHkk09SWVlJeXk5S5cupW/fvhH3N2TIENauXcv999/PuHHjAKcW8eqrr/Lll19SWVnJ448/zpAhQ6ptd9RRR7Ft2za2b9/Ovn37eO6556qWHXrooSHb273st6adO3dyzDHOKK8PP/xw5JNTw4QJE3j55ZcpLy8/aFlqaipXXHEFd9xxR1XZhx9+SM+ePbn22mvp06ePJQNjmprC0kJy5+aS+XAmuXNzYzfRUObP4ey7oPWxgDg/z77LKa8nEeHpp5/m5ZdfpmvXrnTv3p3rrruO9u3b85Of/ITMzEyysrIYNmwYf/vb32jfvn3E/aWkpDBq1CgWLlxY1UyTkZHBrbfeymmnnUZWVha9e/c+aGjq1NRUbrzxRvr27cvw4cM58cQTq5ZNmDCBSy+9tKoDOcDLfmsqKCjg3HPPpXfv3rRt27ZO56pFixZMmjSJbdtCT+syceLEqhoIwJ133kmPHj3IzMwkNTWVs846q07HC8fXIaz9kJOTo4Ee/2SVjNNVNnWBmeeCJxxKS0mjYEBBvf62NoR1cqvPENZxG7XU1E/ND43AdJWAJYQEFm7muVvfvNUSv4kJayZKMDZdZdMUboa5Hft22DzVJiYsGSQYm66ybuLWDl9H7dMjt5kHWOI3frFkkGDCfWh4/TBJJoEmtUT4Zh1q5rlwLPEbP1gySDA2XaV3idSkltclj4IBBWSkZyAIGekZtG7ROuS6lviNH6wDOcHYdJXeJVqTWs2Z58JdYWSJ3/jBagYJKK9LHovGLqLk1yUsGrvIEkEYid6kFqq2UN9LTeMhJSWF7OxsevTowbnnnsu3337redvNmzfzn//8p17HHTBgQL22CxVD8CB3fmnVqlVU1mkoSwamyWoKTWqxSvx+dLS3bNmS4uJi1q9fT4sWLbjvvupTnwffSFVTpGQQaTuAFStW1D1Y418yEJEHRWSbiKwPs3y8iJSIyNsiskJEsvyKxSSnRP9mHSux6GgfNGgQmzZtYsmSJQwaNIjRo0fTrVs3KisrmTx5Mn369CEzM5OZM2cCzvg7y5YtIzs7mzvuuIPZs2czevRohg0bxumnn86uXbs4/fTT6dWrFz179uTZZ5+tOlbgW3S4IbHBmStgyJAh9O7dmxEjRlSNmrpmzRqysrLIyspixowZIX+XJUuWMGTIEMaMGUOXLl2YMmUKjz32GH379qVnz558+OGHgJPQhg0bRmZmJqeffjqffPIJAB999BH9+/enZ8+eXH/99dX2PW3atKpzcdNNNx107K1btzJ48OCqGteyZcsa8mepTlVrfQDHAAOAwYGHh20GA72A9WGWDwAOc5+fBbzhJZbevXurMSayjRs3el53+FPDtcfsHgc9hj81vEExpKenq6pqRUWFjh49Wv/5z39qUVGR/uAHP9DS0lJVVZ05c6b+6U9/UlXVvXv3au/evbW0tFSLioo0Ly+val8PPfSQHnPMMbp9+/aqfe7cuVNVVcvLy7Vr16564MCBasctKirSH/7wh/rpp59qZWWl9uvXT5ctW6bfffed9u/fX7dt26aqqk888YT+5je/UVXVnj176quvvqqqqldffbV27979oN+rqKhIW7durZ999pnu3btXjz76aL3xxhtVVfXOO+/U/Px8VVUdNWqUzp49W1VV//Wvf+mYMWNUVfXss8/Whx9+WFVV77nnnqp4X3zxRb3ooov0wIEDWllZqXl5eVWxBNa5/fbb9ZZbblFV1f379+vXX38d8tyH+vsDqzXCZ2utHcgichvwf8BGoDKQQ4CIY8Wq6lIR6RRheXBdbiVQ/yESjTH15ldH+549e8jOzgacmsHEiRNZsWIFffv2pXPnzgAsWrSIkpIS5s6dCzgDvn3wwQe0aNHioP0NHz6cww8/HHC+xP7hD39g6dKlNGvWjC1btvDFF18cNMZRYEhsoGpI7DZt2rB+/XqGDx8OQGVlJRkZGezYsYMdO3YwePBgwBkxdOHChSF/tz59+pCRkQFA165dyc3NBaBnz54UFRUB8PrrrzNv3ryqfV1zzTUALF++nP/+979V5YHJcxYtWsSiRYs4+eSTAdi1axcffPBBVTyB415wwQVUVFRwzjnnVJ3faPByNdE5wAmqui9qRz3YRCD0WQdE5GLgYoCOHTv6GIYxyad9enu27t4asrwhAn0GNaWnp1c9V1XuvvtuRowYUW2dJUuWRNzuscceo7y8nDVr1pCamkqnTp1CDhsdakhsVaV79+68/vrr1dbdsWOHx9+s+n6bNWtW9bpZs2a19mkAVcNgB1NVrrvuOi655JKw2w0ePJilS5dSWFjIhAkTuPLKK/nVr37lOe5IvPQZlAKpUTlaCCJyGk4yOHjOOpeqzlLVHFXNadeunV+hGJOU4tnRPmLECO69914qKioAeP/999m9e3fY4aUDdu7cyZFHHklqaipFRUV8/PHHno95wgknUF5eXpUMKioq2LBhA23atKFNmza89tprgJNwGmLAgAE88cQTVfsaNGgQ4ExOE1weMGLECB588EF27doFwJYtWw4ayfTjjz/mqKOO4qKLLuLCCy9k7dq1DYoxWNiagYjcjdMc9C1QLCKvAFW1A1Wd1NCDi0gm8ABwlqpub+j+jDF1F897Vy688EI2b95Mr169UFXatWvHM888Q2ZmJikpKWRlZTFhwgQOO+ywatuNHz+es88+m549e5KTk1NtaOratGjRgrlz5zJp0iR27tzJ/v37+f3vf0/37t156KGHuOCCCxCRqqaf+rr77rv5zW9+w7Rp02jXrh0PPfQQANOnT+f888/ntttuqzY0dm5uLu+88w79+/cHnI7wf//73xx55JFV6yxZsoRp06aRmppKq1ateOSRRxoUY7CwQ1iLyK8jbaiqtc7g4PYZPKeqB12sKyIdgcXAr2r0H0RkQ1gbUzsbwjq5RXsI653AClUNPeNCLUTkcWAo0FZEyoCbcJubVPU+4EbgCOCfbvvZ/kiBGmOM8U+kZPALYIaIfAusAJbjJIeQ9w3UpKrn1bL8QuBCr4EaY4zxT9gOZFUdq6rHAMOBF4FM4GERKReR52MVoDGmfsI1AZumrb5/91ovLVXVzSKSBrR0H4HnxphGKi0tje3bt3PEEUeEvIzRNE2qyvbt20lL8zYcerBIVxP9AegPtAPew7kx7B7gYlWtDLedMSb+OnToQFlZGeXl5fEOxcRYWlpa1Y12dRGpZvArYDewAKfP4A1V3Vm/8IwxsZSamlp1l68xXoRNBqp6oogcjjOG0FBgioi0AtbhdCQ/FJsQjTHG+C1in4Gq/g94TkReAHrjDD53CXABYMnAGGOaiEh9BqNxagUDge7ABpzLS6/CaTYyERSWFtpsZMaYhBGpZjAB58P/GmCNqn4Xk4iagJrTFQbGhwcsIRhjGqVI9xn8VFX/DrSpmQhE5FLfI0tgiTQRuzHGgLdRS28QkWGBFyJyDTAmwvpJL9EmYjfGGC/JYDTwFxEZJCJ/Bk7BkkFEiT4RuzEm+dSaDFT1S5yEMAM4Ghhr/QeRNYWJ2I0xySXS1UTf4MxnENAC6AKMFRFV1R/6HVyiiuf48MYYUx+Rbjo7NJaBNDV5XfLsw98YkzC89BkYY4xp4iwZGGOMsWRgjDHGw3wGACKSAhwVvL6qfuJXUMYYY2Kr1pqBiFwOfAG8BBS6j+c8bPegiGwTkZDTZIrjLhHZJCIlItKrjrEbY4yJEi81g3zgBFXdXsd9z8aZDOeRMMvPAo53H6cA97o/Gx0bdM4Y09R56TP4FKjzpDaquhT4X4RVxgCPqGMl0EZEMup6HL8FBp3bunsrilYNOldYWhjv0IwxJmq81AxKgSUiUgjsCxSq6j8aeOxjcBJNQJlbtrWB+42qSIPOWe3AGNNUeEkGn7iPFu4j5kTkYuBigI4dO8b02DbonDEmGdSaDFT1jz4dewtwbNDrDm5ZqBhmAbMAcnJyNNQ6fmmf3p6tuw+urNigc8aYpiRsn4GI3On+XCAi82s+onDs+cCv3KuK+gE7VbVRNRGBDTpnjEkOkWoGj7o/b6/PjkXkcWAo0FZEyoCbgFQAVb0PeB4YCWwCvgV+U5/j+M0GnTPGJANRjWmrS4Pl5OTo6tWrfdu/XUZqjGmKRGSNquaEW+7pDuRkEY25iy2ZGGMSkY1NFKShcxfbPQnGmERlySBIQy8jbWgyMcaYeKm1mUhEfgxMBo6j+kB1w3yMKy4aehlptO5JsKYmY0yseakZPAWsBa7HSQqBR5Pj5TLSwtJCcufmkvlwJrlzc6s1AYVLGnW5J8Gamowx8eAlGexX1XtV9U1VXRN4+B5ZHOR1yaNgQAEZ6RkIQkZ6BgUDCqq+ldf2QR2NexKsqckYEw9eriZaICL/D3ia6mMTRRqELmFFmru4tnGKonFPgg1/YYyJBy/J4Nfuz+CmIQW6RD+cxs3LB3WkZOKFDX9hjImHWpuJVLVziEfSJQKITp9AbWz4C2NMPHiZ6SxVRCaJyFz3cZmIpMYiuMYmFh/UtfVbGGOMH2odjkJEHsAZU+hht+iXQKWqXuhzbCH5PRxFbeyyT2NMIorGcBR9VDUr6PViEVnX8NASU0P7BIwxpjHycmlppYh0DbwQkS5ApX8hGVNdpHs7jDHR4aVmMBkoEpFSQHDuRG6Uw02bpifS4IFgQ4sbEy1eZjp7RUSOB05wi95T1X2RtjEmWsLd23Hrm7eyd//eBo0wa4z5XqSZzoa5P38K5AE/ch95bpkxvgt3b8eOfTvsTm1joihSzWAIsBg4O8QyBeb5EpExQcLdhBeO3altTP2ETQaqepP79GZV/Sh4mYh09jUqY1z5vfKr9RmAc2/HISmHsPO7nQetb3dqG1M/Xq4m+m+IsrnRDsSYUMLdhHfdKdfZndrGRFHYmoGInAh0B1rX6CP4IZAWequD9nEmMB1IAR5Q1VtrLO+IczNbG3edKar6fF1+AdP01TZ4oF1NZEzDReozOAEYhfNBHdxv8A1wUW07FpEUYAYwHCgDVonIfFXdGLTa9cAcVb1XRLoBzwOd6vILmORlNwAaEz2R+gyeBZ4Vkf6q+no99t0X2KSqpQAi8gQwBghOBopT0wBoDXxWj+MY44kNJWJMeF76DL4QkQUiUi4i20TkWfcu5NocA3wa9LrMLQtWAPxCRMpwagWXh9qRiFwsIqtFZHV5ebmHQxtTnc0gZ0xkXpLBf4A5QAZwNM40mI9H6fjnAbNVtQMwEnhURA6KSVVnqWqOqua0a9cuSoc2ycRmkDMmMi/J4Aeq+qiq7ncf/8ZbB/IW4Nig1x3csmATcRINblNUGtDWw76NqRObQc6YyLwkg4UiMkVEOonIcSJyDfC8iBwuIodH2G4VcLyIdBaRFsA4YH6NdT4BTgcQkZNwkoG1A5moi8XERMYkMi/J4OfAJUARsAT4Lc4H+xog7MQCqrofuAx4EXgH56qhDSJys4iMdle7CrjIHRL7cWCC1jbBQgzYKJlNj80gZ0xktU5u09j4PblNzVEywfnQsNnGEp9dTWSSWW2T23iZ6SwFZ6C6TgRdiqqq/4hSjHXidzLInZsbciycjPQMFo1d5NtxjTHGT9GY6WwBsBd4GzgQrcAaK+toNMYkIy/JoIOqZvoeSSMRbpRM62g0xjRlXq8myvU9kkbCOhqNMcnIS81gJfC0ezNYBc7Ul6qqP4y8WWIKdChaR6MxJpl4SQb/APoDbzeGyz5jwQZAM8YkGy/NRJ8C65MlEZj6sXszjElsXmoGpcASEVkI7AsUxuvSUtP41Lw3wyanNybxeKkZfAS8ArQADg16GAPYIHDGNAW11gxU9Y+xCCRe7K7UhrN7M4xJfLUmAxEpwpmEphpVHeZLRDFkzRvRYfdmGJP4vDQTXQ1Mdh83AMVEGKAukSR780a0On3t3gxjEp+XZqI1NYqWi8ibPsUTU8ncvBHNWpHdm2FM4vPSTBQ8Z0EzoDfOfMUJL5mbNyLViurzIW73ZhiT2Lw0EwXmLVgDvI4zB8FEP4OKlWRu3kjmWpEx5mBemok6xyKQeEjm5o1krhUZYw7mpZnoXOAFVf1GRK4HegG3qOpa36OLgWRt3sjvlR9yEp9kqBUZYw7mpZnoBjcRnAqcAfwLuNffsIzf8rrkUTCggIz0DAQhIz3DZnMzJol5GY6i0v2ZB8xS1UIRucXLzkXkTGA6kAI8oKq3hljn50ABzr0M61T1fC/7Ng2XrLUiY8zBvCSDLSIyExgO3CYih+ChRuFOlznD3a4MWCUi81V1Y9A6xwPXAQNV9SsRObI+v4QxxpiG8dJM9HPgRWCEqu4ADse5Aa02fYFNqlqqqt8BTwBjaqxzETBDVb8CUNVtXgM3xhgTPbUmA1X9FngW2C0iHYFU4F0P+z4GZ/jrgDK3LNiPgR+LyHIRWek2KxljjIkxL1cTXQ7cBHwBHHCLFYjGvMjNgeOBoUAHYKmI9HRrIMExXAxcDNCxY8coHNYYY0wwL30G+cAJqrq9jvveAhwb9LqDWxasDHhDVSuAj0TkfZzksCp4JVWdBcwCyMnJsUl2jDEmyrzOdLazHvteBRwvIp1FpAUwDphfY51ncGoFiEhbnGaj0nocyxhjTAPUZaazQuow05mq7heRy3A6n1OAB1V1g4jcDKxW1fnuslwR2YhzCevketRAjDHGNJCXZPCJ+2jhPjxT1eeB52uU3Rj0XIEr3Ycxxpg48TzTmYi0cl/v8jsoY4wxseXl5rEeIvIWsAHYICJrRKS7/6EZY4yJFS8dyLOAK1X1OFU9DmcI6/v9DcsYY0wseUkG6apaFHihqkuAdN8iMsYYE3OeriYSkRuAR93Xv8Au/zTGmCbFS83gAqAdMA/4L9DWLTPGGNNEeLma6CtgUgxiMcYYEyderiZ6SUTaBL0+TERe9DUqY4wxMeWlmaht8MBxbk3B5h0wxpgmxEsyOOAOXQ2AiByHM2qpMcaYJsLL1URTgddE5FVAgEG4w0kbY4xpGrx0IL8gIr2Afm7R71X1S3/DMg1RWFrI9LXT+Xz357RPb09+r3yb69gYE5GXmgHuh/9zPsdioqCwtJCCFQXsrdwLwNbdWylYUQBgCcEYE5aXPgOTQKavnV6VCAL2Vu5l+trpcYrIGJMILBk0MZ/v/rxO5cYYA7U0E4lICrBBVU+MUTymDkL1DbRPb8/W3VsPWrd9evs4RGiMSRQRawaqWgm8F3xpqWkcAn0DW3dvRdGqvoHBHQaTlpJWbd20lDTye+XHKVJjTCLw0kx0GM48Bq+IyPzAw+/ATGTh+gaWli2lYEABGekZCEJGegYFAwqs89gYE5GXq4lu8D0KU2eR+gbyuuTZh78xpk5qrRmo6qvAZiDVfb4KWOtl5yJypoi8JyKbRGRKhPV+JiIqIjke40564foArG/AGFMfXgaquwiYC8x0i44BnvGwXQowAzgL6AacJyLdQqx3KJAPvOE5akN+r3zrGzDGRI2XPoPfAQOBrwFU9QO8DVTXF9ikqqWq+h3wBDAmxHp/Am4D9oZY5pvC0kJy5+aS+XAmuXNzKSwtjOXhGyyvS571DRhjosZLn8E+Vf1ORAAQkeZ4G6juGODToNdlwCnBK7jDXByrqoUiMjncjkTkYtzxkDp2bPiFTU3lLl3rGzDGRIuXmsGrIvIHoKWIDAeeAhY09MAi0gz4B3BVbeuq6ixVzVHVnHbt2jX00HaXrjHG1OAlGUwByoG3gUuA54HrPWy3BTg26HUHtyzgUKAHsERENuMMhDc/Fp3IdpeuMcZU56WZ6DTg36p6fx33vQo4XkQ64ySBccD5gYWquhNnPmUARGQJcLWqrq7jcerM7tI1xpjqvNQMfgWsE5GVIjJNRM4WkcNq20hV9wOXAS8C7wBzVHWDiNwsIqMbFnbD2JU4xhhTnah6m7RMRI4GxgJXA0erqqfhr6MtJydHV69ueOXBxvw3xiQTEVmjqmGb4Wv9QBeRX+DMbtYT+BK4B1gWtQjjxK7EMcaY73n5dn8n8CFwH1Ckqpv9DMgYY0zseRmOoi1wAZAG/FlE3hSRR32PzBhjTMx4GY7ih0BH4DigE9AaOOBvWMYYY2LJSzPRa0GPe1S1zN+QjDHGxFqtyUBVMwFEpJX/4RhjjIkHL81EPUTkLWADsFFE1ohID/9Da0RK5sAdPaCgjfOzZE68IzLGmKjy0kw0C7hSVYsARGSoWzbAv7AakZI5sGASVOxxXu/81HkNkPnz+MVljDFR5OUO5PRAIgBQ1SVAum8RNTav3Px9Igio2OOUG2NME+GlZlAqIjcAgctJfwGU+hdSI7MzTH95uHJjjElAXmoGFwDtgHnAf3EGl7vAz6AaldYd6lZujDEJKGzNQETSgEuBH+EMX32VqlbEKrBGoWQOfLf74PLUlnD6jbGPxxhjfBKpmehhoAJnHKKzgJOA38cgpsahZsdxQMvD4azbrPPYGNOkREoG3VS1J4CI/At4MzYhxcdBo5h+8Rl5NRMBQIt0SwTGmCYnUjKoahJS1f2BOZCbopBzIv9AIf0H5O3+tvrK1nFsjGmCInUgZ4nI1+7jGyAz8FxEvo5VgLEQck7kZs2Yflibg1e2jmNjTBMUtmagqimxDCSews6J3LzGKbCOY2NME+Xl0tImL9zcx+1btIHWxwLi/Dz7LusvMMbEXGFpIblzc8l8OJPcubkUlhZG/RhxmbqyscnvlV+tzwAg7cAB8r/a4dQELAEYY+IkZJ/migKAqM7W6GvNQETOFJH3RGSTiEwJsfxKEdkoIiUi8oqIHOdnPCGVzCHv2Wsp2LqFjP0HEFUyKvZT8OX/yCv/FOZdDM9dGfOwjDEGwvRpVu5l+trpUT2ObzUDEUkBZgDDgTJglYjMV9WNQau9BeSo6rci8lvgb8D/+RXTQZ67ElY/CCh5QN7uEDeYoc46HftZDcEYE3Nh+zTDlNeXnzWDvsAmVS1V1e+AJ4AxwSuoapGqBq7dXAnE7lKdkjlViaB2agPTGRMnsWgvb8zC9mmGKa8vP5PBMcCnQa/L3LJwJgILQy0QkYtFZLWIrC4vL49OdAuvxVsicNn9BcbEXKC9fOvurSha1V6eTAkhv1c+aSlp1crSUtLI75Uf1eM0iquJROQXQA4wLdRyVZ2lqjmqmtOuXbuGH7BkDuz5X922sfsLjIm5WLWXN2Z5XfIoGFBARnoGgpCRnkHBgIKodh6Dv1cTbQGODXrdwS2rRkTOAKYCQ1R1n4/xfK+uTT52f4ExcRGr9vLGLq9LXtQ//Gvys2awCjheRDqLSAtgHDA/eAURORmYCYxW1W0+xlJdXZp87P4CY+ImVu3lxsdkoKr7gcuAF4F3gDmqukFEbhaR0e5q04BWwFMiUiwi88PsLro8N/kIXLHeEoExcRKr9nLj801nqvo88HyNshuDnp/h5/HDOv3G0MNT12T9BMbEVaBppNqIwr3yfW8ySUbJeQdy4Jv+c78PPXkNWD+BMY1ELNrLTSO5mijmSuY4l5aGSwTWT2CMSTLJVzMomQPzLgEOhF7e+linn8AYY5JI8iSDkjnOJaU7P428nt1cZoxJQsmRDMLNZxyKdRobY5JQcvQZvHKzt0QA1mlsjElKyZEMvDb92GT3xpgklRzJwGvTT8oh/sZhjDGNVHIkg+Nzva235yt/4zDGmEYqOZLBhqe9rWedx8aYJJUcycDTcNXNrPPYGJO0kiMZePHTmdZ5bIxJWkmRDGqdz6zl4ZYIjDFJrckng/H3v157NjjrtpjEYowxjVWTTwbLP6ylvyBnotUKjDFJr8kng1qN+ke8IzDGmLizZGCMMcaSgTHGGJ+TgYicKSLvicgmEZkSYvkhIvKku/wNEenkRxy7NMwwE6npfhzOGGMSjm/JQERSgBnAWUA34DwR6VZjtYnAV6r6I+AOwJfLeqbun0iFSrWyChU4+04/DmeMMQnHz5pBX2CTqpaq6nfAE8CYGuuMAR52n88FThcRIcrmHziVqyp+S9mBthxQoexAW66q+K1dRWSMMS4/J7c5BgieVqwMOCXcOqq6X0R2AkcAXwavJCIXAxcDdOzYsU5BNBfYr05CmP/dqdXK76rTnowxpulKiA5kVZ2lqjmqmtOuXbs6bbvpr3k0r1HXaC5OuTHGGIefNYMtwLFBrzu4ZaHWKROR5kBrYHu0A7EPfmOMiczPmsEq4HgR6SwiLYBxwPwa68wHfu0+HwssVtVahxIyxhgTXb7VDNw+gMuAF4EU4EFV3SAiNwOrVXU+8C/gURHZBPwPJ2EYY4yJMT+biVDV54Hna5TdGPR8L3CunzEYY4ypXUJ0IBtjjPGXJQNjjDFIovXXikg58HE9N29LjXsYGhGLrX4aa2yNNS6w2OqrscbmNa7jVDXstfkJlwwaQkRWq2pOvOMIxWKrn8YaW2ONCyy2+mqssUUrLmsmMsYYY8nAGGNM8iWDWfEOIAKLrX4aa2yNNS6w2OqrscYWlbiSqs/AGGNMaMlWMzDGGBOCJQNjjDFNJxk0ZIpNEbnOLX9PREbEIbYrRWSjiJSIyCsiclzQskoRKXYfNQf68zuuCSJSHnT8C4OW/VpEPnAfv665bQxiuyMorvdFZEfQMj/P2YMisk1E1odZLiJylxt3iYj0Clrm9zmrLbbxbkxvi8gKEckKWrbZLS8WkdVxiG2oiOwM+rvdGLQs4nshBrFNDoprvfv+Otxd5tt5E5FjRaTI/WzYICL5IdaJ3vtNVRP+gTMQ3odAF6AFsA7oVmOd/wfc5z4fBzzpPu/mrn8I0NndT0qMYzsN+IH7/LeB2NzXu+J4ziYA94TY9nCg1P15mPv8sFjGVmP9y3EGQvT1nLn7Hgz0AtaHWT4SWAgI0A94IxbnzGNsAwLHxJmO9o2gZZuBtnE8b0OB5xr6XvAjthrrno0zurLv5w3IAHq5zw8F3g/xPxq191tTqRk0ZIrNMcATqrpPVT8CNrn7i1lsqlqkqt+6L1fizP3gNy/nLJwRwEuq+j9V/Qp4CTgzjrGdBzwexeOHpapLcUbYDWcM8Ig6VgJtRCQD/89ZrbGp6gr32BC791ng2LWdt3Aa8j71I7ZYvte2qupa9/k3wDs4s0MGi9r7rakkg1BTbNY8adWm2AQCU2x62dbv2IJNxMn0AWkislpEVorIOXGI62du9XOuiAQmK2o058xtUusMLA4q9uuceREudr/PWV3VfJ8psEhE1ogzzWw89BeRdSKyUES6u2WN5ryJyA9wPlD/G1Qck/MmTrP2ycAbNRZF7f3m6xDWpm5E5BdADjAkqPg4Vd0iIl2AxSLytqp+GKOQFgCPq+o+EbkEp2Y1LEbH9mocMFdVK4PK4nnOGj0ROQ0nGZwaVHyqe86OBF4SkXfdb8yxshbn77ZLREYCzwDHx/D4XpwNLFfV4FqE7+dNRFrhJKDfq+rX0dx3sKZSM6jLFJtI9Sk2vWzrd2yIyBnAVGC0qu4LlKvqFvdnKbAE59tBTOJS1e1BsTwA9Pa6rd+xBRlHjWq7j+fMi3Cx+33OPBGRTJy/5RhVrZpiNuicbQOeJrpNpbVS1a9VdZf7/HkgVUTa0kjOmyvSe82X8yYiqTiJ4DFVnRdilei93/zo+Ij1A6eGU4rTXBDoZOpeY53fUb0DeY77vDvVO5BLiW4HspfYTsbpJDu+RvlhwCHu87bAB0Sp88xjXBlBz38CrNTvO6c+cuM7zH1+eCzPmbveiTgdeBKLcxZ0jE6E7wjNo3qH3puxOGceY+uI0yc2oEZ5OnBo0PMVwJkxjq194O+I84H6iXsOPb0X/IzNXd4ap18hPVbnzf39HwHujLBO1N5vUT2h8Xzg9Kq/j/OhOtUtuxnnmzZAGvCU+8/wJtAlaNup7nbvAWfFIbaXgS+AYvcx3y0fALzt/gO8DUyMcVx/BTa4xy8CTgza9gL3XG4CfhPrc+a+LgBurbGd3+fscWArUIHTDjsRuBS41F0uwAw37reBnBies9piewD4Kuh9ttot7+Ker3Xu33tqHGK7LOi9tpKghBXqvRDL2Nx1JuBcaBK8na/nDacZT4GSoL/ZSL/ebzYchTHGmCbTZ2CMMaYBLBkYY4yxZGCMMcaSgTHGGCwZGGNMo1DbgHk11h0sImtFZL+IjK2xrF4DIloyMAlBRFRE/h70+moRKYjSvmfX/Ifyg4icKyLviEhRjfJOIrInaGTMYhFpIc6osfeE2M+pIvKmiLzrPi4OWlYgIluCRtgc7ffvZaJmNt7Hq/oE53LX/wQXuqOp3gScgnO/xk0icpiXHVoyMIliH/BT967URsO9m92ricBFqnpaiGUfqmp20OO7MMdrj/MBcKmqnohzLfolIpIXtNodqpoNnAs8KCL2f54ANMSAeSLSVURecMc+WiYiJ7rrblbVEuBAjd3Ue0BEe5OYRLEfZ67XK2ouqPnNXkR2uT+HisirIvKsiJSKyK3ijOn/pjsGfdeg3ZzhDm73voiMcrdPEZFpIrLKHazvkqD9LhNnroSNIeI5z93/ehG5zS27EeeD+18iMq0B5+F3wGz9fjTLL4FrgIPG+VfVd3DOW1sRmSTfz5nxRAOOb2JrFnC5qvYGrgb+Wcv69R7YzwaqM4lkBlAiIn+rwzZZwEk437hKgQdUta84E4VcDvzeXa8TTrW6K1AkIj8CfgXsVNU+InIIsFxEFrnr9wJ6qDPseRURORq4DWccp69wRrQ8R1VvFpFhwNWqGmoSlK4iUuw+X66qvwvz+3Tn+6HYA1a75dWIyCk43xzLcZJFZ3UGHWwTZt+mEXEHqBsAPCUigeJD/DqeJQOTMFT1axF5BJgE7PG42SpV3QogIh8CgQ/zt3EmFQqYo6oHgA9EpBRn3KNcIDOo1tEaZyTN73DGgKmWCFx9gCWqWu4e8zGcyVOeqSXOD92mnWi4wh0B9xvg/1RVRaQEeExEnvEQi2kcmgE76vi+2IIzUVBAB5zBGj0dzJhEcidO23t6UNl+3Pey2z7eImjZvqDnB4JeH6D6l6Ga47Iozrgvlwe143dW1UAy2d2QX6IBNvL96LEBvXHGxgm4w413kKouc8vycGpWvYBVdezrMHGgznDVH4nIuVA1xWVWLZu9COSKyGFux3GuW1YrSwYmoagzlvwcnIQQsJnvPyBHA6n12PW5ItLM7UfogjNo4YvAb91hhBGRH4tIeqSd4AyCOERE2opICs7MWK/WI55wZgATRCTbjekInGapsE1nboI8VlWLgGtxajitohiTiQIReRx4HThBRMpEZCIwHpgoIoHB8Ma46/YRkTKciwRmisgGqPr/+BOwyn3crNXnXwjLvh2YRPR3nFEuA+4HnnX/YV6gft/aP8H5IP8hzpU6e0XkAZy+hLXiNNqWA+dE2omqbhVn0vYinJpFoao+W494AiZI9dna+gG/AO4XkUPdY9ypqgsi7CMF+LeItHbXv0tVdzQgJuMDVT0vzKKDrgZS1VWEmbZUVR8EHqzr8W3UUmOMMdZMZIwxxpKBMcYYLBkYY4zBkoExxhgsGRhjjMGSgTHGGCwZGGOMAf4/v20bTGx552kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_dense = result[result.loc[:,\"config.model_file\"] == \"dataset.models.dense\"]\n",
    "result_conv = result[result.loc[:,\"config.model_file\"] == \"dataset.models.conv\"]\n",
    "result_pretrained = result[result.loc[:,\"config.model_file\"] == \"dataset.models.pretrained\"]\n",
    "\n",
    "for x, name in zip([result_dense, result_conv, result_pretrained], [\"Dense NNs\", \"Convolutional NNs\", \"Pretrained models\"]):\n",
    "    plt.plot(x[\"FLOPs\"], x[\"result.power\"], \"o\", label = name)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Number of FLOPs\")\n",
    "plt.ylabel(\"Power consumption in kWh\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64b02f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjNElEQVR4nO3deZwcdbnv8c83C8RAWJOjCCSDyBJAQBhZPKKImguogAgKBhGNRlA2BT1cQVE0514PolwOIAyCLAZUlgNB9isBIsoyQQgkIxrDFuDIhCUEIoEhz/mjqkln0t1TPenqnu7+vl+vfnXX0lVPZamn67cqIjAzs/Y1rNEBmJlZYzkRmJm1OScCM7M250RgZtbmnAjMzNqcE4GZWZtzIjADJO0paeFqfP87kn5Ry5jKnOcOSV/O+zzWXpwIrCEkfU5St6RXJD0r6SZJH2h0XFmUShoR8e8R0dAbtKTvSwpJnylaNyJd15EuX5wu71K0z7sluUNRG3MisLqT9E3gTODfgbcD44Fzgf0bGFareAH4gaThA+zzozrFY03AicDqStK6wGnA1yPimoh4NSLeiIjrI+Jb6T5rSjpT0jPp60xJa6bb9pS0UNIJkp5Lnya+mG7bVdJ/F98EJX1K0pyBjlsizpD07qLliyX9SNJawE3AO9OnmVckvTP9Nf6rov33kzRX0ktpcc7Eom2PSzpR0hxJiyX9RtKodNv6kn4nqVfSi+nnTar4I74ZeB04rMI+lwDbS/pQmWs/QtICSUskPSZpchXntybkRGD1tjswCvivCvucDOwG7AjsAOwCnFK0/R3AusDGwBTgHEnrR8S9wKvAXkX7fg64PONxBxQRrwL7AM9ExNrp65nifSRtCVwBHA+MA24Erpe0RtFunwH2BjYDtgeOSNcPA34JTCB5UvoncHY1IQLfBU6VNLLMPktJnsam9d+QJrqzgH0iYgzwfuDBKs5vTagpE4Gki9Jfg4/U4FgflvRg0es1SQfUIEwrbUNgUUT0VdhnMnBaRDwXEb3AD4DPF21/I93+RkTcCLwCbJVuuwI4FEDSGGDfdF2W49bKZ4EbIuK2iHgD+AnwNpKbasFZEfFMRLwAXE+SnIiI5yPi6ohYGhFLSG7WJX+5lxMRM4BeoFKdxfnAeEn7lNi2HNhO0tsi4tmImFvN+a35NGUiAC4m+TW12iJiZkTsGBE7kvySXArcWotjW0nPA2MljaiwzzuBJ4qWn0jXvXWMfolkKbB2+vly4MC0yOdA4IGIKBxroOPWykrniYjlwFMkTzAF/130+a34JY2WdL6kJyS9DNwFrDdAmX8pp5A8AY0qtTEilgE/TF/F618lSWRHAs9KukHS1lWe25pMUyaCiLiLpMLrLZI2l3SzpNmSZg3yH+9BwE0RsbQmgVopfwKWAQdU2OcZkqKRgvHpugFFxDySm/A+rFwsVO1xlwKji5bfUXyaAcJY6TySBGwKPD3A9wBOIHm62TUi1gE+WDhMhu+uCDDiNmA+8LUKu/0SWI8kYRZ/95aI+BiwEfAX4IJqzm3NpykTQRldwDERsTNwIkkrlGodwopiBMtBRCwGvkdSrn9A+gt4pKR9JP1HutsVwCmSxkkam+7/q3LHLOFy4DiSm+iVReurOe6DwOckDZe0NysXz/wD2DCt+C7lt8DHJX0kLac/gST5/TFD7GNI6gVekrQBcGqG75RzMvDtchvTp6pTgX8rrJP0dkn7p3UFy0iK3ZavRgzWBFoiEUham6T89UpJD5KUf26UbjtQ0iMlXrf0O8ZGwHuAW7BcRcQZwDdJii96SYpNjgauTXf5EdANzAEeBh6guuaOV5DcuG+PiEVF66s57nHAJ4GXSOoWCrEREX9Jz7EgbRW0UvFSRDxK0mrnP4FF6XE+GRGvZ4j9TJL6hEXAPSStgAYlIu4G7htgtyuAZ4uWh5H83TxD8tT9IeCowcZgzUHNOjGNkg4yv4uI7SStAzwaERutxvGOA7aNiKm1itHMrBm0xBNBRLwMPCbpYEjKZCXtUOVhDsXFQmbWhpoyEUi6gqTScau0c9EUksf3KZIeAuZSRS/V9OliU+DOHMI1MxvSmrZoyMzMaqMpnwjMzKx2KnXqGZLGjh0bHR0djQ7DzKypzJ49e1FEjCu1rekSQUdHB93d3Y0Ow8ysqUh6otw2Fw2ZmbW53BKBpFGS7pP0UDoc7w9K7LNmOgTvfEn3pq13zMysjvJ8IlgG7BURO5CMrLi3pN367TMFeDEi3g38DPhxjvGYmVkJuSWCSLySLo5MX/3bqu5PMkkGwFXAR9IBuszMrE5yrSNIB+x6EHgOuC2dOKTYxiTjzBQGwFpMMl59/+NMVTK/bXdvb2+eIZuZtZ1cE0FEvJmO878JsIuk7QZ5nK6I6IyIznHjSrZ+MjNrXT3ToasDzhiWvPdMr+nh69JqKCJeAmay6mQyT5MM7UA6Ucm6JBOXmJkZJDf9W6fCkieASN5vnVrTZJBnq6FxktZLP78N+BjJJBfFZgBfSD8fRDJssMe8MDMrmHUy9PWbK6tvabK+RvLsULYRcEk6xd4w4LcR8TtJpwHd6byqFwKXSZpPMvb5ITnGY2bWfJY8Wd36QcgtEUTEHOC9JdZ/r+jza8DBecVgZtb0xoxPi4VKrK8R9yw2MxvK9pgGI0avvG7E6GR9jTgRmJkNZRMnw6QuGDMBUPI+qStZXyNNN+icmVnbmTi5pjf+/vxEYGbW5pwIzMzanBOBmVmbcyIwM2tzTgRmZm3OicDMrM05EZiZtTknAjOzNudEYGbW5pwIzMzanBOBmVmbcyIwM2tzTgRmZm3OicDMrM05EZiZtTknAjOzNudEYGbW5pwIzMzanBOBmVmbcyIwMyvWMx26OuCMYcl7z/RGR5Q7T15vZlbQMx1unQp9S5PlJU8ky5Dr5PGN5icCM7OCWSevSAIFfUuT9S3MicDMrGDJk9WtbxFOBGZmBWPGV7e+RTgRmJkV7DENRoxeed2I0cn6FpZbIpC0qaSZkuZJmivpuBL77ClpsaQH09f38orHzGxAEyfDpC4YMwFQ8j6pq6UriiHfVkN9wAkR8YCkMcBsSbdFxLx++82KiE/kGIeZWXYTJ7f8jb+/3J4IIuLZiHgg/bwE6AE2zut8ZmY2OJmeCCRtDEwo3j8i7sp6EkkdwHuBe0ts3l3SQ8AzwIkRMbfE96cCUwHGj2/tShszs3obMBFI+jHwWWAe8Ga6OoBMiUDS2sDVwPER8XK/zQ8AEyLiFUn7AtcCW/Q/RkR0AV0AnZ2dkeW8ZmaWTZYnggOArSJiWbUHlzSSJAlMj4hr+m8vTgwRcaOkcyWNjYhF1Z7LzMwGJ0sdwQJgZLUHliTgQqAnIn5aZp93pPshaZc0nuerPZeZmQ1e2ScCSf9JUgS0FHhQ0u+Bt54KIuLYAY79r8DngYclPZiu+w4wPv3+ecBBwFGS+oB/AodEhIt+zMzqqFLRUHf6PhuYUe2BI+IPgAbY52zg7GqPbWZmtVMpESwG/hgRz9UrGDMzq79KdQSHAX+W9DdJl0iaKmm7egVmZmb1UTYRRMRBEbEx8DHgFmB74BJJvZJurFeAZmaWrwGbj0bE45JGAW9LX4XPZmbWAiq1GvoOsDswDngUuIekYndqRLxZ7ntmZtZcKj0RHA68ClwP/BG4NyIW1yUqMzOrm7KJICK2lrQB8H5gT+CkdLiIh0haE/2yPiGamVmeKtYRRMQLwO8k3QzsDHwQ+CrwJcCJwMysBVSqI9iP5GngX4FtgbnA3cAJJEVFZmbWAio9ERxBcuP/NjA7Il6vS0RmZlZXlfoRHBgRZwDr9U8Cko7MPTIzM6uLLKOPflfSXoUFSd8G9s8vJDMzq6cs8xHsR1Jh/C1gb2BrnAjMzFpGlp7Fi9KK4/9PMhLpQR4q2sysdVRqNbSEZD6CgjWAdwEHSYqIWCfv4MzMLH+VOpSNqWcgZmbWGFkqi83MrIU5EZiZtTknAjOzNpel+SiShgNvL94/Ip7MKygzM6ufAROBpGOAU4F/AMvT1UEyY5mZmTW5LE8ExwFbRcTzeQdjZmb1l6WO4CnAE9KYmbWoLE8EC4A7JN0ALCusjIif5haVmZnVTZZE8GT6WiN9mVkr65kOs06GJU/CmPGwxzSYOLnRUVmOsow19IN6BGJmQ0DPdLh1KvQtTZaXPJEsg5NBC6s01tCZEXG8pOtZecwhACJiv1wjM7P6m3XyiiRQ0Lc0We9E0LIqPRFclr7/pB6BmNkQsKRM96By660lVBp0bnb6fmf9wjGzhhozPikOKrXeWlZuQ0xI2lTSTEnzJM2VdFyJfSTpLEnzJc2RtFNe8ZhZBntMgxGjV143YnSyPoue6dDVAWcMS957ptc6QstBnmMN9QEnRMQ2wG7A1yVt02+ffYAt0tdU4Oc5xmOtwjeb/EycDJO6YMwEQMn7pK5s9QOFiuYlTwCxoqLZfz9DXqaxhgYjIp4Fnk0/L5HUA2wMzCvabX/g0nTGs3skrSdpo/S7Zqtyq5b8TZw8uD9LVzQ3rQGfCCRtKekCSbdKur3wquYkkjqA9wL39tu0MUnP5YKF6br+358qqVtSd29vbzWntlZT6WZjjeWK5qaV5YngSuA84ALgzWpPIGlt4Grg+Ih4udrvA0REF9AF0NnZ6fmS25lvNkOXK5qbVpZE0BcRgyq7lzSSJAlMj4hrSuzyNLBp0fIm6Tqz0nyzGbr2mLZysR1UV9FsDZOlsvh6SV+TtJGkDQqvgb4kScCFQE+FcYlmAIenrYd2Axa7fsAqWt1WLZaf1alotoZSUk9bYQfpsRKrIyLeNcD3PgDMAh5mxTwG3wHGpwc4L00WZwN7A0uBL0ZEd6XjdnZ2Rnd3xV2s1XksHLOqSZodEZ0ltw2UCIYaJwIzs+pVSgRZWg2NlHSspKvS19Fp2b9ZftxXwKxuslQW/xwYCZybLn8+XfflvIKyNue+AmZ1lSURvC8idihavl3SQ3kFZOaOSWb1laXV0JuSNi8sSHoXg+hPYJaZ+wqY1VWWJ4JvATMlLQAETAC+mGtU1t7cV8CsrrLMUPZ7SVsAW6WrHo2IZZW+Y7Za3DHJrK4qzVC2V0TcLunAfpveLYkyPYXNVl+hHsB9BczqotITwYeA24FPltgWgBOB5de5a7AjYJpZ1SrNUHZq+vG0iFipd7GkzXKNypqDm3matYQsrYauLrHuqloHYk3IQ0KbtYRKdQRbA9sC6/arJ1gHGJV3YNYE3MzTrCVUqiPYCvgEsB4r1xMsAb6SY0zWLNzM06wlVKojuA64TtLuEfGnOsZkzcLNPM1aQpY6gn9Iul5Sr6TnJF2X9i62dufx52vDA+xZg2XpWXw5cA7wqXT5EOAKYNe8grIm4maeq8ctr2wIyPJEMDoiLouIvvT1K1xZbI3WKr+i3fLKhoAsTwQ3SToJ+DVJR7LPAjcWpquMiBdyjM9sVa30K9otr2wIyJIIPpO+f7Xf+kNIEoPrC6y+WmmYare8siEgy6Bz7kVsQ0sr/Yp2yysbAgZMBJKGAx8HOor3j4if5heWWQWt9CvaA+zZEJClaOh64DXgYWB5vuGYZdBqv6Ld8soaLEsi2CQits89ErOs/CvarKaythqaFBG35h6NWVb+FW1WM1kSwT3Af0kaBrxBMl1lRMQ6uUZmZmZ1kSUR/BTYHXg4IiLneMzMrM6y9Cx+CnjEScDMrDVleSJYANwh6SbgrUnr3XzUzKw1ZEkEj6WvNdKXmZm1kCw9i38wmANLuohkYpvnImK7Etv3BK4jSTIA10TEaYM5l5mZDV6WnsUzScYUWklE7DXAVy8GzgYurbDPrIj4xEAxmJlZfrIUDZ1Y9HkU8Gmgb6AvRcRdkjoGGZeZmdVJlqKh2f1W3S3pvhqdf3dJDwHPACdGxNxSO0maCkwFGD++CceTMTMbwrIUDW1QtDgM2BlYtwbnfgCYEBGvSNoXuBbYotSOEdEFdAF0dna6GauZWQ1lKRqaTVJHIJIioceAKat74oh4uejzjZLOlTQ2Ihat7rHNzCy7hs1HIOkdwD8iIiTtQvK08Xwe5zIzs/KyFA0dDNwcEUsknQLsBPwoIh4Y4HtXAHsCYyUtBE4FRgJExHnAQcBRkvqAfwKHuPeymVn9ZSka+m5EXCnpA8BHgdOBnwO7VvpSRBw6wPazSZqXmplZA2UZa+jN9P3jQFdE3IB7GJuZtYwsieBpSecDnwVulLRmxu+ZmVkTyHJD/wxwC/C/IuIlYAPgW3kGZWZm9TNgIoiIpSRjAr0qaTxJhe9f8g7MzMzqI0uroWNIWvz8gxWT1wfgeYzNzFpAllZDxwFbRYTb+Fvt9Uz3JPRmDZYlETwFLM47EGtDPdPh1qnQtzRZXvJEsgxOBmZ1VM0MZTfgGcqslmadvCIJFPQtTdY7EZjVTZZE8GT68gxlVltLnqxuvZnlIvMMZZLWTpdfyTsoaxNjxifFQaXWm1ndDNh8VNJ2kv4MzAXmSpotadv8Q7OWt8c0GDF65XUjRifrzaxusnQo6wK+GRETImICcAJwQb5hWS56pkNXB5wxLHnvmd7YeCZOhkldMGYCoOR9UpfrB8zqLEsdwVoRMbOwEBF3SForx5gsD0O1hc7Eyb7xmzVYlieCBZK+K6kjfZ1C0pLImkmlFjpm1tayJIIvAeOAa4CrgbHpOmsmbqFjZmVkaTX0InBsHWKxPLmFjpmVkaXV0G2S1itaXl/SLblGZbXVMx3eKNHq1y10zIxslcVj0+GngeQJQdK/5BeS1VT/SuKC4WvBpPNdUWtmmeoIlqfDTwMgaQLJ6KPWDEpVEgO8WWJdOUOt2amZ1VSWJ4KTgT9IuhMQsAcwNdeorHbKVgZHtjF9hmqzUzOrmSwT09wM7AT8Bvg1sHNEuI6gWVSqDM7SYsjNTs1aXqa5hyNiUUT8Ln0tyjsoq6E9ppE8yJWQpcWQm52atTxPQt/qJk6GHY5klWSQtcVQuWThZqdmLcOJoB0qQj96Lux72eDG9PHAcGYtr2JlsaThwNyI2LpO8dRXO1WEDnZMn8J3PJ2kWcuqmAgi4k1Jj0oaHxGtVyjsGbKy8cBwZi0tS/PR9UnmIbgPeLWwMiL2yy2qenFFqJlZpkTw3dyjaBSPv2NmlqkfwZ3A48DI9PP9wAM5x1Ufrgg1M8s06NxXgKuA89NVGwPXZvjeRZKek/RIme2SdJak+ZLmSNqpirhrwzNkmZllKhr6OrALcC9ARPwt46BzFwNnA5eW2b4PsEX62hX4efpeX64INbM2l6UfwbKIeL2wIGkEGQadi4i7gBcq7LI/cGkk7gHWk7RRhnisUdqhz4VZG8qSCO6U9B3gbZI+BlwJXF+Dc28MPFW0vDBdtwpJUyV1S+ru7e2twalrqNVujuWup9DnYskTQKzoc9Hs12tmmRLBSUAv8DDwVeBG4JQ8g+ovIroiojMiOseNG1fPU1fWajfHStfjwefMWlaWOoIPA7+KiAtqfO6ngU2LljdJ1zWP1emQVri5NrK3bv8YXn+l/PW4z4VZy8ryRHA48JCkeySdLumTktavwblnAIenrYd2AxZHxLM1OG79DPbmOBSeJErFsOz50vsWEkUp7nNh1vSy9CP4QkRsCRxIUqZ/DklRUUWSrgD+BGwlaaGkKZKOlHRkusuNwAJgPnAB8LVBXkPjDPbmOBSKWcrNXFZK4YnFfS7MWtKARUOSDiOZlew9wCKSJqGzBvpeRBw6wPYgaZravPaYtup8wFlujkOhmCXruQrX48HnzFpWljqCM4G/A+cBMyPi8TwDaiqDvTkOhaEtysUwakMYuXbp63GfC7OWNGAiiIixkrYFPghMk7QF8GhEfD736JrBYG6Og32SqGUFc7kY9vp/vtmbtZksQ0ysA4wHJgAdwLrA8nzDanGDGdqi1hXMHl7DzFJKiuor7CDNAf6Qvu6KiIX1CKyczs7O6O7ubmQIjdHVUaY4aQJMfbze0ZhZk5E0OyI6S23LUjS0fXqQtWsdmFVhKFQwm1lLylI0tJ2kPwNzgXmSZkvaLv/QDFgx5EO54Z3cjt/MVlOWDmVdwDcjYkJEjAdOSNe1l0aMKbRSvUAJbsdvZjWQpfnoWhExs7AQEXdIWivHmIaeRk1yX6nT15gJbsdvZjWRJREskPRd4LJ0+TCSHsHto1GT3Jct/5criM2sZrIUDX0JGAdcA1wNjE3XtY9qK2prVYzk8X3MrA7KJgJJoyQdD/yQpKJ414jYOSKOj4gX6xVgTazujbmaG3It2/t7fB8zq4NKTwSXAJ0k8xDsA5xel4hqrRY35mpuyLUcUK5Sp69WmxDHzBqmUh3BNhHxHgBJFwL31SekGqtF+X41YwrVur1/qSEsGlV5bWYtqVIieKPwISL6JNUhnBzU6sacdUyhURvAayXG9a9luX6jKq/NrCVVSgQ7SHo5/SySOYtfTj9HRKyTe3S1UM+RPnumw7KXV10/bI3aluu7l7GZ1VDZOoKIGB4R66SvMRExouhzcyQBqG+F66yTId5Ydf3IMbX9pe7WRGZWQ1majza3eo6yWe4X+bIXansetyYysxrK0qGs+dVrQpV6FUN5tjAzq6H2SAT1MtgJZwbDs4WZWY20ftFQPXmyFzNrQn4iqDX/UjezJuMnAjOzNucngoH0TIffHwfL0k5iozb0BO9m1lKcCCrpmQ43fXHlvgGvPQ83p4OvOhmYWQtw0VAl5TqILX99cIPImZkNQU4ElVQassHDOZhZi3AiqKRSRzAP52BmLcKJoJI9poFGrrq+1oPImZk1UK6JQNLekh6VNF/SSSW2HyGpV9KD6evLuQUzmIlcJk6GfX4Ja264Yt2oDWHvi1xRbGYtI7dWQ5KGA+cAHwMWAvdLmhER8/rt+puIODqvOIDVm8jFHcTMrMXl+USwCzA/IhZExOvAr4H9czxfebWcPtLMrMXkmQg2Bp4qWl6Yruvv05LmSLpK0qalDiRpqqRuSd29vb3VR+KJXMzMymp0ZfH1QEdEbA/cBlxSaqeI6IqIzojoHDduXPVn8UQuZmZl5ZkIngaKf+Fvkq57S0Q8HxHL0sVfADvnEokncjEzKyvPRHA/sIWkzSStARwCzCjeQdJGRYv7AT25ROLhoc3Mysqt1VBE9Ek6GrgFGA5cFBFzJZ0GdEfEDOBYSfsBfcALwBF5xePWP2ZmpSkiGh1DVTo7O6O7u7vRYZiZNRVJsyOis9S2RlcWm5lZgzkRZDWYnslmZk3A8xEMpGc63H5cMg9BQTU9k83Mhjg/EVRSGJqiOAkUuGeymbUIJ4JKSg1NUcw9k82sBTgRVDLQjd49k82sBTgRVDJqg/Lb3DPZzFqEE0E5PdNh2cult625oXsmm1nLcKuhcspNXL/mhnD0ovrHY2aWEz8RlFOufmDZC/WNw8wsZ04E5XjoajNrE04E5XjoajNrE04E5XjoajNrE64srsRDV5tZG/ATgZlZm3MiMDNrc04EZmZtzonAzKzNORGYmbW5ppuzWFIv8ESVXxsLtNO4EO10ve10reDrbXV5Xu+EiBhXakPTJYLBkNRdbtLmVtRO19tO1wq+3lbXqOt10ZCZWZtzIjAza3Ptkgi6Gh1AnbXT9bbTtYKvt9U15Hrboo7AzMzKa5cnAjMzK8OJwMyszbVUIpC0t6RHJc2XdFKJ7WtK+k26/V5JHQ0IsyYyXOs3Jc2TNEfS7yVNaESctTLQ9Rbt92lJIampmxxmuV5Jn0n/judKurzeMdZShn/P4yXNlPTn9N/0vo2IsxYkXSTpOUmPlNkuSWelfxZzJO2Ue1AR0RIvYDjwd+BdwBrAQ8A2/fb5GnBe+vkQ4DeNjjvHa/0wMDr9fFSzXmvW6033GwPcBdwDdDY67pz/frcA/gysny7/S6Pjzvl6u4Cj0s/bAI83Ou7VuN4PAjsBj5TZvi9wEyBgN+DevGNqpSeCXYD5EbEgIl4Hfg3s32+f/YFL0s9XAR+RpDrGWCsDXmtEzIyIpeniPcAmdY6xlrL83QL8EPgx8Fo9g8tBluv9CnBORLwIEBHP1TnGWspyvQGsk35eF3imjvHVVETcBVSa/Hx/4NJI3AOsJ2mjPGNqpUSwMfBU0fLCdF3JfSKiD1gMbFiX6Gory7UWm0LyC6NZDXi96ePzphFxQz0Dy0mWv98tgS0l3S3pHkl71y262styvd8HDpO0ELgROKY+oTVEtf+/V5tnKGtxkg4DOoEPNTqWvEgaBvwUOKLBodTTCJLioT1JnvbukvSeiHipkUHl6FDg4og4Q9LuwGWStouI5Y0OrBW00hPB08CmRcubpOtK7iNpBMkj5vN1ia62slwrkj4KnAzsFxHL6hRbHga63jHAdsAdkh4nKVed0cQVxln+fhcCMyLijYh4DPgrSWJoRlmudwrwW4CI+BMwimSAtlaU6f93LbVSIrgf2ELSZpLWIKkMntFvnxnAF9LPBwG3R1o702QGvFZJ7wXOJ0kCzVx+DANcb0QsjoixEdERER0kdSL7RUR3Y8JdbVn+LV9L8jSApLEkRUUL6hhjLWW53ieBjwBImkiSCHrrGmX9zAAOT1sP7QYsjohn8zxhyxQNRUSfpKOBW0haIVwUEXMlnQZ0R8QM4EKSR8r5JJU1hzQu4sHLeK2nA2sDV6b14U9GxH4NC3o1ZLzelpHxem8BJkmaB7wJfCsimvHpNuv1ngBcIOkbJBXHRzTpjzgkXUGSxMemdR6nAiMBIuI8kjqQfYH5wFLgi7nH1KR/lmZmViOtVDRkZmaD4ERgZtbmnAjMzNqcE4GZWZtzIjAzG8IGGqSu374T0kEm50i6Q1KmoWWcCKwppCOKnlG0fKKk79fo2BdLOqgWxxrgPAdL6pE0s9/6Dkn/lPRg0WsNSUdIOrvEcT4g6T5Jf0lfU4u2fV/S0+kxHpHUlE2GbSUXA1mHEPkJyThF2wOnAf8ny5ecCKxZLAMOTDtPDRlpD/WspgBfiYgPl9j294jYsej1epnzvQO4HDgyIrYGPgB8VdLHi3b7WUTsCBwMXJQOwWFNqtQgdZI2l3SzpNmSZknaOt20DXB7+nkmpQdnXIX/gViz6CMZivgb/Tf0/0Uv6ZX0fU9Jd0q6TtICSf9X0uT01/TDkjYvOsxHJXVL+qukT6TfHy7pdEn3p4/aXy067ixJM4B5JeI5ND3+I5J+nK77HslN+0JJp6/Gn8PXScbceQAgIhYB3wZWGcM/InpI/tzGSjpWK+an+PVqnN+Ghi7gmIjYGTgRODdd/xBwYPr5U8AYSQMOrNkyPYutLZwDzJH0H1V8ZwdgIskvqgXALyJiF0nHkYxgeXy6XwfJcMibAzMlvRs4nKR7//skrQncLenWdP+dgO3ScX7eIumdJENh7wy8CNwq6YCIOE3SXsCJZYa+2FzSg+nnuyPi62WuZ1tWDKVe0J2uX4mkXYHlJEMxnARsFhHLJK1X5tjWBCStDbyfFaMGAKyZvp8InC3pCJK5OZ4m6XlekROBNY2IeFnSpcCxwD8zfu3+wjgtkv4OFG7kD5NM3lPw23Qky79JWgBsDUwCti962liXZGC314H7+ieB1PuAOyKiNz3ndJKJSK4dIM6/p8U5tfANJaPOLgE+GxEhaQ4wXdK1GWKxoW0Y8FKpfy8R8QzpE0GaMD6dZURaFw1ZszmTpKx9raJ1faT/ltPy8DWKthWPurq8aHk5K/8Q6j/WSpDMEHVMUbn9ZhFRSCSvrs5FrIZ5JE8bxXYG5hYt/yyNd4+ImJWu+zjJE9VOwP1V1m3YEBIRLwOPSToY3pracof089iiOqH/DVyU5ZhOBNZUIuIFkuGIpxStfpwVN8f9SAfwqtLBkoal9QbvAh4lGQTtKEkjASRtKWmtSgcB7gM+lP6HHE4yjv6dg4innHOAIyTtmMa0IUlRVNnisvTGsGlEzAT+jeTJZu0axmQ5Sgep+xOwlaSFkqYAk4Epkh4i+RFQqBTeE3hU0l+BtwPTspzDvwqsGZ0BHF20fAFwXfqf4mYG92v9SZKb+DokLXJek/QLkrqDB5QUxvYCB1Q6SEQ8q2Ty9ZkkTxQ3RMR1g4in4AhJxefcDTiMZCTOMek5zoyI6yscYzjwK0nrpvuf1cIT2LSciDi0zKZVmpRGxFUk0/BWxaOPmpm1ORcNmZm1OScCM7M250RgZtbmnAjMzNqcE4GZWZtzIjAza3NOBGZmbe5/AMSz7X1pkXTBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_FLOPS(data, color, title):\n",
    "    plt.plot(data[\"FLOPs\"], data[\"result.power\"], \"o\", color = color)\n",
    "    plt.xlabel(\"Number of FLOPs\")\n",
    "    plt.ylabel(\"Power consumption in kWh\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "plot_FLOPS(result_dense, \"blue\", \"Dense NNs\")\n",
    "plot_FLOPS(result_conv, \"darkorange\", \"Convolutional NNs\")\n",
    "plot_FLOPS(result_pretrained, \"green\", \"Pretrained NNs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c12ad18",
   "metadata": {},
   "source": [
    "One can see that (especially for more complicated models) the number of FLOPs does not seem to be correlated with the power consumption in our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef29cc83",
   "metadata": {},
   "source": [
    "## Layerwise power consumption vs. combined power consumption\n",
    "In our dataset we measured the combined power consumption for a forward pass (through all layers) and the power consumption for a forward pass through each layer, individually.\n",
    "We will now investigate if the combined power consumption is close to the sum of the power consumption of every layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de6f034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"power_additive\"] = result.apply(lambda x: sum(x[\"result.power_layerwise\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec0541f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"additivity_factor\"] = result.apply(lambda x: x[\"result.power\"]/x[\"power_additive\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abf362f",
   "metadata": {},
   "source": [
    "The additivity_factor of a model $M$ consisting of layers $l_1, \\dots, l_n$ is defined as\n",
    "$$\\text{additivity_factor}(M) = \\frac{P(M)}{\\sum_{l \\in M} P(l)}$$\n",
    "where $P(x)$ denotes the measured power consumption of a forward pass through $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62861f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.violinplot(result[\"additivity_factor\"])\n",
    "plt.ylabel(\"additivity factor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9986f6be",
   "metadata": {},
   "source": [
    "\"The whole is more than the sum of its parts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a8e0c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_dense = result[result.loc[:,\"config.model_file\"] == \"dataset.models.dense\"]\n",
    "result_conv = result[result.loc[:,\"config.model_file\"] == \"dataset.models.conv\"]\n",
    "result_pretrained = result[result.loc[:,\"config.model_file\"] == \"dataset.models.pretrained\"]\n",
    "results = [result_dense, result_conv, result_pretrained]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot()\n",
    "ax1.violinplot([res[\"additivity_factor\"] for res in results])\n",
    "ax1.set_xticks([1,2,3], labels = [\"Dense NNs\", \"Convolutional NNs\", \"Pretrained models\"])\n",
    "ax1.set_ylabel(\"additivity factor\")\n",
    "plt.show()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14cc2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2421064c",
   "metadata": {},
   "source": [
    "# Different model types\n",
    "Let us now look in more detail at the different types of models in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9669dc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dense = result[result.loc[:,\"config.model_file\"] == \"dataset.models.dense\"]\n",
    "result_conv = result[result.loc[:,\"config.model_file\"] == \"dataset.models.conv\"]\n",
    "result_pretrained = result[result.loc[:,\"config.model_file\"] == \"dataset.models.pretrained\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4343121e",
   "metadata": {},
   "source": [
    "## Fully connected NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15241918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "for hidden_size in range(10,51,5):\n",
    "    vis = result_dense[result_dense.loc[:,\"config.params.hidden_size\"] == hidden_size]\n",
    "    plt.plot(vis[\"config.params.number_layers\"], vis[\"result.power\"], \"o\", label = f\"hidden size: {hidden_size}\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"number of layers\")\n",
    "plt.ylabel(\"power consumption in kWh\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ebbe7d",
   "metadata": {},
   "source": [
    "One can see that the hidden size of a fully connected network seems to have no influence on the power consumption. In contrast, the number of layers seems to be linearly correlated with the power consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5643d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for hidden_size in range(10,51,5):\n",
    "    vis = result_dense[result_dense.loc[:,\"config.params.hidden_size\"] == hidden_size]\n",
    "    plt.plot(vis[\"config.params.number_layers\"], vis[\"additivity_factor\"], \"o\", label = f\"hidden size: {hidden_size}\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"number of layers\")\n",
    "plt.ylabel(\"additivity_factor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2106cf",
   "metadata": {},
   "source": [
    "So the very high additivity factor of 4 seems to only occur for two layers. Not sure why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3a071c",
   "metadata": {},
   "source": [
    "## Convolutional NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba9ae524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(result_conv[\"config.params.number_layers\"], result_conv[\"result.power\"], \"o\")\n",
    "plt.xlabel(\"number of layers\")\n",
    "plt.ylabel(\"power consumption in kWh\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f6e8520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(result_conv[\"config.params.number_layers\"], result_conv[\"additivity_factor\"], \"o\")\n",
    "plt.xlabel(\"number of layers\")\n",
    "plt.ylabel(\"additivity factor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b577a902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(result_conv[\"FLOPs\"], result_conv[\"additivity_factor\"], \"o\", color = \"darkorange\")\n",
    "plt.xlabel(\"FLOPs\")\n",
    "plt.ylabel(\"additivity factor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c345c08c",
   "metadata": {},
   "source": [
    "## Pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e43a9e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"layers\"] = result.apply(lambda x: len(x[\"model\"].layers), axis = 1)\n",
    "result_pretrained = result[result.loc[:,\"config.model_file\"] == \"dataset.models.pretrained\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "929710b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(result_pretrained[\"layers\"], result_pretrained[\"result.power\"], \"o\")\n",
    "plt.xlabel(\"number of layers\")\n",
    "plt.ylabel(\"power consumption in kWh\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "faad2101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(result_pretrained[\"layers\"], result_pretrained[\"additivity_factor\"], \"o\")\n",
    "plt.xlabel(\"number of layers\")\n",
    "plt.ylabel(\"additivity factor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fdbcdfe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78          DenseNet121\n",
       "79          DenseNet169\n",
       "80       EfficientNetB0\n",
       "81       EfficientNetB1\n",
       "82       EfficientNetB2\n",
       "83       EfficientNetB3\n",
       "84       EfficientNetB4\n",
       "85     EfficientNetV2B0\n",
       "86     EfficientNetV2B1\n",
       "87     EfficientNetV2B2\n",
       "88      EfficientNetV2S\n",
       "89          InceptionV3\n",
       "90            MobileNet\n",
       "91          MobileNetV2\n",
       "92            ResNet101\n",
       "93          ResNet101V2\n",
       "94            ResNet152\n",
       "95          ResNet152V2\n",
       "96             ResNet50\n",
       "97           ResNet50V2\n",
       "98          ResNetRS101\n",
       "99           ResNetRS50\n",
       "100               VGG16\n",
       "101               VGG19\n",
       "102            Xception\n",
       "Name: result.name, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_pretrained[\"result.name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd82850d",
   "metadata": {},
   "source": [
    "# Layer analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "be58b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_pretrained = []\n",
    "conv_simple = []\n",
    "pool_pretrained = []\n",
    "pool_simple = []\n",
    "dense_simple = []\n",
    "dense_pretrained = []\n",
    "\n",
    "for _,x in result.iterrows():\n",
    "    for layer, power in zip(x[\"model\"].layers, x[\"result.power_layerwise\"]):\n",
    "        if x[\"result.type\"] == \"simple\":\n",
    "            if \"dense\" in layer.__class__.__name__.lower():\n",
    "                dense_simple.append(power)\n",
    "            elif \"conv\" in layer.__class__.__name__.lower():\n",
    "                conv_simple.append(power)\n",
    "            elif \"pool\" in layer.__class__.__name__.lower():\n",
    "                pool_simple.append(power)\n",
    "        else:\n",
    "            if \"dense\" in layer.__class__.__name__.lower():\n",
    "                dense_pretrained.append(power)\n",
    "            elif \"conv\" in layer.__class__.__name__.lower():\n",
    "                conv_pretrained.append(power)\n",
    "            elif \"pool\" in layer.__class__.__name__.lower():\n",
    "                pool_pretrained.append(power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "67af64e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Remove one outlier:\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot()\n",
    "ax1.violinplot([conv_simple, conv_pretrained, conv_simple + conv_pretrained])\n",
    "plt.ylabel(\"power consumption in kWh\")\n",
    "ax1.set_xticks([1,2,3], labels = [\"Simple models\", \"Pretrained models\", \"Combined\"])\n",
    "plt.title(\"Convolutional layers\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "27aa5f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot()\n",
    "ax1.violinplot([pool_simple, pool_pretrained, pool_simple + pool_pretrained])\n",
    "plt.ylabel(\"power consumption in kWh\")\n",
    "ax1.set_xticks([1,2,3], labels = [\"Simple models\", \"Pretrained models\", \"Combined\"])\n",
    "plt.title(\"Pooling layers\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "41546129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot()\n",
    "ax1.violinplot([dense_simple, dense_pretrained, dense_simple + dense_pretrained])\n",
    "plt.ylabel(\"power consumption in kWh\")\n",
    "#ax1.set_ylim(0,2e-8)\n",
    "ax1.set_xticks([1,2,3], labels = [\"Simple models\", \"Pretrained models\", \"Combined\"])\n",
    "plt.title(\"Dense layers\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca17c7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
