{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c19f6503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c96a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40b1f5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5497e16e765848ac9346abe953205b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a5cb338e9149dc8e0c55212583a05c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = seml.get_results(\"dataset_experiment6\", to_data_frame = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af1541ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce68467c7be4b9483134b8c817595ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64df281ece404e8697659df1bfe49ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = seml.get_results(\"datset_experiment6\", to_data_frame = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d92af32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>config.overwrite</th>\n",
       "      <th>config.db_collection</th>\n",
       "      <th>config.batch_size</th>\n",
       "      <th>config.model_file</th>\n",
       "      <th>config.model_index</th>\n",
       "      <th>config.number_forward_passes</th>\n",
       "      <th>config.seed</th>\n",
       "      <th>result.name</th>\n",
       "      <th>result.power</th>\n",
       "      <th>result.power_layerwise</th>\n",
       "      <th>result.model.class_name</th>\n",
       "      <th>result.model.config.name</th>\n",
       "      <th>result.model.config.layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>datset_experiment6</td>\n",
       "      <td>16</td>\n",
       "      <td>dataset.models.dense</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>889273469</td>\n",
       "      <td>Dense 2-layers</td>\n",
       "      <td>1.317396e-08</td>\n",
       "      <td>[6.594850572582439e-09, 6.429890697023957e-09]</td>\n",
       "      <td>Sequential</td>\n",
       "      <td>sequential</td>\n",
       "      <td>[{'class_name': 'InputLayer', 'config': {'batc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>datset_experiment6</td>\n",
       "      <td>16</td>\n",
       "      <td>dataset.models.dense</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>279643018</td>\n",
       "      <td>Dense 3-layers</td>\n",
       "      <td>1.329794e-08</td>\n",
       "      <td>[6.762513501498269e-09, 6.524168267780167e-09,...</td>\n",
       "      <td>Sequential</td>\n",
       "      <td>sequential</td>\n",
       "      <td>[{'class_name': 'InputLayer', 'config': {'batc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>datset_experiment6</td>\n",
       "      <td>16</td>\n",
       "      <td>dataset.models.dense</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>486806917</td>\n",
       "      <td>Dense 4-layers</td>\n",
       "      <td>4.140278e-09</td>\n",
       "      <td>[1.6767953403711317e-09, 1.731779547762871e-09...</td>\n",
       "      <td>Sequential</td>\n",
       "      <td>sequential</td>\n",
       "      <td>[{'class_name': 'InputLayer', 'config': {'batc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>datset_experiment6</td>\n",
       "      <td>16</td>\n",
       "      <td>dataset.models.dense</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>516127578</td>\n",
       "      <td>Dense 5-layers</td>\n",
       "      <td>4.545500e-09</td>\n",
       "      <td>[1.7734681543244255e-09, 1.7733712011708152e-0...</td>\n",
       "      <td>Sequential</td>\n",
       "      <td>sequential</td>\n",
       "      <td>[{'class_name': 'InputLayer', 'config': {'batc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>datset_experiment6</td>\n",
       "      <td>16</td>\n",
       "      <td>dataset.models.dense</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>192850020</td>\n",
       "      <td>Dense 6-layers</td>\n",
       "      <td>5.391746e-09</td>\n",
       "      <td>[1.7237906573428049e-09, 1.622985592575868e-09...</td>\n",
       "      <td>Sequential</td>\n",
       "      <td>sequential</td>\n",
       "      <td>[{'class_name': 'InputLayer', 'config': {'batc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id  config.overwrite config.db_collection  config.batch_size  \\\n",
       "0    1                 1   datset_experiment6                 16   \n",
       "1    2                 2   datset_experiment6                 16   \n",
       "2    3                 3   datset_experiment6                 16   \n",
       "3    4                 4   datset_experiment6                 16   \n",
       "4    5                 5   datset_experiment6                 16   \n",
       "\n",
       "      config.model_file  config.model_index  config.number_forward_passes  \\\n",
       "0  dataset.models.dense                   2                            50   \n",
       "1  dataset.models.dense                   3                            50   \n",
       "2  dataset.models.dense                   4                            50   \n",
       "3  dataset.models.dense                   5                            50   \n",
       "4  dataset.models.dense                   6                            50   \n",
       "\n",
       "   config.seed     result.name  result.power  \\\n",
       "0    889273469  Dense 2-layers  1.317396e-08   \n",
       "1    279643018  Dense 3-layers  1.329794e-08   \n",
       "2    486806917  Dense 4-layers  4.140278e-09   \n",
       "3    516127578  Dense 5-layers  4.545500e-09   \n",
       "4    192850020  Dense 6-layers  5.391746e-09   \n",
       "\n",
       "                              result.power_layerwise result.model.class_name  \\\n",
       "0     [6.594850572582439e-09, 6.429890697023957e-09]              Sequential   \n",
       "1  [6.762513501498269e-09, 6.524168267780167e-09,...              Sequential   \n",
       "2  [1.6767953403711317e-09, 1.731779547762871e-09...              Sequential   \n",
       "3  [1.7734681543244255e-09, 1.7733712011708152e-0...              Sequential   \n",
       "4  [1.7237906573428049e-09, 1.622985592575868e-09...              Sequential   \n",
       "\n",
       "  result.model.config.name                         result.model.config.layers  \n",
       "0               sequential  [{'class_name': 'InputLayer', 'config': {'batc...  \n",
       "1               sequential  [{'class_name': 'InputLayer', 'config': {'batc...  \n",
       "2               sequential  [{'class_name': 'InputLayer', 'config': {'batc...  \n",
       "3               sequential  [{'class_name': 'InputLayer', 'config': {'batc...  \n",
       "4               sequential  [{'class_name': 'InputLayer', 'config': {'batc...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7ca699d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>config.overwrite</th>\n",
       "      <th>config.db_collection</th>\n",
       "      <th>config.batch_size</th>\n",
       "      <th>config.model_file</th>\n",
       "      <th>config.model_index</th>\n",
       "      <th>config.number_forward_passes</th>\n",
       "      <th>config.seed</th>\n",
       "      <th>result.name</th>\n",
       "      <th>result.power</th>\n",
       "      <th>result.power_layerwise</th>\n",
       "      <th>result.model.class_name</th>\n",
       "      <th>result.model.config.name</th>\n",
       "      <th>result.model.config.layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>datset_experiment6</td>\n",
       "      <td>16</td>\n",
       "      <td>dataset.models.dense</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>192850020</td>\n",
       "      <td>Dense 6-layers</td>\n",
       "      <td>5.391746e-09</td>\n",
       "      <td>[1.7237906573428049e-09, 1.622985592575868e-09...</td>\n",
       "      <td>Sequential</td>\n",
       "      <td>sequential</td>\n",
       "      <td>[{'class_name': 'InputLayer', 'config': {'batc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>datset_experiment6</td>\n",
       "      <td>16</td>\n",
       "      <td>dataset.models.dense</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>770121828</td>\n",
       "      <td>Dense 7-layers</td>\n",
       "      <td>5.566577e-09</td>\n",
       "      <td>[1.7640407514890036e-09, 1.6794869868490428e-0...</td>\n",
       "      <td>Sequential</td>\n",
       "      <td>sequential</td>\n",
       "      <td>[{'class_name': 'InputLayer', 'config': {'batc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>datset_experiment6</td>\n",
       "      <td>16</td>\n",
       "      <td>dataset.models.dense</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>474167282</td>\n",
       "      <td>Dense 8-layers</td>\n",
       "      <td>6.273305e-09</td>\n",
       "      <td>[1.7279056281844778e-09, 1.7649032366646658e-0...</td>\n",
       "      <td>Sequential</td>\n",
       "      <td>sequential</td>\n",
       "      <td>[{'class_name': 'InputLayer', 'config': {'batc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>datset_experiment6</td>\n",
       "      <td>16</td>\n",
       "      <td>dataset.models.dense</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>301861407</td>\n",
       "      <td>Dense 9-layers</td>\n",
       "      <td>3.161635e-08</td>\n",
       "      <td>[1.0145051029340952e-08, 9.855710097923486e-09...</td>\n",
       "      <td>Sequential</td>\n",
       "      <td>sequential</td>\n",
       "      <td>[{'class_name': 'InputLayer', 'config': {'batc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>datset_experiment6</td>\n",
       "      <td>16</td>\n",
       "      <td>dataset.models.dense</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>863721593</td>\n",
       "      <td>Dense 10-layers</td>\n",
       "      <td>6.136569e-08</td>\n",
       "      <td>[1.1232037013597198e-08, 1.1865133152399321e-0...</td>\n",
       "      <td>Sequential</td>\n",
       "      <td>sequential</td>\n",
       "      <td>[{'class_name': 'InputLayer', 'config': {'batc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id  config.overwrite config.db_collection  config.batch_size  \\\n",
       "4    5                 5   datset_experiment6                 16   \n",
       "5    6                 6   datset_experiment6                 16   \n",
       "6    7                 7   datset_experiment6                 16   \n",
       "7    8                 8   datset_experiment6                 16   \n",
       "8    9                 9   datset_experiment6                 16   \n",
       "\n",
       "      config.model_file  config.model_index  config.number_forward_passes  \\\n",
       "4  dataset.models.dense                   6                            50   \n",
       "5  dataset.models.dense                   7                            50   \n",
       "6  dataset.models.dense                   8                            50   \n",
       "7  dataset.models.dense                   9                            50   \n",
       "8  dataset.models.dense                  10                            50   \n",
       "\n",
       "   config.seed      result.name  result.power  \\\n",
       "4    192850020   Dense 6-layers  5.391746e-09   \n",
       "5    770121828   Dense 7-layers  5.566577e-09   \n",
       "6    474167282   Dense 8-layers  6.273305e-09   \n",
       "7    301861407   Dense 9-layers  3.161635e-08   \n",
       "8    863721593  Dense 10-layers  6.136569e-08   \n",
       "\n",
       "                              result.power_layerwise result.model.class_name  \\\n",
       "4  [1.7237906573428049e-09, 1.622985592575868e-09...              Sequential   \n",
       "5  [1.7640407514890036e-09, 1.6794869868490428e-0...              Sequential   \n",
       "6  [1.7279056281844778e-09, 1.7649032366646658e-0...              Sequential   \n",
       "7  [1.0145051029340952e-08, 9.855710097923486e-09...              Sequential   \n",
       "8  [1.1232037013597198e-08, 1.1865133152399321e-0...              Sequential   \n",
       "\n",
       "  result.model.config.name                         result.model.config.layers  \n",
       "4               sequential  [{'class_name': 'InputLayer', 'config': {'batc...  \n",
       "5               sequential  [{'class_name': 'InputLayer', 'config': {'batc...  \n",
       "6               sequential  [{'class_name': 'InputLayer', 'config': {'batc...  \n",
       "7               sequential  [{'class_name': 'InputLayer', 'config': {'batc...  \n",
       "8               sequential  [{'class_name': 'InputLayer', 'config': {'batc...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cfa558c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-03 11:00:26.080776: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-03 11:00:26.080811: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d173676",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-03 11:04:50.494074: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-03 11:04:50.494200: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-03 11:04:50.494285: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-03 11:04:50.494371: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-06-03 11:04:50.494456: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-06-03 11:04:50.494537: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-03 11:04:50.494619: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-03 11:04:50.494702: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-06-03 11:04:50.494718: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-06-03 11:04:50.495701: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "example = tf.keras.Sequential([tf.keras.layers.Dense(10,activation = \"relu\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07eb43e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f8dcfbcc6a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cec15980",
   "metadata": {},
   "outputs": [],
   "source": [
    "denseNet = tf.keras.applications.DenseNet121(weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5784b27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, 224, 224, 3)]\n",
      "(None, 224, 224, 3)\n",
      "(None, 230, 230, 3)\n",
      "(None, 112, 112, 64)\n",
      "(None, 112, 112, 64)\n",
      "(None, 112, 112, 64)\n",
      "(None, 114, 114, 64)\n",
      "(None, 56, 56, 64)\n",
      "(None, 56, 56, 64)\n",
      "(None, 56, 56, 64)\n",
      "(None, 56, 56, 128)\n",
      "(None, 56, 56, 128)\n",
      "(None, 56, 56, 128)\n",
      "[(None, 56, 56, 64), (None, 56, 56, 32)]\n",
      "(None, 56, 56, 96)\n",
      "(None, 56, 56, 96)\n",
      "(None, 56, 56, 96)\n",
      "(None, 56, 56, 128)\n",
      "(None, 56, 56, 128)\n",
      "(None, 56, 56, 128)\n",
      "[(None, 56, 56, 96), (None, 56, 56, 32)]\n",
      "(None, 56, 56, 128)\n",
      "(None, 56, 56, 128)\n",
      "(None, 56, 56, 128)\n",
      "(None, 56, 56, 128)\n",
      "(None, 56, 56, 128)\n",
      "(None, 56, 56, 128)\n",
      "[(None, 56, 56, 128), (None, 56, 56, 32)]\n",
      "(None, 56, 56, 160)\n",
      "(None, 56, 56, 160)\n",
      "(None, 56, 56, 160)\n",
      "(None, 56, 56, 128)\n",
      "(None, 56, 56, 128)\n",
      "(None, 56, 56, 128)\n",
      "[(None, 56, 56, 160), (None, 56, 56, 32)]\n",
      "(None, 56, 56, 192)\n",
      "(None, 56, 56, 192)\n",
      "(None, 56, 56, 192)\n",
      "(None, 56, 56, 128)\n",
      "(None, 56, 56, 128)\n",
      "(None, 56, 56, 128)\n",
      "[(None, 56, 56, 192), (None, 56, 56, 32)]\n",
      "(None, 56, 56, 224)\n",
      "(None, 56, 56, 224)\n",
      "(None, 56, 56, 224)\n",
      "(None, 56, 56, 128)\n",
      "(None, 56, 56, 128)\n",
      "(None, 56, 56, 128)\n",
      "[(None, 56, 56, 224), (None, 56, 56, 32)]\n",
      "(None, 56, 56, 256)\n",
      "(None, 56, 56, 256)\n",
      "(None, 56, 56, 256)\n",
      "(None, 56, 56, 128)\n",
      "(None, 28, 28, 128)\n",
      "(None, 28, 28, 128)\n",
      "(None, 28, 28, 128)\n",
      "(None, 28, 28, 128)\n",
      "(None, 28, 28, 128)\n",
      "(None, 28, 28, 128)\n",
      "[(None, 28, 28, 128), (None, 28, 28, 32)]\n",
      "(None, 28, 28, 160)\n",
      "(None, 28, 28, 160)\n",
      "(None, 28, 28, 160)\n",
      "(None, 28, 28, 128)\n",
      "(None, 28, 28, 128)\n",
      "(None, 28, 28, 128)\n",
      "[(None, 28, 28, 160), (None, 28, 28, 32)]\n",
      "(None, 28, 28, 192)\n",
      "(None, 28, 28, 192)\n",
      "(None, 28, 28, 192)\n",
      "(None, 28, 28, 128)\n",
      "(None, 28, 28, 128)\n",
      "(None, 28, 28, 128)\n",
      "[(None, 28, 28, 192), (None, 28, 28, 32)]\n",
      "(None, 28, 28, 224)\n",
      "(None, 28, 28, 224)\n",
      "(None, 28, 28, 224)\n",
      "(None, 28, 28, 128)\n",
      "(None, 28, 28, 128)\n",
      "(None, 28, 28, 128)\n",
      "[(None, 28, 28, 224), (None, 28, 28, 32)]\n",
      "(None, 28, 28, 256)\n",
      "(None, 28, 28, 256)\n",
      "(None, 28, 28, 256)\n",
      "(None, 28, 28, 128)\n",
      "(None, 28, 28, 128)\n",
      "(None, 28, 28, 128)\n",
      "[(None, 28, 28, 256), (None, 28, 28, 32)]\n",
      "(None, 28, 28, 288)\n",
      "(None, 28, 28, 288)\n",
      "(None, 28, 28, 288)\n",
      "(None, 28, 28, 128)\n",
      "(None, 28, 28, 128)\n",
      "(None, 28, 28, 128)\n",
      "[(None, 28, 28, 288), (None, 28, 28, 32)]\n",
      "(None, 28, 28, 320)\n",
      "(None, 28, 28, 320)\n",
      "(None, 28, 28, 320)\n",
      "(None, 28, 28, 128)\n",
      "(None, 28, 28, 128)\n",
      "(None, 28, 28, 128)\n",
      "[(None, 28, 28, 320), (None, 28, 28, 32)]\n",
      "(None, 28, 28, 352)\n",
      "(None, 28, 28, 352)\n",
      "(None, 28, 28, 352)\n",
      "(None, 28, 28, 128)\n",
      "(None, 28, 28, 128)\n",
      "(None, 28, 28, 128)\n",
      "[(None, 28, 28, 352), (None, 28, 28, 32)]\n",
      "(None, 28, 28, 384)\n",
      "(None, 28, 28, 384)\n",
      "(None, 28, 28, 384)\n",
      "(None, 28, 28, 128)\n",
      "(None, 28, 28, 128)\n",
      "(None, 28, 28, 128)\n",
      "[(None, 28, 28, 384), (None, 28, 28, 32)]\n",
      "(None, 28, 28, 416)\n",
      "(None, 28, 28, 416)\n",
      "(None, 28, 28, 416)\n",
      "(None, 28, 28, 128)\n",
      "(None, 28, 28, 128)\n",
      "(None, 28, 28, 128)\n",
      "[(None, 28, 28, 416), (None, 28, 28, 32)]\n",
      "(None, 28, 28, 448)\n",
      "(None, 28, 28, 448)\n",
      "(None, 28, 28, 448)\n",
      "(None, 28, 28, 128)\n",
      "(None, 28, 28, 128)\n",
      "(None, 28, 28, 128)\n",
      "[(None, 28, 28, 448), (None, 28, 28, 32)]\n",
      "(None, 28, 28, 480)\n",
      "(None, 28, 28, 480)\n",
      "(None, 28, 28, 480)\n",
      "(None, 28, 28, 128)\n",
      "(None, 28, 28, 128)\n",
      "(None, 28, 28, 128)\n",
      "[(None, 28, 28, 480), (None, 28, 28, 32)]\n",
      "(None, 28, 28, 512)\n",
      "(None, 28, 28, 512)\n",
      "(None, 28, 28, 512)\n",
      "(None, 28, 28, 256)\n",
      "(None, 14, 14, 256)\n",
      "(None, 14, 14, 256)\n",
      "(None, 14, 14, 256)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "[(None, 14, 14, 256), (None, 14, 14, 32)]\n",
      "(None, 14, 14, 288)\n",
      "(None, 14, 14, 288)\n",
      "(None, 14, 14, 288)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "[(None, 14, 14, 288), (None, 14, 14, 32)]\n",
      "(None, 14, 14, 320)\n",
      "(None, 14, 14, 320)\n",
      "(None, 14, 14, 320)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "[(None, 14, 14, 320), (None, 14, 14, 32)]\n",
      "(None, 14, 14, 352)\n",
      "(None, 14, 14, 352)\n",
      "(None, 14, 14, 352)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "[(None, 14, 14, 352), (None, 14, 14, 32)]\n",
      "(None, 14, 14, 384)\n",
      "(None, 14, 14, 384)\n",
      "(None, 14, 14, 384)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "[(None, 14, 14, 384), (None, 14, 14, 32)]\n",
      "(None, 14, 14, 416)\n",
      "(None, 14, 14, 416)\n",
      "(None, 14, 14, 416)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "[(None, 14, 14, 416), (None, 14, 14, 32)]\n",
      "(None, 14, 14, 448)\n",
      "(None, 14, 14, 448)\n",
      "(None, 14, 14, 448)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "[(None, 14, 14, 448), (None, 14, 14, 32)]\n",
      "(None, 14, 14, 480)\n",
      "(None, 14, 14, 480)\n",
      "(None, 14, 14, 480)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "[(None, 14, 14, 480), (None, 14, 14, 32)]\n",
      "(None, 14, 14, 512)\n",
      "(None, 14, 14, 512)\n",
      "(None, 14, 14, 512)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "[(None, 14, 14, 512), (None, 14, 14, 32)]\n",
      "(None, 14, 14, 544)\n",
      "(None, 14, 14, 544)\n",
      "(None, 14, 14, 544)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "[(None, 14, 14, 544), (None, 14, 14, 32)]\n",
      "(None, 14, 14, 576)\n",
      "(None, 14, 14, 576)\n",
      "(None, 14, 14, 576)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "[(None, 14, 14, 576), (None, 14, 14, 32)]\n",
      "(None, 14, 14, 608)\n",
      "(None, 14, 14, 608)\n",
      "(None, 14, 14, 608)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "[(None, 14, 14, 608), (None, 14, 14, 32)]\n",
      "(None, 14, 14, 640)\n",
      "(None, 14, 14, 640)\n",
      "(None, 14, 14, 640)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "[(None, 14, 14, 640), (None, 14, 14, 32)]\n",
      "(None, 14, 14, 672)\n",
      "(None, 14, 14, 672)\n",
      "(None, 14, 14, 672)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "[(None, 14, 14, 672), (None, 14, 14, 32)]\n",
      "(None, 14, 14, 704)\n",
      "(None, 14, 14, 704)\n",
      "(None, 14, 14, 704)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "[(None, 14, 14, 704), (None, 14, 14, 32)]\n",
      "(None, 14, 14, 736)\n",
      "(None, 14, 14, 736)\n",
      "(None, 14, 14, 736)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "[(None, 14, 14, 736), (None, 14, 14, 32)]\n",
      "(None, 14, 14, 768)\n",
      "(None, 14, 14, 768)\n",
      "(None, 14, 14, 768)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "[(None, 14, 14, 768), (None, 14, 14, 32)]\n",
      "(None, 14, 14, 800)\n",
      "(None, 14, 14, 800)\n",
      "(None, 14, 14, 800)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "[(None, 14, 14, 800), (None, 14, 14, 32)]\n",
      "(None, 14, 14, 832)\n",
      "(None, 14, 14, 832)\n",
      "(None, 14, 14, 832)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "[(None, 14, 14, 832), (None, 14, 14, 32)]\n",
      "(None, 14, 14, 864)\n",
      "(None, 14, 14, 864)\n",
      "(None, 14, 14, 864)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "[(None, 14, 14, 864), (None, 14, 14, 32)]\n",
      "(None, 14, 14, 896)\n",
      "(None, 14, 14, 896)\n",
      "(None, 14, 14, 896)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "[(None, 14, 14, 896), (None, 14, 14, 32)]\n",
      "(None, 14, 14, 928)\n",
      "(None, 14, 14, 928)\n",
      "(None, 14, 14, 928)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "[(None, 14, 14, 928), (None, 14, 14, 32)]\n",
      "(None, 14, 14, 960)\n",
      "(None, 14, 14, 960)\n",
      "(None, 14, 14, 960)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "[(None, 14, 14, 960), (None, 14, 14, 32)]\n",
      "(None, 14, 14, 992)\n",
      "(None, 14, 14, 992)\n",
      "(None, 14, 14, 992)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "(None, 14, 14, 128)\n",
      "[(None, 14, 14, 992), (None, 14, 14, 32)]\n",
      "(None, 14, 14, 1024)\n",
      "(None, 14, 14, 1024)\n",
      "(None, 14, 14, 1024)\n",
      "(None, 14, 14, 512)\n",
      "(None, 7, 7, 512)\n",
      "(None, 7, 7, 512)\n",
      "(None, 7, 7, 512)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "[(None, 7, 7, 512), (None, 7, 7, 32)]\n",
      "(None, 7, 7, 544)\n",
      "(None, 7, 7, 544)\n",
      "(None, 7, 7, 544)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "[(None, 7, 7, 544), (None, 7, 7, 32)]\n",
      "(None, 7, 7, 576)\n",
      "(None, 7, 7, 576)\n",
      "(None, 7, 7, 576)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "[(None, 7, 7, 576), (None, 7, 7, 32)]\n",
      "(None, 7, 7, 608)\n",
      "(None, 7, 7, 608)\n",
      "(None, 7, 7, 608)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "[(None, 7, 7, 608), (None, 7, 7, 32)]\n",
      "(None, 7, 7, 640)\n",
      "(None, 7, 7, 640)\n",
      "(None, 7, 7, 640)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "[(None, 7, 7, 640), (None, 7, 7, 32)]\n",
      "(None, 7, 7, 672)\n",
      "(None, 7, 7, 672)\n",
      "(None, 7, 7, 672)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "[(None, 7, 7, 672), (None, 7, 7, 32)]\n",
      "(None, 7, 7, 704)\n",
      "(None, 7, 7, 704)\n",
      "(None, 7, 7, 704)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "[(None, 7, 7, 704), (None, 7, 7, 32)]\n",
      "(None, 7, 7, 736)\n",
      "(None, 7, 7, 736)\n",
      "(None, 7, 7, 736)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "[(None, 7, 7, 736), (None, 7, 7, 32)]\n",
      "(None, 7, 7, 768)\n",
      "(None, 7, 7, 768)\n",
      "(None, 7, 7, 768)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "[(None, 7, 7, 768), (None, 7, 7, 32)]\n",
      "(None, 7, 7, 800)\n",
      "(None, 7, 7, 800)\n",
      "(None, 7, 7, 800)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "[(None, 7, 7, 800), (None, 7, 7, 32)]\n",
      "(None, 7, 7, 832)\n",
      "(None, 7, 7, 832)\n",
      "(None, 7, 7, 832)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "[(None, 7, 7, 832), (None, 7, 7, 32)]\n",
      "(None, 7, 7, 864)\n",
      "(None, 7, 7, 864)\n",
      "(None, 7, 7, 864)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "[(None, 7, 7, 864), (None, 7, 7, 32)]\n",
      "(None, 7, 7, 896)\n",
      "(None, 7, 7, 896)\n",
      "(None, 7, 7, 896)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "[(None, 7, 7, 896), (None, 7, 7, 32)]\n",
      "(None, 7, 7, 928)\n",
      "(None, 7, 7, 928)\n",
      "(None, 7, 7, 928)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "[(None, 7, 7, 928), (None, 7, 7, 32)]\n",
      "(None, 7, 7, 960)\n",
      "(None, 7, 7, 960)\n",
      "(None, 7, 7, 960)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "[(None, 7, 7, 960), (None, 7, 7, 32)]\n",
      "(None, 7, 7, 992)\n",
      "(None, 7, 7, 992)\n",
      "(None, 7, 7, 992)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "(None, 7, 7, 128)\n",
      "[(None, 7, 7, 992), (None, 7, 7, 32)]\n",
      "(None, 7, 7, 1024)\n",
      "(None, 7, 7, 1024)\n",
      "(None, 7, 7, 1024)\n",
      "(None, 1024)\n"
     ]
    }
   ],
   "source": [
    "for layers in denseNet.layers:\n",
    "    print(layers.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3723be6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Concatenate' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdenseNet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m13\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Concatenate' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "denseNet.layers[13].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1e5af7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"densenet121\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1/conv (Conv2D)            (None, 112, 112, 64  9408        ['zero_padding2d[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1/bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1/conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1/relu (Activation)        (None, 112, 112, 64  0           ['conv1/bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadding2  (None, 114, 114, 64  0          ['conv1/relu[0][0]']             \n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " pool1 (MaxPooling2D)           (None, 56, 56, 64)   0           ['zero_padding2d_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 64)  256         ['pool1[0][0]']                  \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_0_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 128)  8192        ['conv2_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_concat (Concatena  (None, 56, 56, 96)  0           ['pool1[0][0]',                  \n",
      " te)                                                              'conv2_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_0_bn (BatchNormal  (None, 56, 56, 96)  384         ['conv2_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_0_relu (Activatio  (None, 56, 56, 96)  0           ['conv2_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 128)  12288       ['conv2_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_concat (Concatena  (None, 56, 56, 128)  0          ['conv2_block1_concat[0][0]',    \n",
      " te)                                                              'conv2_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_0_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_0_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 128)  16384       ['conv2_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_concat (Concatena  (None, 56, 56, 160)  0          ['conv2_block2_concat[0][0]',    \n",
      " te)                                                              'conv2_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block4_0_bn (BatchNormal  (None, 56, 56, 160)  640        ['conv2_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block4_0_relu (Activatio  (None, 56, 56, 160)  0          ['conv2_block4_0_bn[0][0]']      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block4_1_conv (Conv2D)   (None, 56, 56, 128)  20480       ['conv2_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block4_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block4_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block4_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block4_concat (Concatena  (None, 56, 56, 192)  0          ['conv2_block3_concat[0][0]',    \n",
      " te)                                                              'conv2_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block5_0_bn (BatchNormal  (None, 56, 56, 192)  768        ['conv2_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block5_0_relu (Activatio  (None, 56, 56, 192)  0          ['conv2_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block5_1_conv (Conv2D)   (None, 56, 56, 128)  24576       ['conv2_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block5_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block5_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block5_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block5_concat (Concatena  (None, 56, 56, 224)  0          ['conv2_block4_concat[0][0]',    \n",
      " te)                                                              'conv2_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block6_0_bn (BatchNormal  (None, 56, 56, 224)  896        ['conv2_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block6_0_relu (Activatio  (None, 56, 56, 224)  0          ['conv2_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block6_1_conv (Conv2D)   (None, 56, 56, 128)  28672       ['conv2_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block6_1_bn (BatchNormal  (None, 56, 56, 128)  512        ['conv2_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block6_1_relu (Activatio  (None, 56, 56, 128)  0          ['conv2_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block6_2_conv (Conv2D)   (None, 56, 56, 32)   36864       ['conv2_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block6_concat (Concatena  (None, 56, 56, 256)  0          ['conv2_block5_concat[0][0]',    \n",
      " te)                                                              'conv2_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " pool2_bn (BatchNormalization)  (None, 56, 56, 256)  1024        ['conv2_block6_concat[0][0]']    \n",
      "                                                                                                  \n",
      " pool2_relu (Activation)        (None, 56, 56, 256)  0           ['pool2_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool2_conv (Conv2D)            (None, 56, 56, 128)  32768       ['pool2_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool2_pool (AveragePooling2D)  (None, 28, 28, 128)  0           ['pool2_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 128)  512        ['pool2_pool[0][0]']             \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_0_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  16384       ['conv3_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_concat (Concatena  (None, 28, 28, 160)  0          ['pool2_pool[0][0]',             \n",
      " te)                                                              'conv3_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_0_bn (BatchNormal  (None, 28, 28, 160)  640        ['conv3_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv3_block2_0_relu (Activatio  (None, 28, 28, 160)  0          ['conv3_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  20480       ['conv3_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_concat (Concatena  (None, 28, 28, 192)  0          ['conv3_block1_concat[0][0]',    \n",
      " te)                                                              'conv3_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_0_bn (BatchNormal  (None, 28, 28, 192)  768        ['conv3_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_0_relu (Activatio  (None, 28, 28, 192)  0          ['conv3_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  24576       ['conv3_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_concat (Concatena  (None, 28, 28, 224)  0          ['conv3_block2_concat[0][0]',    \n",
      " te)                                                              'conv3_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_0_bn (BatchNormal  (None, 28, 28, 224)  896        ['conv3_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_0_relu (Activatio  (None, 28, 28, 224)  0          ['conv3_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  28672       ['conv3_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_concat (Concatena  (None, 28, 28, 256)  0          ['conv3_block3_concat[0][0]',    \n",
      " te)                                                              'conv3_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block5_0_bn (BatchNormal  (None, 28, 28, 256)  1024       ['conv3_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block5_0_relu (Activatio  (None, 28, 28, 256)  0          ['conv3_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block5_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block5_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block5_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block5_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block5_concat (Concatena  (None, 28, 28, 288)  0          ['conv3_block4_concat[0][0]',    \n",
      " te)                                                              'conv3_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block6_0_bn (BatchNormal  (None, 28, 28, 288)  1152       ['conv3_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block6_0_relu (Activatio  (None, 28, 28, 288)  0          ['conv3_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block6_1_conv (Conv2D)   (None, 28, 28, 128)  36864       ['conv3_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block6_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv3_block6_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block6_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block6_concat (Concatena  (None, 28, 28, 320)  0          ['conv3_block5_concat[0][0]',    \n",
      " te)                                                              'conv3_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block7_0_bn (BatchNormal  (None, 28, 28, 320)  1280       ['conv3_block6_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block7_0_relu (Activatio  (None, 28, 28, 320)  0          ['conv3_block7_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block7_1_conv (Conv2D)   (None, 28, 28, 128)  40960       ['conv3_block7_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block7_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block7_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block7_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block7_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block7_concat (Concatena  (None, 28, 28, 352)  0          ['conv3_block6_concat[0][0]',    \n",
      " te)                                                              'conv3_block7_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block8_0_bn (BatchNormal  (None, 28, 28, 352)  1408       ['conv3_block7_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block8_0_relu (Activatio  (None, 28, 28, 352)  0          ['conv3_block8_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block8_1_conv (Conv2D)   (None, 28, 28, 128)  45056       ['conv3_block8_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block8_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block8_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block8_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block8_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block8_concat (Concatena  (None, 28, 28, 384)  0          ['conv3_block7_concat[0][0]',    \n",
      " te)                                                              'conv3_block8_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block9_0_bn (BatchNormal  (None, 28, 28, 384)  1536       ['conv3_block8_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block9_0_relu (Activatio  (None, 28, 28, 384)  0          ['conv3_block9_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block9_1_conv (Conv2D)   (None, 28, 28, 128)  49152       ['conv3_block9_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block9_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block9_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block9_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block9_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block9_2_conv (Conv2D)   (None, 28, 28, 32)   36864       ['conv3_block9_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block9_concat (Concatena  (None, 28, 28, 416)  0          ['conv3_block8_concat[0][0]',    \n",
      " te)                                                              'conv3_block9_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block10_0_bn (BatchNorma  (None, 28, 28, 416)  1664       ['conv3_block9_concat[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block10_0_relu (Activati  (None, 28, 28, 416)  0          ['conv3_block10_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block10_1_conv (Conv2D)  (None, 28, 28, 128)  53248       ['conv3_block10_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block10_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block10_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block10_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block10_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block10_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block10_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block10_concat (Concaten  (None, 28, 28, 448)  0          ['conv3_block9_concat[0][0]',    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ate)                                                             'conv3_block10_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block11_0_bn (BatchNorma  (None, 28, 28, 448)  1792       ['conv3_block10_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block11_0_relu (Activati  (None, 28, 28, 448)  0          ['conv3_block11_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block11_1_conv (Conv2D)  (None, 28, 28, 128)  57344       ['conv3_block11_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block11_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block11_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block11_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block11_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block11_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block11_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block11_concat (Concaten  (None, 28, 28, 480)  0          ['conv3_block10_concat[0][0]',   \n",
      " ate)                                                             'conv3_block11_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block12_0_bn (BatchNorma  (None, 28, 28, 480)  1920       ['conv3_block11_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block12_0_relu (Activati  (None, 28, 28, 480)  0          ['conv3_block12_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block12_1_conv (Conv2D)  (None, 28, 28, 128)  61440       ['conv3_block12_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block12_1_bn (BatchNorma  (None, 28, 28, 128)  512        ['conv3_block12_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block12_1_relu (Activati  (None, 28, 28, 128)  0          ['conv3_block12_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block12_2_conv (Conv2D)  (None, 28, 28, 32)   36864       ['conv3_block12_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block12_concat (Concaten  (None, 28, 28, 512)  0          ['conv3_block11_concat[0][0]',   \n",
      " ate)                                                             'conv3_block12_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " pool3_bn (BatchNormalization)  (None, 28, 28, 512)  2048        ['conv3_block12_concat[0][0]']   \n",
      "                                                                                                  \n",
      " pool3_relu (Activation)        (None, 28, 28, 512)  0           ['pool3_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool3_conv (Conv2D)            (None, 28, 28, 256)  131072      ['pool3_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool3_pool (AveragePooling2D)  (None, 14, 14, 256)  0           ['pool3_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 256)  1024       ['pool3_pool[0][0]']             \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_0_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 128)  32768       ['conv4_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_concat (Concatena  (None, 14, 14, 288)  0          ['pool3_pool[0][0]',             \n",
      " te)                                                              'conv4_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_0_bn (BatchNormal  (None, 14, 14, 288)  1152       ['conv4_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_0_relu (Activatio  (None, 14, 14, 288)  0          ['conv4_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 128)  36864       ['conv4_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv4_block2_concat (Concatena  (None, 14, 14, 320)  0          ['conv4_block1_concat[0][0]',    \n",
      " te)                                                              'conv4_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_0_bn (BatchNormal  (None, 14, 14, 320)  1280       ['conv4_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_0_relu (Activatio  (None, 14, 14, 320)  0          ['conv4_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 128)  40960       ['conv4_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_concat (Concatena  (None, 14, 14, 352)  0          ['conv4_block2_concat[0][0]',    \n",
      " te)                                                              'conv4_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_0_bn (BatchNormal  (None, 14, 14, 352)  1408       ['conv4_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_0_relu (Activatio  (None, 14, 14, 352)  0          ['conv4_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 128)  45056       ['conv4_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_concat (Concatena  (None, 14, 14, 384)  0          ['conv4_block3_concat[0][0]',    \n",
      " te)                                                              'conv4_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_0_bn (BatchNormal  (None, 14, 14, 384)  1536       ['conv4_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_0_relu (Activatio  (None, 14, 14, 384)  0          ['conv4_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 128)  49152       ['conv4_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_concat (Concatena  (None, 14, 14, 416)  0          ['conv4_block4_concat[0][0]',    \n",
      " te)                                                              'conv4_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_0_bn (BatchNormal  (None, 14, 14, 416)  1664       ['conv4_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_0_relu (Activatio  (None, 14, 14, 416)  0          ['conv4_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 128)  53248       ['conv4_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_concat (Concatena  (None, 14, 14, 448)  0          ['conv4_block5_concat[0][0]',    \n",
      " te)                                                              'conv4_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block7_0_bn (BatchNormal  (None, 14, 14, 448)  1792       ['conv4_block6_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block7_0_relu (Activatio  (None, 14, 14, 448)  0          ['conv4_block7_0_bn[0][0]']      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block7_1_conv (Conv2D)   (None, 14, 14, 128)  57344       ['conv4_block7_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block7_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block7_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block7_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block7_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block7_concat (Concatena  (None, 14, 14, 480)  0          ['conv4_block6_concat[0][0]',    \n",
      " te)                                                              'conv4_block7_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block8_0_bn (BatchNormal  (None, 14, 14, 480)  1920       ['conv4_block7_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block8_0_relu (Activatio  (None, 14, 14, 480)  0          ['conv4_block8_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block8_1_conv (Conv2D)   (None, 14, 14, 128)  61440       ['conv4_block8_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block8_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block8_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block8_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block8_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block8_concat (Concatena  (None, 14, 14, 512)  0          ['conv4_block7_concat[0][0]',    \n",
      " te)                                                              'conv4_block8_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block9_0_bn (BatchNormal  (None, 14, 14, 512)  2048       ['conv4_block8_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block9_0_relu (Activatio  (None, 14, 14, 512)  0          ['conv4_block9_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block9_1_conv (Conv2D)   (None, 14, 14, 128)  65536       ['conv4_block9_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block9_1_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv4_block9_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block9_1_relu (Activatio  (None, 14, 14, 128)  0          ['conv4_block9_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block9_2_conv (Conv2D)   (None, 14, 14, 32)   36864       ['conv4_block9_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block9_concat (Concatena  (None, 14, 14, 544)  0          ['conv4_block8_concat[0][0]',    \n",
      " te)                                                              'conv4_block9_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block10_0_bn (BatchNorma  (None, 14, 14, 544)  2176       ['conv4_block9_concat[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block10_0_relu (Activati  (None, 14, 14, 544)  0          ['conv4_block10_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block10_1_conv (Conv2D)  (None, 14, 14, 128)  69632       ['conv4_block10_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block10_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block10_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block10_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block10_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block10_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block10_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block10_concat (Concaten  (None, 14, 14, 576)  0          ['conv4_block9_concat[0][0]',    \n",
      " ate)                                                             'conv4_block10_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block11_0_bn (BatchNorma  (None, 14, 14, 576)  2304       ['conv4_block10_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block11_0_relu (Activati  (None, 14, 14, 576)  0          ['conv4_block11_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block11_1_conv (Conv2D)  (None, 14, 14, 128)  73728       ['conv4_block11_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block11_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block11_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv4_block11_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block11_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block11_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block11_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block11_concat (Concaten  (None, 14, 14, 608)  0          ['conv4_block10_concat[0][0]',   \n",
      " ate)                                                             'conv4_block11_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block12_0_bn (BatchNorma  (None, 14, 14, 608)  2432       ['conv4_block11_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block12_0_relu (Activati  (None, 14, 14, 608)  0          ['conv4_block12_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block12_1_conv (Conv2D)  (None, 14, 14, 128)  77824       ['conv4_block12_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block12_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block12_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block12_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block12_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block12_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block12_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block12_concat (Concaten  (None, 14, 14, 640)  0          ['conv4_block11_concat[0][0]',   \n",
      " ate)                                                             'conv4_block12_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block13_0_bn (BatchNorma  (None, 14, 14, 640)  2560       ['conv4_block12_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block13_0_relu (Activati  (None, 14, 14, 640)  0          ['conv4_block13_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block13_1_conv (Conv2D)  (None, 14, 14, 128)  81920       ['conv4_block13_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block13_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block13_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block13_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block13_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block13_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block13_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block13_concat (Concaten  (None, 14, 14, 672)  0          ['conv4_block12_concat[0][0]',   \n",
      " ate)                                                             'conv4_block13_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block14_0_bn (BatchNorma  (None, 14, 14, 672)  2688       ['conv4_block13_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block14_0_relu (Activati  (None, 14, 14, 672)  0          ['conv4_block14_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block14_1_conv (Conv2D)  (None, 14, 14, 128)  86016       ['conv4_block14_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block14_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block14_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block14_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block14_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block14_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block14_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block14_concat (Concaten  (None, 14, 14, 704)  0          ['conv4_block13_concat[0][0]',   \n",
      " ate)                                                             'conv4_block14_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block15_0_bn (BatchNorma  (None, 14, 14, 704)  2816       ['conv4_block14_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block15_0_relu (Activati  (None, 14, 14, 704)  0          ['conv4_block15_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block15_1_conv (Conv2D)  (None, 14, 14, 128)  90112       ['conv4_block15_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block15_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block15_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block15_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block15_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block15_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block15_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block15_concat (Concaten  (None, 14, 14, 736)  0          ['conv4_block14_concat[0][0]',   \n",
      " ate)                                                             'conv4_block15_2_conv[0][0]']   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv4_block16_0_bn (BatchNorma  (None, 14, 14, 736)  2944       ['conv4_block15_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block16_0_relu (Activati  (None, 14, 14, 736)  0          ['conv4_block16_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block16_1_conv (Conv2D)  (None, 14, 14, 128)  94208       ['conv4_block16_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block16_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block16_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block16_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block16_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block16_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block16_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block16_concat (Concaten  (None, 14, 14, 768)  0          ['conv4_block15_concat[0][0]',   \n",
      " ate)                                                             'conv4_block16_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block17_0_bn (BatchNorma  (None, 14, 14, 768)  3072       ['conv4_block16_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block17_0_relu (Activati  (None, 14, 14, 768)  0          ['conv4_block17_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block17_1_conv (Conv2D)  (None, 14, 14, 128)  98304       ['conv4_block17_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block17_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block17_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block17_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block17_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block17_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block17_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block17_concat (Concaten  (None, 14, 14, 800)  0          ['conv4_block16_concat[0][0]',   \n",
      " ate)                                                             'conv4_block17_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block18_0_bn (BatchNorma  (None, 14, 14, 800)  3200       ['conv4_block17_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block18_0_relu (Activati  (None, 14, 14, 800)  0          ['conv4_block18_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block18_1_conv (Conv2D)  (None, 14, 14, 128)  102400      ['conv4_block18_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block18_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block18_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block18_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block18_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block18_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block18_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block18_concat (Concaten  (None, 14, 14, 832)  0          ['conv4_block17_concat[0][0]',   \n",
      " ate)                                                             'conv4_block18_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block19_0_bn (BatchNorma  (None, 14, 14, 832)  3328       ['conv4_block18_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block19_0_relu (Activati  (None, 14, 14, 832)  0          ['conv4_block19_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block19_1_conv (Conv2D)  (None, 14, 14, 128)  106496      ['conv4_block19_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block19_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block19_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block19_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block19_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block19_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block19_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block19_concat (Concaten  (None, 14, 14, 864)  0          ['conv4_block18_concat[0][0]',   \n",
      " ate)                                                             'conv4_block19_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block20_0_bn (BatchNorma  (None, 14, 14, 864)  3456       ['conv4_block19_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block20_0_relu (Activati  (None, 14, 14, 864)  0          ['conv4_block20_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv4_block20_1_conv (Conv2D)  (None, 14, 14, 128)  110592      ['conv4_block20_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block20_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block20_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block20_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block20_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block20_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block20_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block20_concat (Concaten  (None, 14, 14, 896)  0          ['conv4_block19_concat[0][0]',   \n",
      " ate)                                                             'conv4_block20_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block21_0_bn (BatchNorma  (None, 14, 14, 896)  3584       ['conv4_block20_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block21_0_relu (Activati  (None, 14, 14, 896)  0          ['conv4_block21_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block21_1_conv (Conv2D)  (None, 14, 14, 128)  114688      ['conv4_block21_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block21_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block21_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block21_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block21_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block21_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block21_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block21_concat (Concaten  (None, 14, 14, 928)  0          ['conv4_block20_concat[0][0]',   \n",
      " ate)                                                             'conv4_block21_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block22_0_bn (BatchNorma  (None, 14, 14, 928)  3712       ['conv4_block21_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block22_0_relu (Activati  (None, 14, 14, 928)  0          ['conv4_block22_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block22_1_conv (Conv2D)  (None, 14, 14, 128)  118784      ['conv4_block22_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block22_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block22_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block22_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block22_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block22_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block22_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block22_concat (Concaten  (None, 14, 14, 960)  0          ['conv4_block21_concat[0][0]',   \n",
      " ate)                                                             'conv4_block22_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_0_bn (BatchNorma  (None, 14, 14, 960)  3840       ['conv4_block22_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block23_0_relu (Activati  (None, 14, 14, 960)  0          ['conv4_block23_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block23_1_conv (Conv2D)  (None, 14, 14, 128)  122880      ['conv4_block23_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block23_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block23_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block23_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block23_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block23_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_concat (Concaten  (None, 14, 14, 992)  0          ['conv4_block22_concat[0][0]',   \n",
      " ate)                                                             'conv4_block23_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block24_0_bn (BatchNorma  (None, 14, 14, 992)  3968       ['conv4_block23_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block24_0_relu (Activati  (None, 14, 14, 992)  0          ['conv4_block24_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block24_1_conv (Conv2D)  (None, 14, 14, 128)  126976      ['conv4_block24_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block24_1_bn (BatchNorma  (None, 14, 14, 128)  512        ['conv4_block24_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block24_1_relu (Activati  (None, 14, 14, 128)  0          ['conv4_block24_1_bn[0][0]']     \n",
      " on)                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv4_block24_2_conv (Conv2D)  (None, 14, 14, 32)   36864       ['conv4_block24_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block24_concat (Concaten  (None, 14, 14, 1024  0          ['conv4_block23_concat[0][0]',   \n",
      " ate)                           )                                 'conv4_block24_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " pool4_bn (BatchNormalization)  (None, 14, 14, 1024  4096        ['conv4_block24_concat[0][0]']   \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool4_relu (Activation)        (None, 14, 14, 1024  0           ['pool4_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool4_conv (Conv2D)            (None, 14, 14, 512)  524288      ['pool4_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool4_pool (AveragePooling2D)  (None, 7, 7, 512)    0           ['pool4_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 512)   2048        ['pool4_pool[0][0]']             \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_0_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 128)    65536       ['conv5_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_concat (Concatena  (None, 7, 7, 544)   0           ['pool4_pool[0][0]',             \n",
      " te)                                                              'conv5_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_0_bn (BatchNormal  (None, 7, 7, 544)   2176        ['conv5_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_0_relu (Activatio  (None, 7, 7, 544)   0           ['conv5_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 128)    69632       ['conv5_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_concat (Concatena  (None, 7, 7, 576)   0           ['conv5_block1_concat[0][0]',    \n",
      " te)                                                              'conv5_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_0_bn (BatchNormal  (None, 7, 7, 576)   2304        ['conv5_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_0_relu (Activatio  (None, 7, 7, 576)   0           ['conv5_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 128)    73728       ['conv5_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_concat (Concatena  (None, 7, 7, 608)   0           ['conv5_block2_concat[0][0]',    \n",
      " te)                                                              'conv5_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block4_0_bn (BatchNormal  (None, 7, 7, 608)   2432        ['conv5_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block4_0_relu (Activatio  (None, 7, 7, 608)   0           ['conv5_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block4_1_conv (Conv2D)   (None, 7, 7, 128)    77824       ['conv5_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block4_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv5_block4_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block4_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block4_concat (Concatena  (None, 7, 7, 640)   0           ['conv5_block3_concat[0][0]',    \n",
      " te)                                                              'conv5_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block5_0_bn (BatchNormal  (None, 7, 7, 640)   2560        ['conv5_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block5_0_relu (Activatio  (None, 7, 7, 640)   0           ['conv5_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block5_1_conv (Conv2D)   (None, 7, 7, 128)    81920       ['conv5_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block5_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block5_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block5_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block5_concat (Concatena  (None, 7, 7, 672)   0           ['conv5_block4_concat[0][0]',    \n",
      " te)                                                              'conv5_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block6_0_bn (BatchNormal  (None, 7, 7, 672)   2688        ['conv5_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block6_0_relu (Activatio  (None, 7, 7, 672)   0           ['conv5_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block6_1_conv (Conv2D)   (None, 7, 7, 128)    86016       ['conv5_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block6_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block6_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block6_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block6_concat (Concatena  (None, 7, 7, 704)   0           ['conv5_block5_concat[0][0]',    \n",
      " te)                                                              'conv5_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block7_0_bn (BatchNormal  (None, 7, 7, 704)   2816        ['conv5_block6_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block7_0_relu (Activatio  (None, 7, 7, 704)   0           ['conv5_block7_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block7_1_conv (Conv2D)   (None, 7, 7, 128)    90112       ['conv5_block7_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block7_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block7_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block7_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block7_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block7_concat (Concatena  (None, 7, 7, 736)   0           ['conv5_block6_concat[0][0]',    \n",
      " te)                                                              'conv5_block7_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block8_0_bn (BatchNormal  (None, 7, 7, 736)   2944        ['conv5_block7_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block8_0_relu (Activatio  (None, 7, 7, 736)   0           ['conv5_block8_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block8_1_conv (Conv2D)   (None, 7, 7, 128)    94208       ['conv5_block8_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block8_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block8_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block8_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block8_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block8_concat (Concatena  (None, 7, 7, 768)   0           ['conv5_block7_concat[0][0]',    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " te)                                                              'conv5_block8_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block9_0_bn (BatchNormal  (None, 7, 7, 768)   3072        ['conv5_block8_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block9_0_relu (Activatio  (None, 7, 7, 768)   0           ['conv5_block9_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block9_1_conv (Conv2D)   (None, 7, 7, 128)    98304       ['conv5_block9_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block9_1_bn (BatchNormal  (None, 7, 7, 128)   512         ['conv5_block9_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block9_1_relu (Activatio  (None, 7, 7, 128)   0           ['conv5_block9_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block9_2_conv (Conv2D)   (None, 7, 7, 32)     36864       ['conv5_block9_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block9_concat (Concatena  (None, 7, 7, 800)   0           ['conv5_block8_concat[0][0]',    \n",
      " te)                                                              'conv5_block9_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block10_0_bn (BatchNorma  (None, 7, 7, 800)   3200        ['conv5_block9_concat[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block10_0_relu (Activati  (None, 7, 7, 800)   0           ['conv5_block10_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block10_1_conv (Conv2D)  (None, 7, 7, 128)    102400      ['conv5_block10_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block10_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block10_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block10_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block10_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block10_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block10_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block10_concat (Concaten  (None, 7, 7, 832)   0           ['conv5_block9_concat[0][0]',    \n",
      " ate)                                                             'conv5_block10_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block11_0_bn (BatchNorma  (None, 7, 7, 832)   3328        ['conv5_block10_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block11_0_relu (Activati  (None, 7, 7, 832)   0           ['conv5_block11_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block11_1_conv (Conv2D)  (None, 7, 7, 128)    106496      ['conv5_block11_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block11_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block11_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block11_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block11_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block11_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block11_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block11_concat (Concaten  (None, 7, 7, 864)   0           ['conv5_block10_concat[0][0]',   \n",
      " ate)                                                             'conv5_block11_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block12_0_bn (BatchNorma  (None, 7, 7, 864)   3456        ['conv5_block11_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block12_0_relu (Activati  (None, 7, 7, 864)   0           ['conv5_block12_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block12_1_conv (Conv2D)  (None, 7, 7, 128)    110592      ['conv5_block12_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block12_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block12_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block12_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block12_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block12_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block12_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block12_concat (Concaten  (None, 7, 7, 896)   0           ['conv5_block11_concat[0][0]',   \n",
      " ate)                                                             'conv5_block12_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block13_0_bn (BatchNorma  (None, 7, 7, 896)   3584        ['conv5_block12_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block13_0_relu (Activati  (None, 7, 7, 896)   0           ['conv5_block13_0_bn[0][0]']     \n",
      " on)                                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv5_block13_1_conv (Conv2D)  (None, 7, 7, 128)    114688      ['conv5_block13_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block13_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block13_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block13_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block13_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block13_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block13_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block13_concat (Concaten  (None, 7, 7, 928)   0           ['conv5_block12_concat[0][0]',   \n",
      " ate)                                                             'conv5_block13_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block14_0_bn (BatchNorma  (None, 7, 7, 928)   3712        ['conv5_block13_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block14_0_relu (Activati  (None, 7, 7, 928)   0           ['conv5_block14_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block14_1_conv (Conv2D)  (None, 7, 7, 128)    118784      ['conv5_block14_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block14_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block14_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block14_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block14_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block14_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block14_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block14_concat (Concaten  (None, 7, 7, 960)   0           ['conv5_block13_concat[0][0]',   \n",
      " ate)                                                             'conv5_block14_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block15_0_bn (BatchNorma  (None, 7, 7, 960)   3840        ['conv5_block14_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block15_0_relu (Activati  (None, 7, 7, 960)   0           ['conv5_block15_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block15_1_conv (Conv2D)  (None, 7, 7, 128)    122880      ['conv5_block15_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block15_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block15_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block15_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block15_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block15_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block15_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block15_concat (Concaten  (None, 7, 7, 992)   0           ['conv5_block14_concat[0][0]',   \n",
      " ate)                                                             'conv5_block15_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block16_0_bn (BatchNorma  (None, 7, 7, 992)   3968        ['conv5_block15_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block16_0_relu (Activati  (None, 7, 7, 992)   0           ['conv5_block16_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block16_1_conv (Conv2D)  (None, 7, 7, 128)    126976      ['conv5_block16_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block16_1_bn (BatchNorma  (None, 7, 7, 128)   512         ['conv5_block16_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block16_1_relu (Activati  (None, 7, 7, 128)   0           ['conv5_block16_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block16_2_conv (Conv2D)  (None, 7, 7, 32)     36864       ['conv5_block16_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block16_concat (Concaten  (None, 7, 7, 1024)  0           ['conv5_block15_concat[0][0]',   \n",
      " ate)                                                             'conv5_block16_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " bn (BatchNormalization)        (None, 7, 7, 1024)   4096        ['conv5_block16_concat[0][0]']   \n",
      "                                                                                                  \n",
      " relu (Activation)              (None, 7, 7, 1024)   0           ['bn[0][0]']                     \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePooling  (None, 1024)        0           ['relu[0][0]']                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " predictions (Dense)            (None, 1000)         1025000     ['avg_pool[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,062,504\n",
      "Trainable params: 7,978,856\n",
      "Non-trainable params: 83,648\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "denseNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5f574d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = tf.keras.applications.VGG16(weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86e4e540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, 224, 224, 3)]\n",
      "(None, 224, 224, 3)\n",
      "(None, 224, 224, 64)\n",
      "(None, 224, 224, 64)\n",
      "(None, 112, 112, 64)\n",
      "(None, 112, 112, 128)\n",
      "(None, 112, 112, 128)\n",
      "(None, 56, 56, 128)\n",
      "(None, 56, 56, 256)\n",
      "(None, 56, 56, 256)\n",
      "(None, 56, 56, 256)\n",
      "(None, 28, 28, 256)\n",
      "(None, 28, 28, 512)\n",
      "(None, 28, 28, 512)\n",
      "(None, 28, 28, 512)\n",
      "(None, 14, 14, 512)\n",
      "(None, 14, 14, 512)\n",
      "(None, 14, 14, 512)\n",
      "(None, 14, 14, 512)\n",
      "(None, 7, 7, 512)\n",
      "(None, 25088)\n",
      "(None, 4096)\n",
      "(None, 4096)\n"
     ]
    }
   ],
   "source": [
    "for layers in vgg.layers:\n",
    "    print(layers.input_shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7faafda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "serial = tf.keras.layers.serialize(example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e3ff748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_name': 'Sequential',\n",
       " 'config': {'name': 'sequential',\n",
       "  'layers': [{'class_name': 'Dense',\n",
       "    'config': {'name': 'dense_1',\n",
       "     'trainable': True,\n",
       "     'dtype': 'float32',\n",
       "     'units': 10,\n",
       "     'activation': 'relu',\n",
       "     'use_bias': True,\n",
       "     'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "      'config': {'seed': None}},\n",
       "     'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "     'kernel_regularizer': None,\n",
       "     'bias_regularizer': None,\n",
       "     'activity_regularizer': None,\n",
       "     'kernel_constraint': None,\n",
       "     'bias_constraint': None}}]}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1886e4cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Unable to revive model from config. When overriding the `get_config()`, make sure that the returned config contains all items used as arguments in the constructor to <class 'keras.engine.training.Model'>, which is the default behavior. You can override this default behavior by defining a `from_config` method to specify how to create an instance of Model from the config. \n\nError encountered during deserialization:\n('Keyword argument not understood:', 'class_name')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/greenML/lib/python3.8/site-packages/keras/engine/training.py:2732\u001b[0m, in \u001b[0;36mModel.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   2731\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2732\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2733\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/greenML/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 587\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/greenML/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/greenML/lib/python3.8/site-packages/keras/utils/generic_utils.py:1174\u001b[0m, in \u001b[0;36mvalidate_kwargs\u001b[0;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwarg \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_kwargs:\n\u001b[0;32m-> 1174\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(error_message, kwarg)\n",
      "\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'class_name')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserial\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/greenML/lib/python3.8/site-packages/keras/engine/training.py:2734\u001b[0m, in \u001b[0;36mModel.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   2732\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n\u001b[1;32m   2733\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 2734\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnable to revive model from config. When overriding \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2735\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe `get_config()`, make sure that the returned \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2736\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig contains all items used as arguments in the \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2737\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstructor to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, which is the default behavior. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2738\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou can override this default behavior by defining a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2739\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`from_config` method to specify how to create an \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2740\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstance of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from the config. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2741\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError encountered during deserialization:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Unable to revive model from config. When overriding the `get_config()`, make sure that the returned config contains all items used as arguments in the constructor to <class 'keras.engine.training.Model'>, which is the default behavior. You can override this default behavior by defining a `from_config` method to specify how to create an instance of Model from the config. \n\nError encountered during deserialization:\n('Keyword argument not understood:', 'class_name')"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model.from_config(serial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ae44d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "json = example.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a44ef19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"layers\": [{\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 10, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.9.0\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c48efe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "json2 = vgg.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06e6ca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "vggRe = tf.keras.models.model_from_json(json2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54fcc04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vggRe.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "beaca575",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 15:09:10] Energy consumed for RAM : 0.000667 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:09:10] Energy consumed for all GPUs : 0.000943 kWh. All GPUs Power : 8.265000000000002 W\n",
      "[codecarbon INFO @ 15:09:10] Energy consumed for all CPUs : 0.001455 kWh. All CPUs Power : 12.568690776220922 W\n",
      "[codecarbon INFO @ 15:09:10] 0.003065 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:09:11] Energy consumed for RAM : 0.000519 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:09:11] Energy consumed for all GPUs : 0.000727 kWh. All GPUs Power : 8.265000000000002 W\n",
      "[codecarbon INFO @ 15:09:11] Energy consumed for all CPUs : 0.001146 kWh. All CPUs Power : 12.623643902412628 W\n",
      "[codecarbon INFO @ 15:09:11] 0.002391 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:09:11] Energy consumed for RAM : 0.000346 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:09:11] Energy consumed for all GPUs : 0.000503 kWh. All GPUs Power : 8.166000000000002 W\n",
      "[codecarbon INFO @ 15:09:11] Energy consumed for all CPUs : 0.000735 kWh. All CPUs Power : 12.580795649091485 W\n",
      "[codecarbon INFO @ 15:09:11] 0.001584 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:09:12] Energy consumed for RAM : 0.000470 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:09:12] Energy consumed for all GPUs : 0.000655 kWh. All GPUs Power : 8.265000000000002 W\n",
      "[codecarbon INFO @ 15:09:12] Energy consumed for all CPUs : 0.001031 kWh. All CPUs Power : 12.578433537889108 W\n",
      "[codecarbon INFO @ 15:09:12] 0.002155 kWh of electricity used since the begining.\n"
     ]
    }
   ],
   "source": [
    "# %load ../dataset/utils/energyEvaluation.py\n",
    "from codecarbon import EmissionsTracker\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_energy_forward(model, input_size, batch_size =1, repetitions = 1):\n",
    "    \"\"\" Measures the energy consumption of a forward pass of the given model\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        model:\n",
    "            ML model that should be measured (has to be callable on input)\n",
    "        input_size:\n",
    "            size of the input to the model as int tuple, can also be a list of int tuples if the model expects list of input tensors\n",
    "        batch_size: int\n",
    "            size of a batch for the forward pass (default 1)\n",
    "        repetitions: int\n",
    "            number of repetitions for the measurement\n",
    "        \n",
    "    Returns:\n",
    "    ----------\n",
    "        float: measured average energy consumption of forward pass for the model\n",
    "    \"\"\"\n",
    "    #Create random input:\n",
    "    \n",
    "    if isinstance(input_size, list):\n",
    "        input = []\n",
    "        for s in input_size:\n",
    "            input.append(np.random.rand(batch_size, *s[1:]))\n",
    "    else:\n",
    "        input = np.random.rand(batch_size, *input_size[1:])\n",
    "    \n",
    "    #Run repetitions forward passes and meassure the energy consumption\n",
    "    tracker = EmissionsTracker(save_to_file= False)\n",
    "    tracker.start()\n",
    "    for i in range(repetitions):\n",
    "        output = model(input)\n",
    "    \n",
    "    energy_consumption = tracker.stop()/repetitions\n",
    "    return energy_consumption\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "45797228",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 15:10:21] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 15:10:21] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 15:10:21] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 15:10:21] [setup] CPU Tracking...\n",
      "[codecarbon INFO @ 15:10:21] Tracking Intel CPU via RAPL interface\n",
      "[codecarbon INFO @ 15:10:23] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 15:10:23]   Platform system: Linux-5.4.0-88-generic-x86_64-with-glibc2.17\n",
      "[codecarbon INFO @ 15:10:23]   Python version: 3.8.13\n",
      "[codecarbon INFO @ 15:10:23]   Available RAM : 16.000 GB\n",
      "[codecarbon INFO @ 15:10:23]   CPU count: 2\n",
      "[codecarbon INFO @ 15:10:23]   CPU model: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz\n",
      "[codecarbon INFO @ 15:10:23]   GPU count: 1\n",
      "[codecarbon INFO @ 15:10:23]   GPU model: 1 x NVIDIA GeForce GTX 1080 Ti\n",
      "[codecarbon INFO @ 15:10:25] Energy consumed for RAM : 0.000791 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:10:25] Energy consumed for all GPUs : 0.001120 kWh. All GPUs Power : 8.363 W\n",
      "[codecarbon INFO @ 15:10:25] Energy consumed for all CPUs : 0.001883 kWh. All CPUs Power : 16.689495966048007 W\n",
      "[codecarbon INFO @ 15:10:25] 0.003793 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:10:26] Energy consumed for RAM : 0.000642 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:10:26] Energy consumed for all GPUs : 0.000901 kWh. All GPUs Power : 8.265000000000002 W\n",
      "[codecarbon INFO @ 15:10:26] Energy consumed for all CPUs : 0.001573 kWh. All CPUs Power : 15.447284004034962 W\n",
      "[codecarbon INFO @ 15:10:26] 0.003115 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:10:26] Energy consumed for RAM : 0.000000 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:10:26] Energy consumed for all GPUs : 0.000001 kWh. All GPUs Power : 8.359 W\n",
      "[codecarbon INFO @ 15:10:26] Energy consumed for all CPUs : 0.000003 kWh. All CPUs Power : 38.44011876612364 W\n",
      "[codecarbon INFO @ 15:10:26] 0.000003 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:10:26] Energy consumed for RAM : 0.000470 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:10:26] Energy consumed for all GPUs : 0.000673 kWh. All GPUs Power : 8.265000000000002 W\n",
      "[codecarbon INFO @ 15:10:26] Energy consumed for all CPUs : 0.001164 kWh. All CPUs Power : 15.757976003458761 W\n",
      "[codecarbon INFO @ 15:10:26] 0.002307 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:10:26] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 15:10:26] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 15:10:26] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 15:10:26] [setup] CPU Tracking...\n",
      "[codecarbon INFO @ 15:10:26] Tracking Intel CPU via RAPL interface\n",
      "[codecarbon INFO @ 15:10:27] Energy consumed for RAM : 0.000593 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:10:27] Energy consumed for all GPUs : 0.000827 kWh. All GPUs Power : 8.068000000000001 W\n",
      "[codecarbon INFO @ 15:10:27] Energy consumed for all CPUs : 0.001462 kWh. All CPUs Power : 16.223521915182392 W\n",
      "[codecarbon INFO @ 15:10:27] 0.002883 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:10:28] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 15:10:28]   Platform system: Linux-5.4.0-88-generic-x86_64-with-glibc2.17\n",
      "[codecarbon INFO @ 15:10:28]   Python version: 3.8.13\n",
      "[codecarbon INFO @ 15:10:28]   Available RAM : 16.000 GB\n",
      "[codecarbon INFO @ 15:10:28]   CPU count: 2\n",
      "[codecarbon INFO @ 15:10:28]   CPU model: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz\n",
      "[codecarbon INFO @ 15:10:28]   GPU count: 1\n",
      "[codecarbon INFO @ 15:10:28]   GPU model: 1 x NVIDIA GeForce GTX 1080 Ti\n",
      "[codecarbon INFO @ 15:10:31] Energy consumed for RAM : 0.000000 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:10:31] Energy consumed for all GPUs : 0.000001 kWh. All GPUs Power : 8.069 W\n",
      "[codecarbon INFO @ 15:10:31] Energy consumed for all CPUs : 0.000002 kWh. All CPUs Power : 33.00881893522559 W\n",
      "[codecarbon INFO @ 15:10:31] 0.000003 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:10:31] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 15:10:31] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 15:10:31] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 15:10:31] [setup] CPU Tracking...\n",
      "[codecarbon INFO @ 15:10:31] Tracking Intel CPU via RAPL interface\n",
      "[codecarbon INFO @ 15:10:33] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 15:10:33]   Platform system: Linux-5.4.0-88-generic-x86_64-with-glibc2.17\n",
      "[codecarbon INFO @ 15:10:33]   Python version: 3.8.13\n",
      "[codecarbon INFO @ 15:10:33]   Available RAM : 16.000 GB\n",
      "[codecarbon INFO @ 15:10:33]   CPU count: 2\n",
      "[codecarbon INFO @ 15:10:33]   CPU model: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz\n",
      "[codecarbon INFO @ 15:10:33]   GPU count: 1\n",
      "[codecarbon INFO @ 15:10:33]   GPU model: 1 x NVIDIA GeForce GTX 1080 Ti\n",
      "[codecarbon INFO @ 15:10:36] Energy consumed for RAM : 0.000001 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:10:36] Energy consumed for all GPUs : 0.000001 kWh. All GPUs Power : 8.265000000000002 W\n",
      "[codecarbon INFO @ 15:10:36] Energy consumed for all CPUs : 0.000006 kWh. All CPUs Power : 40.262219482892114 W\n",
      "[codecarbon INFO @ 15:10:36] 0.000008 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:10:36] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 15:10:36] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 15:10:36] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 15:10:36] [setup] CPU Tracking...\n",
      "[codecarbon INFO @ 15:10:36] Tracking Intel CPU via RAPL interface\n",
      "[codecarbon INFO @ 15:10:38] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 15:10:38]   Platform system: Linux-5.4.0-88-generic-x86_64-with-glibc2.17\n",
      "[codecarbon INFO @ 15:10:38]   Python version: 3.8.13\n",
      "[codecarbon INFO @ 15:10:38]   Available RAM : 16.000 GB\n",
      "[codecarbon INFO @ 15:10:38]   CPU count: 2\n",
      "[codecarbon INFO @ 15:10:38]   CPU model: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz\n",
      "[codecarbon INFO @ 15:10:38]   GPU count: 1\n",
      "[codecarbon INFO @ 15:10:38]   GPU model: 1 x NVIDIA GeForce GTX 1080 Ti\n",
      "[codecarbon INFO @ 15:10:40] Energy consumed for RAM : 0.000815 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:10:40] Energy consumed for all GPUs : 0.001156 kWh. All GPUs Power : 8.658 W\n",
      "[codecarbon INFO @ 15:10:40] Energy consumed for all CPUs : 0.001978 kWh. All CPUs Power : 22.731060770012895 W\n",
      "[codecarbon INFO @ 15:10:40] 0.003949 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:10:41] Energy consumed for RAM : 0.000667 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:10:41] Energy consumed for all GPUs : 0.000935 kWh. All GPUs Power : 8.265000000000002 W\n",
      "[codecarbon INFO @ 15:10:41] Energy consumed for all CPUs : 0.001667 kWh. All CPUs Power : 22.751326781390194 W\n",
      "[codecarbon INFO @ 15:10:41] 0.003269 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:10:41] Energy consumed for RAM : 0.000495 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:10:41] Energy consumed for RAM : 0.000001 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:10:41] Energy consumed for all GPUs : 0.000707 kWh. All GPUs Power : 8.166000000000002 W\n",
      "[codecarbon INFO @ 15:10:41] Energy consumed for all CPUs : 0.001261 kWh. All CPUs Power : 22.97955805189553 W\n",
      "[codecarbon INFO @ 15:10:41] 0.002463 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:10:41] Energy consumed for all GPUs : 0.000001 kWh. All GPUs Power : 8.561000000000002 W\n",
      "[codecarbon INFO @ 15:10:41] Energy consumed for all CPUs : 0.000006 kWh. All CPUs Power : 43.954972023317566 W\n",
      "[codecarbon INFO @ 15:10:41] 0.000008 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:10:42] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 15:10:42] Energy consumed for RAM : 0.000618 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:10:42] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 15:10:42] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 15:10:42] [setup] CPU Tracking...\n",
      "[codecarbon INFO @ 15:10:42] Tracking Intel CPU via RAPL interface\n",
      "[codecarbon INFO @ 15:10:42] Energy consumed for all GPUs : 0.000861 kWh. All GPUs Power : 8.167 W\n",
      "[codecarbon INFO @ 15:10:42] Energy consumed for all CPUs : 0.001559 kWh. All CPUs Power : 23.00817804893967 W\n",
      "[codecarbon INFO @ 15:10:42] 0.003038 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:10:43] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 15:10:43]   Platform system: Linux-5.4.0-88-generic-x86_64-with-glibc2.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 15:10:43]   Python version: 3.8.13\n",
      "[codecarbon INFO @ 15:10:43]   Available RAM : 16.000 GB\n",
      "[codecarbon INFO @ 15:10:43]   CPU count: 2\n",
      "[codecarbon INFO @ 15:10:43]   CPU model: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz\n",
      "[codecarbon INFO @ 15:10:43]   GPU count: 1\n",
      "[codecarbon INFO @ 15:10:43]   GPU model: 1 x NVIDIA GeForce GTX 1080 Ti\n",
      "[codecarbon INFO @ 15:10:46] Energy consumed for RAM : 0.000000 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:10:46] Energy consumed for all GPUs : 0.000001 kWh. All GPUs Power : 7.97 W\n",
      "[codecarbon INFO @ 15:10:46] Energy consumed for all CPUs : 0.000004 kWh. All CPUs Power : 37.89122616031297 W\n",
      "[codecarbon INFO @ 15:10:46] 0.000005 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:10:47] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 15:10:47] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 15:10:47] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 15:10:47] [setup] CPU Tracking...\n",
      "[codecarbon INFO @ 15:10:47] Tracking Intel CPU via RAPL interface\n",
      "[codecarbon INFO @ 15:10:48] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 15:10:48]   Platform system: Linux-5.4.0-88-generic-x86_64-with-glibc2.17\n",
      "[codecarbon INFO @ 15:10:48]   Python version: 3.8.13\n",
      "[codecarbon INFO @ 15:10:48]   Available RAM : 16.000 GB\n",
      "[codecarbon INFO @ 15:10:48]   CPU count: 2\n",
      "[codecarbon INFO @ 15:10:48]   CPU model: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz\n",
      "[codecarbon INFO @ 15:10:48]   GPU count: 1\n",
      "[codecarbon INFO @ 15:10:48]   GPU model: 1 x NVIDIA GeForce GTX 1080 Ti\n",
      "[codecarbon INFO @ 15:10:51] Energy consumed for RAM : 0.000000 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:10:51] Energy consumed for all GPUs : 0.000001 kWh. All GPUs Power : 8.364 W\n",
      "[codecarbon INFO @ 15:10:51] Energy consumed for all CPUs : 0.000004 kWh. All CPUs Power : 37.63683700779331 W\n",
      "[codecarbon INFO @ 15:10:51] 0.000005 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:10:52] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 15:10:52] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 15:10:52] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 15:10:52] [setup] CPU Tracking...\n",
      "[codecarbon INFO @ 15:10:52] Tracking Intel CPU via RAPL interface\n",
      "[codecarbon INFO @ 15:10:53] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 15:10:53]   Platform system: Linux-5.4.0-88-generic-x86_64-with-glibc2.17\n",
      "[codecarbon INFO @ 15:10:53]   Python version: 3.8.13\n",
      "[codecarbon INFO @ 15:10:53]   Available RAM : 16.000 GB\n",
      "[codecarbon INFO @ 15:10:53]   CPU count: 2\n",
      "[codecarbon INFO @ 15:10:53]   CPU model: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz\n",
      "[codecarbon INFO @ 15:10:53]   GPU count: 1\n",
      "[codecarbon INFO @ 15:10:53]   GPU model: 1 x NVIDIA GeForce GTX 1080 Ti\n",
      "[codecarbon INFO @ 15:10:55] Energy consumed for RAM : 0.000840 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:10:55] Energy consumed for all GPUs : 0.001191 kWh. All GPUs Power : 8.363 W\n",
      "[codecarbon INFO @ 15:10:55] Energy consumed for all CPUs : 0.002075 kWh. All CPUs Power : 23.324188415513923 W\n",
      "[codecarbon INFO @ 15:10:55] 0.004105 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:10:56] Energy consumed for RAM : 0.000691 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:10:56] Energy consumed for all GPUs : 0.000970 kWh. All GPUs Power : 8.461 W\n",
      "[codecarbon INFO @ 15:10:56] Energy consumed for all CPUs : 0.001764 kWh. All CPUs Power : 23.315496579311883 W\n",
      "[codecarbon INFO @ 15:10:56] 0.003426 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:10:56] Energy consumed for RAM : 0.000519 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:10:56] Energy consumed for all GPUs : 0.000742 kWh. All GPUs Power : 8.362 W\n",
      "[codecarbon INFO @ 15:10:56] Energy consumed for all CPUs : 0.001356 kWh. All CPUs Power : 22.890532419111683 W\n",
      "[codecarbon INFO @ 15:10:56] 0.002618 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:10:57] Energy consumed for RAM : 0.000001 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:10:57] Energy consumed for RAM : 0.000643 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:10:57] Energy consumed for all GPUs : 0.000001 kWh. All GPUs Power : 8.067 W\n",
      "[codecarbon INFO @ 15:10:57] Energy consumed for all CPUs : 0.000006 kWh. All CPUs Power : 43.0697855134479 W\n",
      "[codecarbon INFO @ 15:10:57] 0.000007 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:10:57] Energy consumed for all GPUs : 0.000895 kWh. All GPUs Power : 8.065 W\n",
      "[codecarbon INFO @ 15:10:57] Energy consumed for all CPUs : 0.001654 kWh. All CPUs Power : 22.85551234017843 W\n",
      "[codecarbon INFO @ 15:10:57] 0.003191 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:10:57] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 15:10:57] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 15:10:57] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 15:10:57] [setup] CPU Tracking...\n",
      "[codecarbon INFO @ 15:10:57] Tracking Intel CPU via RAPL interface\n",
      "[codecarbon INFO @ 15:10:58] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 15:10:58]   Platform system: Linux-5.4.0-88-generic-x86_64-with-glibc2.17\n",
      "[codecarbon INFO @ 15:10:58]   Python version: 3.8.13\n",
      "[codecarbon INFO @ 15:10:58]   Available RAM : 16.000 GB\n",
      "[codecarbon INFO @ 15:10:58]   CPU count: 2\n",
      "[codecarbon INFO @ 15:10:58]   CPU model: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz\n",
      "[codecarbon INFO @ 15:10:58]   GPU count: 1\n",
      "[codecarbon INFO @ 15:10:58]   GPU model: 1 x NVIDIA GeForce GTX 1080 Ti\n",
      "[codecarbon INFO @ 15:11:01] Energy consumed for RAM : 0.000000 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:11:01] Energy consumed for all GPUs : 0.000001 kWh. All GPUs Power : 8.069 W\n",
      "[codecarbon INFO @ 15:11:01] Energy consumed for all CPUs : 0.000002 kWh. All CPUs Power : 33.43647132151712 W\n",
      "[codecarbon INFO @ 15:11:01] 0.000003 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:02] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 15:11:02] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 15:11:02] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 15:11:02] [setup] CPU Tracking...\n",
      "[codecarbon INFO @ 15:11:02] Tracking Intel CPU via RAPL interface\n",
      "[codecarbon INFO @ 15:11:03] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 15:11:03]   Platform system: Linux-5.4.0-88-generic-x86_64-with-glibc2.17\n",
      "[codecarbon INFO @ 15:11:03]   Python version: 3.8.13\n",
      "[codecarbon INFO @ 15:11:03]   Available RAM : 16.000 GB\n",
      "[codecarbon INFO @ 15:11:03]   CPU count: 2\n",
      "[codecarbon INFO @ 15:11:03]   CPU model: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz\n",
      "[codecarbon INFO @ 15:11:03]   GPU count: 1\n",
      "[codecarbon INFO @ 15:11:03]   GPU model: 1 x NVIDIA GeForce GTX 1080 Ti\n",
      "[codecarbon INFO @ 15:11:06] Energy consumed for RAM : 0.000000 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:11:06] Energy consumed for all GPUs : 0.000001 kWh. All GPUs Power : 7.97 W\n",
      "[codecarbon INFO @ 15:11:06] Energy consumed for all CPUs : 0.000002 kWh. All CPUs Power : 32.777518710784975 W\n",
      "[codecarbon INFO @ 15:11:06] 0.000003 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:06] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 15:11:07] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 15:11:07] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 15:11:07] [setup] CPU Tracking...\n",
      "[codecarbon INFO @ 15:11:07] Tracking Intel CPU via RAPL interface\n",
      "[codecarbon INFO @ 15:11:08] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 15:11:08]   Platform system: Linux-5.4.0-88-generic-x86_64-with-glibc2.17\n",
      "[codecarbon INFO @ 15:11:08]   Python version: 3.8.13\n",
      "[codecarbon INFO @ 15:11:08]   Available RAM : 16.000 GB\n",
      "[codecarbon INFO @ 15:11:08]   CPU count: 2\n",
      "[codecarbon INFO @ 15:11:08]   CPU model: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz\n",
      "[codecarbon INFO @ 15:11:08]   GPU count: 1\n",
      "[codecarbon INFO @ 15:11:08]   GPU model: 1 x NVIDIA GeForce GTX 1080 Ti\n",
      "[codecarbon INFO @ 15:11:10] Energy consumed for RAM : 0.000865 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:11:10] Energy consumed for all GPUs : 0.001225 kWh. All GPUs Power : 8.363 W\n",
      "[codecarbon INFO @ 15:11:10] Energy consumed for all CPUs : 0.002169 kWh. All CPUs Power : 22.59971936877753 W\n",
      "[codecarbon INFO @ 15:11:10] 0.004259 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:11] Energy consumed for RAM : 0.000716 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:11:11] Energy consumed for all GPUs : 0.001005 kWh. All GPUs Power : 8.363 W\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 15:11:11] Energy consumed for all CPUs : 0.001859 kWh. All CPUs Power : 22.61641334996804 W\n",
      "[codecarbon INFO @ 15:11:11] 0.003579 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:11] Energy consumed for RAM : 0.000000 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:11:11] Energy consumed for RAM : 0.000544 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:11:11] Energy consumed for all GPUs : 0.000001 kWh. All GPUs Power : 8.363 W\n",
      "[codecarbon INFO @ 15:11:11] Energy consumed for all CPUs : 0.000003 kWh. All CPUs Power : 42.11468047636374 W\n",
      "[codecarbon INFO @ 15:11:11] 0.000004 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:11] Energy consumed for all GPUs : 0.000776 kWh. All GPUs Power : 8.068000000000001 W\n",
      "[codecarbon INFO @ 15:11:11] Energy consumed for all CPUs : 0.001451 kWh. All CPUs Power : 22.755997815230717 W\n",
      "[codecarbon INFO @ 15:11:11] 0.002770 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:11] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 15:11:11] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 15:11:11] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 15:11:12] [setup] CPU Tracking...\n",
      "[codecarbon INFO @ 15:11:12] Tracking Intel CPU via RAPL interface\n",
      "[codecarbon INFO @ 15:11:12] Energy consumed for RAM : 0.000667 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:11:12] Energy consumed for all GPUs : 0.000928 kWh. All GPUs Power : 7.97 W\n",
      "[codecarbon INFO @ 15:11:12] Energy consumed for all CPUs : 0.001749 kWh. All CPUs Power : 22.73543037596107 W\n",
      "[codecarbon INFO @ 15:11:12] 0.003344 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:13] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 15:11:13]   Platform system: Linux-5.4.0-88-generic-x86_64-with-glibc2.17\n",
      "[codecarbon INFO @ 15:11:13]   Python version: 3.8.13\n",
      "[codecarbon INFO @ 15:11:13]   Available RAM : 16.000 GB\n",
      "[codecarbon INFO @ 15:11:13]   CPU count: 2\n",
      "[codecarbon INFO @ 15:11:13]   CPU model: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz\n",
      "[codecarbon INFO @ 15:11:13]   GPU count: 1\n",
      "[codecarbon INFO @ 15:11:13]   GPU model: 1 x NVIDIA GeForce GTX 1080 Ti\n",
      "[codecarbon INFO @ 15:11:16] Energy consumed for RAM : 0.000000 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:11:16] Energy consumed for all GPUs : 0.000001 kWh. All GPUs Power : 8.163 W\n",
      "[codecarbon INFO @ 15:11:16] Energy consumed for all CPUs : 0.000004 kWh. All CPUs Power : 36.70172231250935 W\n",
      "[codecarbon INFO @ 15:11:16] 0.000005 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:16] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 15:11:17] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 15:11:17] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 15:11:17] [setup] CPU Tracking...\n",
      "[codecarbon INFO @ 15:11:17] Tracking Intel CPU via RAPL interface\n",
      "[codecarbon INFO @ 15:11:18] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 15:11:18]   Platform system: Linux-5.4.0-88-generic-x86_64-with-glibc2.17\n",
      "[codecarbon INFO @ 15:11:18]   Python version: 3.8.13\n",
      "[codecarbon INFO @ 15:11:18]   Available RAM : 16.000 GB\n",
      "[codecarbon INFO @ 15:11:18]   CPU count: 2\n",
      "[codecarbon INFO @ 15:11:18]   CPU model: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz\n",
      "[codecarbon INFO @ 15:11:18]   GPU count: 1\n",
      "[codecarbon INFO @ 15:11:18]   GPU model: 1 x NVIDIA GeForce GTX 1080 Ti\n",
      "[codecarbon INFO @ 15:11:21] Energy consumed for RAM : 0.000000 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:11:21] Energy consumed for all GPUs : 0.000001 kWh. All GPUs Power : 8.069 W\n",
      "[codecarbon INFO @ 15:11:21] Energy consumed for all CPUs : 0.000003 kWh. All CPUs Power : 34.62903860631409 W\n",
      "[codecarbon INFO @ 15:11:21] 0.000003 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:21] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 15:11:21] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 15:11:21] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 15:11:21] [setup] CPU Tracking...\n",
      "[codecarbon INFO @ 15:11:21] Tracking Intel CPU via RAPL interface\n",
      "[codecarbon INFO @ 15:11:23] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 15:11:23]   Platform system: Linux-5.4.0-88-generic-x86_64-with-glibc2.17\n",
      "[codecarbon INFO @ 15:11:23]   Python version: 3.8.13\n",
      "[codecarbon INFO @ 15:11:23]   Available RAM : 16.000 GB\n",
      "[codecarbon INFO @ 15:11:23]   CPU count: 2\n",
      "[codecarbon INFO @ 15:11:23]   CPU model: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz\n",
      "[codecarbon INFO @ 15:11:23]   GPU count: 1\n",
      "[codecarbon INFO @ 15:11:23]   GPU model: 1 x NVIDIA GeForce GTX 1080 Ti\n",
      "[codecarbon INFO @ 15:11:25] Energy consumed for RAM : 0.000889 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:11:25] Energy consumed for all GPUs : 0.001263 kWh. All GPUs Power : 8.953 W\n",
      "[codecarbon INFO @ 15:11:25] Energy consumed for all CPUs : 0.002261 kWh. All CPUs Power : 22.174504091470773 W\n",
      "[codecarbon INFO @ 15:11:25] 0.004413 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:26] Energy consumed for RAM : 0.000741 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:11:26] Energy consumed for all GPUs : 0.001041 kWh. All GPUs Power : 8.56 W\n",
      "[codecarbon INFO @ 15:11:26] Energy consumed for all CPUs : 0.001951 kWh. All CPUs Power : 22.140546293133845 W\n",
      "[codecarbon INFO @ 15:11:26] 0.003732 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:26] Energy consumed for RAM : 0.000568 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:11:26] Energy consumed for all GPUs : 0.000811 kWh. All GPUs Power : 8.363 W\n",
      "[codecarbon INFO @ 15:11:26] Energy consumed for all CPUs : 0.001545 kWh. All CPUs Power : 22.490141272689627 W\n",
      "[codecarbon INFO @ 15:11:26] 0.002924 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:26] Energy consumed for RAM : 0.000001 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:11:26] Energy consumed for all GPUs : 0.000001 kWh. All GPUs Power : 8.265000000000002 W\n",
      "[codecarbon INFO @ 15:11:26] Energy consumed for all CPUs : 0.000007 kWh. All CPUs Power : 45.11405569484958 W\n",
      "[codecarbon INFO @ 15:11:26] 0.000009 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:27] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 15:11:27] Energy consumed for RAM : 0.000692 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:11:27] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 15:11:27] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 15:11:27] [setup] CPU Tracking...\n",
      "[codecarbon INFO @ 15:11:27] Tracking Intel CPU via RAPL interface\n",
      "[codecarbon INFO @ 15:11:27] Energy consumed for all GPUs : 0.000962 kWh. All GPUs Power : 8.167 W\n",
      "[codecarbon INFO @ 15:11:27] Energy consumed for all CPUs : 0.001843 kWh. All CPUs Power : 22.551935284893332 W\n",
      "[codecarbon INFO @ 15:11:27] 0.003497 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:28] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 15:11:28]   Platform system: Linux-5.4.0-88-generic-x86_64-with-glibc2.17\n",
      "[codecarbon INFO @ 15:11:28]   Python version: 3.8.13\n",
      "[codecarbon INFO @ 15:11:28]   Available RAM : 16.000 GB\n",
      "[codecarbon INFO @ 15:11:28]   CPU count: 2\n",
      "[codecarbon INFO @ 15:11:28]   CPU model: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz\n",
      "[codecarbon INFO @ 15:11:28]   GPU count: 1\n",
      "[codecarbon INFO @ 15:11:28]   GPU model: 1 x NVIDIA GeForce GTX 1080 Ti\n",
      "[codecarbon INFO @ 15:11:31] Energy consumed for RAM : 0.000000 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:11:31] Energy consumed for all GPUs : 0.000001 kWh. All GPUs Power : 8.066 W\n",
      "[codecarbon INFO @ 15:11:31] Energy consumed for all CPUs : 0.000003 kWh. All CPUs Power : 35.129331628162284 W\n",
      "[codecarbon INFO @ 15:11:31] 0.000003 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:31] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 15:11:32] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 15:11:32] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 15:11:32] [setup] CPU Tracking...\n",
      "[codecarbon INFO @ 15:11:32] Tracking Intel CPU via RAPL interface\n",
      "[codecarbon INFO @ 15:11:33] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 15:11:33]   Platform system: Linux-5.4.0-88-generic-x86_64-with-glibc2.17\n",
      "[codecarbon INFO @ 15:11:33]   Python version: 3.8.13\n",
      "[codecarbon INFO @ 15:11:33]   Available RAM : 16.000 GB\n",
      "[codecarbon INFO @ 15:11:33]   CPU count: 2\n",
      "[codecarbon INFO @ 15:11:33]   CPU model: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 15:11:33]   GPU count: 1\n",
      "[codecarbon INFO @ 15:11:33]   GPU model: 1 x NVIDIA GeForce GTX 1080 Ti\n",
      "[codecarbon INFO @ 15:11:36] Energy consumed for RAM : 0.000000 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:11:36] Energy consumed for all GPUs : 0.000001 kWh. All GPUs Power : 8.363 W\n",
      "[codecarbon INFO @ 15:11:36] Energy consumed for all CPUs : 0.000003 kWh. All CPUs Power : 36.192116511558545 W\n",
      "[codecarbon INFO @ 15:11:36] 0.000004 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:36] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 15:11:37] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 15:11:37] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 15:11:37] [setup] CPU Tracking...\n",
      "[codecarbon INFO @ 15:11:37] Tracking Intel CPU via RAPL interface\n",
      "[codecarbon INFO @ 15:11:38] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 15:11:38]   Platform system: Linux-5.4.0-88-generic-x86_64-with-glibc2.17\n",
      "[codecarbon INFO @ 15:11:38]   Python version: 3.8.13\n",
      "[codecarbon INFO @ 15:11:38]   Available RAM : 16.000 GB\n",
      "[codecarbon INFO @ 15:11:38]   CPU count: 2\n",
      "[codecarbon INFO @ 15:11:38]   CPU model: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz\n",
      "[codecarbon INFO @ 15:11:38]   GPU count: 1\n",
      "[codecarbon INFO @ 15:11:38]   GPU model: 1 x NVIDIA GeForce GTX 1080 Ti\n",
      "[codecarbon INFO @ 15:11:40] Energy consumed for RAM : 0.000914 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:11:40] Energy consumed for all GPUs : 0.001298 kWh. All GPUs Power : 8.363 W\n",
      "[codecarbon INFO @ 15:11:40] Energy consumed for all CPUs : 0.002357 kWh. All CPUs Power : 22.90008606459973 W\n",
      "[codecarbon INFO @ 15:11:40] 0.004568 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:41] Energy consumed for RAM : 0.000765 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:11:41] Energy consumed for all GPUs : 0.001075 kWh. All GPUs Power : 8.265000000000002 W\n",
      "[codecarbon INFO @ 15:11:41] Energy consumed for all CPUs : 0.002046 kWh. All CPUs Power : 22.876169473380326 W\n",
      "[codecarbon INFO @ 15:11:41] 0.003886 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:41] Energy consumed for RAM : 0.000000 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:11:41] Energy consumed for RAM : 0.000593 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:11:41] Energy consumed for all GPUs : 0.000001 kWh. All GPUs Power : 8.462000000000002 W\n",
      "[codecarbon INFO @ 15:11:41] Energy consumed for all CPUs : 0.000004 kWh. All CPUs Power : 36.52716734108702 W\n",
      "[codecarbon INFO @ 15:11:41] 0.000005 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:41] Energy consumed for all GPUs : 0.000846 kWh. All GPUs Power : 8.363 W\n",
      "[codecarbon INFO @ 15:11:41] Energy consumed for all CPUs : 0.001639 kWh. All CPUs Power : 22.63179247981315 W\n",
      "[codecarbon INFO @ 15:11:41] 0.003078 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:41] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 15:11:42] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 15:11:42] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 15:11:42] [setup] CPU Tracking...\n",
      "[codecarbon INFO @ 15:11:42] Tracking Intel CPU via RAPL interface\n",
      "[codecarbon INFO @ 15:11:42] Energy consumed for RAM : 0.000717 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:11:42] Energy consumed for all GPUs : 0.000996 kWh. All GPUs Power : 8.265000000000002 W\n",
      "[codecarbon INFO @ 15:11:42] Energy consumed for all CPUs : 0.001937 kWh. All CPUs Power : 22.535820273791064 W\n",
      "[codecarbon INFO @ 15:11:42] 0.003650 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:43] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 15:11:43]   Platform system: Linux-5.4.0-88-generic-x86_64-with-glibc2.17\n",
      "[codecarbon INFO @ 15:11:43]   Python version: 3.8.13\n",
      "[codecarbon INFO @ 15:11:43]   Available RAM : 16.000 GB\n",
      "[codecarbon INFO @ 15:11:43]   CPU count: 2\n",
      "[codecarbon INFO @ 15:11:43]   CPU model: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz\n",
      "[codecarbon INFO @ 15:11:43]   GPU count: 1\n",
      "[codecarbon INFO @ 15:11:43]   GPU model: 1 x NVIDIA GeForce GTX 1080 Ti\n",
      "[codecarbon INFO @ 15:11:46] Energy consumed for RAM : 0.000000 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:11:46] Energy consumed for all GPUs : 0.000001 kWh. All GPUs Power : 8.167 W\n",
      "[codecarbon INFO @ 15:11:46] Energy consumed for all CPUs : 0.000004 kWh. All CPUs Power : 37.67009851834914 W\n",
      "[codecarbon INFO @ 15:11:46] 0.000005 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:46] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 15:11:47] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 15:11:47] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 15:11:47] [setup] CPU Tracking...\n",
      "[codecarbon INFO @ 15:11:47] Tracking Intel CPU via RAPL interface\n",
      "[codecarbon INFO @ 15:11:48] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 15:11:48]   Platform system: Linux-5.4.0-88-generic-x86_64-with-glibc2.17\n",
      "[codecarbon INFO @ 15:11:48]   Python version: 3.8.13\n",
      "[codecarbon INFO @ 15:11:48]   Available RAM : 16.000 GB\n",
      "[codecarbon INFO @ 15:11:48]   CPU count: 2\n",
      "[codecarbon INFO @ 15:11:48]   CPU model: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz\n",
      "[codecarbon INFO @ 15:11:48]   GPU count: 1\n",
      "[codecarbon INFO @ 15:11:48]   GPU model: 1 x NVIDIA GeForce GTX 1080 Ti\n",
      "[codecarbon INFO @ 15:11:51] Energy consumed for RAM : 0.000000 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:11:51] Energy consumed for all GPUs : 0.000001 kWh. All GPUs Power : 8.166000000000002 W\n",
      "[codecarbon INFO @ 15:11:51] Energy consumed for all CPUs : 0.000003 kWh. All CPUs Power : 36.982061190766785 W\n",
      "[codecarbon INFO @ 15:11:51] 0.000004 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:51] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 15:11:51] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 15:11:51] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 15:11:51] [setup] CPU Tracking...\n",
      "[codecarbon INFO @ 15:11:51] Tracking Intel CPU via RAPL interface\n",
      "[codecarbon INFO @ 15:11:53] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 15:11:53]   Platform system: Linux-5.4.0-88-generic-x86_64-with-glibc2.17\n",
      "[codecarbon INFO @ 15:11:53]   Python version: 3.8.13\n",
      "[codecarbon INFO @ 15:11:53]   Available RAM : 16.000 GB\n",
      "[codecarbon INFO @ 15:11:53]   CPU count: 2\n",
      "[codecarbon INFO @ 15:11:53]   CPU model: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz\n",
      "[codecarbon INFO @ 15:11:53]   GPU count: 1\n",
      "[codecarbon INFO @ 15:11:53]   GPU model: 1 x NVIDIA GeForce GTX 1080 Ti\n",
      "[codecarbon INFO @ 15:11:55] Energy consumed for RAM : 0.000939 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:11:55] Energy consumed for all GPUs : 0.001332 kWh. All GPUs Power : 8.266 W\n",
      "[codecarbon INFO @ 15:11:55] Energy consumed for all CPUs : 0.002451 kWh. All CPUs Power : 22.553466387786024 W\n",
      "[codecarbon INFO @ 15:11:55] 0.004721 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:56] Energy consumed for RAM : 0.000790 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:11:56] Energy consumed for all GPUs : 0.001110 kWh. All GPUs Power : 8.364 W\n",
      "[codecarbon INFO @ 15:11:56] Energy consumed for all CPUs : 0.002140 kWh. All CPUs Power : 22.650330035193523 W\n",
      "[codecarbon INFO @ 15:11:56] 0.004040 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:56] Energy consumed for RAM : 0.000000 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:11:56] Energy consumed for all GPUs : 0.000001 kWh. All GPUs Power : 8.068000000000001 W\n",
      "[codecarbon INFO @ 15:11:56] Energy consumed for all CPUs : 0.000003 kWh. All CPUs Power : 38.927307268890466 W\n",
      "[codecarbon INFO @ 15:11:56] 0.000004 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:56] Energy consumed for RAM : 0.000618 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:11:56] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 15:11:56] Energy consumed for all GPUs : 0.000879 kWh. All GPUs Power : 8.166000000000002 W\n",
      "[codecarbon INFO @ 15:11:56] Energy consumed for all CPUs : 0.001733 kWh. All CPUs Power : 22.712826621953596 W\n",
      "[codecarbon INFO @ 15:11:56] 0.003231 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:56] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 15:11:56] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 15:11:56] [setup] CPU Tracking...\n",
      "[codecarbon INFO @ 15:11:56] Tracking Intel CPU via RAPL interface\n",
      "[codecarbon INFO @ 15:11:57] Energy consumed for RAM : 0.000742 kWh. RAM Power : 6.0 W\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 15:11:57] Energy consumed for all GPUs : 0.001031 kWh. All GPUs Power : 8.265000000000002 W\n",
      "[codecarbon INFO @ 15:11:57] Energy consumed for all CPUs : 0.002032 kWh. All CPUs Power : 22.7699116674137 W\n",
      "[codecarbon INFO @ 15:11:57] 0.003804 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:11:58] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 15:11:58]   Platform system: Linux-5.4.0-88-generic-x86_64-with-glibc2.17\n",
      "[codecarbon INFO @ 15:11:58]   Python version: 3.8.13\n",
      "[codecarbon INFO @ 15:11:58]   Available RAM : 16.000 GB\n",
      "[codecarbon INFO @ 15:11:58]   CPU count: 2\n",
      "[codecarbon INFO @ 15:11:58]   CPU model: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz\n",
      "[codecarbon INFO @ 15:11:58]   GPU count: 1\n",
      "[codecarbon INFO @ 15:11:58]   GPU model: 1 x NVIDIA GeForce GTX 1080 Ti\n",
      "[codecarbon INFO @ 15:12:01] Energy consumed for RAM : 0.000000 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:12:01] Energy consumed for all GPUs : 0.000001 kWh. All GPUs Power : 8.363 W\n",
      "[codecarbon INFO @ 15:12:01] Energy consumed for all CPUs : 0.000005 kWh. All CPUs Power : 43.16173232048318 W\n",
      "[codecarbon INFO @ 15:12:01] 0.000007 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:12:10] Energy consumed for RAM : 0.000963 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:12:10] Energy consumed for all GPUs : 0.001368 kWh. All GPUs Power : 8.56 W\n",
      "[codecarbon INFO @ 15:12:10] Energy consumed for all CPUs : 0.002520 kWh. All CPUs Power : 16.74281297299528 W\n",
      "[codecarbon INFO @ 15:12:10] 0.004851 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:12:11] Energy consumed for RAM : 0.000815 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:12:11] Energy consumed for all GPUs : 0.001150 kWh. All GPUs Power : 9.544 W\n",
      "[codecarbon INFO @ 15:12:11] Energy consumed for all CPUs : 0.002210 kWh. All CPUs Power : 16.64714069543008 W\n",
      "[codecarbon INFO @ 15:12:11] 0.004174 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:12:11] Energy consumed for RAM : 0.000642 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:12:11] Energy consumed for all GPUs : 0.000914 kWh. All GPUs Power : 8.264 W\n",
      "[codecarbon INFO @ 15:12:11] Energy consumed for all CPUs : 0.001801 kWh. All CPUs Power : 16.06151021068687 W\n",
      "[codecarbon INFO @ 15:12:11] 0.003357 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:12:12] Energy consumed for RAM : 0.000766 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:12:12] Energy consumed for all GPUs : 0.001068 kWh. All GPUs Power : 8.856 W\n",
      "[codecarbon INFO @ 15:12:12] Energy consumed for all CPUs : 0.002097 kWh. All CPUs Power : 15.549427469614855 W\n",
      "[codecarbon INFO @ 15:12:12] 0.003931 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:12:25] Energy consumed for RAM : 0.000988 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:12:25] Energy consumed for all GPUs : 0.001401 kWh. All GPUs Power : 8.069 W\n",
      "[codecarbon INFO @ 15:12:25] Energy consumed for all CPUs : 0.002574 kWh. All CPUs Power : 12.735098349512764 W\n",
      "[codecarbon INFO @ 15:12:25] 0.004963 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:12:26] Energy consumed for RAM : 0.000839 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:12:26] Energy consumed for all GPUs : 0.001184 kWh. All GPUs Power : 8.363 W\n",
      "[codecarbon INFO @ 15:12:26] Energy consumed for all CPUs : 0.002263 kWh. All CPUs Power : 12.720835990278683 W\n",
      "[codecarbon INFO @ 15:12:26] 0.004286 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:12:26] Energy consumed for RAM : 0.000667 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:12:26] Energy consumed for all GPUs : 0.000948 kWh. All GPUs Power : 8.069 W\n",
      "[codecarbon INFO @ 15:12:26] Energy consumed for all CPUs : 0.001854 kWh. All CPUs Power : 12.728034852240272 W\n",
      "[codecarbon INFO @ 15:12:26] 0.003468 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:12:27] Energy consumed for RAM : 0.000791 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:12:27] Energy consumed for all GPUs : 0.001103 kWh. All GPUs Power : 8.461 W\n",
      "[codecarbon INFO @ 15:12:27] Energy consumed for all CPUs : 0.002150 kWh. All CPUs Power : 12.722169544978042 W\n",
      "[codecarbon INFO @ 15:12:27] 0.004044 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:12:40] Energy consumed for RAM : 0.001013 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:12:40] Energy consumed for all GPUs : 0.001434 kWh. All GPUs Power : 7.97 W\n",
      "[codecarbon INFO @ 15:12:40] Energy consumed for all CPUs : 0.002627 kWh. All CPUs Power : 12.77281054990939 W\n",
      "[codecarbon INFO @ 15:12:40] 0.005074 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:12:41] Energy consumed for RAM : 0.000864 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:12:41] Energy consumed for all GPUs : 0.001218 kWh. All GPUs Power : 8.167 W\n",
      "[codecarbon INFO @ 15:12:41] Energy consumed for all CPUs : 0.002316 kWh. All CPUs Power : 12.767208446912484 W\n",
      "[codecarbon INFO @ 15:12:41] 0.004398 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:12:41] Energy consumed for RAM : 0.000692 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:12:41] Energy consumed for all GPUs : 0.000982 kWh. All GPUs Power : 8.167 W\n",
      "[codecarbon INFO @ 15:12:41] Energy consumed for all CPUs : 0.001907 kWh. All CPUs Power : 12.760680583910906 W\n",
      "[codecarbon INFO @ 15:12:41] 0.003580 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:12:42] Energy consumed for RAM : 0.000816 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:12:42] Energy consumed for all GPUs : 0.001139 kWh. All GPUs Power : 8.658 W\n",
      "[codecarbon INFO @ 15:12:42] Energy consumed for all CPUs : 0.002203 kWh. All CPUs Power : 12.762715730419362 W\n",
      "[codecarbon INFO @ 15:12:42] 0.004157 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:12:55] Energy consumed for RAM : 0.001037 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:12:55] Energy consumed for all GPUs : 0.001468 kWh. All GPUs Power : 8.069 W\n",
      "[codecarbon INFO @ 15:12:55] Energy consumed for all CPUs : 0.002680 kWh. All CPUs Power : 12.72335793270338 W\n",
      "[codecarbon INFO @ 15:12:55] 0.005185 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:12:56] Energy consumed for RAM : 0.000889 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:12:56] Energy consumed for all GPUs : 0.001263 kWh. All GPUs Power : 10.722 W\n",
      "[codecarbon INFO @ 15:12:56] Energy consumed for all CPUs : 0.002369 kWh. All CPUs Power : 12.717878175967531 W\n",
      "[codecarbon INFO @ 15:12:56] 0.004521 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:12:56] Energy consumed for RAM : 0.000716 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:12:56] Energy consumed for all GPUs : 0.001016 kWh. All GPUs Power : 8.265000000000002 W\n",
      "[codecarbon INFO @ 15:12:56] Energy consumed for all CPUs : 0.001960 kWh. All CPUs Power : 12.713522913163159 W\n",
      "[codecarbon INFO @ 15:12:56] 0.003692 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:12:57] Energy consumed for RAM : 0.000840 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:12:57] Energy consumed for all GPUs : 0.001175 kWh. All GPUs Power : 8.559000000000001 W\n",
      "[codecarbon INFO @ 15:12:57] Energy consumed for all CPUs : 0.002256 kWh. All CPUs Power : 12.714299812443596 W\n",
      "[codecarbon INFO @ 15:12:57] 0.004271 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:13:10] Energy consumed for RAM : 0.001062 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:13:10] Energy consumed for all GPUs : 0.001502 kWh. All GPUs Power : 8.265000000000002 W\n",
      "[codecarbon INFO @ 15:13:10] Energy consumed for all CPUs : 0.002733 kWh. All CPUs Power : 12.681496526744429 W\n",
      "[codecarbon INFO @ 15:13:10] 0.005297 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:13:11] Energy consumed for RAM : 0.000913 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:13:11] Energy consumed for all GPUs : 0.001297 kWh. All GPUs Power : 8.166000000000002 W\n",
      "[codecarbon INFO @ 15:13:11] Energy consumed for all CPUs : 0.002422 kWh. All CPUs Power : 12.70744247951346 W\n",
      "[codecarbon INFO @ 15:13:11] 0.004632 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:13:11] Energy consumed for RAM : 0.000741 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:13:11] Energy consumed for all GPUs : 0.001052 kWh. All GPUs Power : 8.56 W\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 15:13:11] Energy consumed for all CPUs : 0.002013 kWh. All CPUs Power : 12.714929626939883 W\n",
      "[codecarbon INFO @ 15:13:11] 0.003805 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:13:12] Energy consumed for RAM : 0.000865 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:13:12] Energy consumed for all GPUs : 0.001209 kWh. All GPUs Power : 8.167 W\n",
      "[codecarbon INFO @ 15:13:12] Energy consumed for all CPUs : 0.002309 kWh. All CPUs Power : 12.714992140462776 W\n",
      "[codecarbon INFO @ 15:13:12] 0.004382 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:13:25] Energy consumed for RAM : 0.001087 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:13:25] Energy consumed for all GPUs : 0.001537 kWh. All GPUs Power : 8.363 W\n",
      "[codecarbon INFO @ 15:13:25] Energy consumed for all CPUs : 0.002785 kWh. All CPUs Power : 12.698857300690037 W\n",
      "[codecarbon INFO @ 15:13:25] 0.005409 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:13:26] Energy consumed for RAM : 0.000938 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:13:26] Energy consumed for all GPUs : 0.001331 kWh. All GPUs Power : 8.069 W\n",
      "[codecarbon INFO @ 15:13:26] Energy consumed for all CPUs : 0.002475 kWh. All CPUs Power : 12.676473326529791 W\n",
      "[codecarbon INFO @ 15:13:26] 0.004743 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:13:26] Energy consumed for RAM : 0.000766 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:13:26] Energy consumed for all GPUs : 0.001086 kWh. All GPUs Power : 8.363 W\n",
      "[codecarbon INFO @ 15:13:26] Energy consumed for all CPUs : 0.002065 kWh. All CPUs Power : 12.676171629633025 W\n",
      "[codecarbon INFO @ 15:13:26] 0.003918 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:13:27] Energy consumed for RAM : 0.000890 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:13:27] Energy consumed for all GPUs : 0.001242 kWh. All GPUs Power : 8.068000000000001 W\n",
      "[codecarbon INFO @ 15:13:27] Energy consumed for all CPUs : 0.002362 kWh. All CPUs Power : 12.667942953847458 W\n",
      "[codecarbon INFO @ 15:13:27] 0.004493 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:13:40] Energy consumed for RAM : 0.001111 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:13:40] Energy consumed for all GPUs : 0.001571 kWh. All GPUs Power : 8.166000000000002 W\n",
      "[codecarbon INFO @ 15:13:40] Energy consumed for all CPUs : 0.002838 kWh. All CPUs Power : 12.642414349536933 W\n",
      "[codecarbon INFO @ 15:13:40] 0.005521 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:13:41] Energy consumed for RAM : 0.000963 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:13:41] Energy consumed for all GPUs : 0.001377 kWh. All GPUs Power : 11.017 W\n",
      "[codecarbon INFO @ 15:13:41] Energy consumed for all CPUs : 0.002527 kWh. All CPUs Power : 12.648054827554901 W\n",
      "[codecarbon INFO @ 15:13:41] 0.004866 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:13:41] Energy consumed for RAM : 0.000790 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:13:41] Energy consumed for all GPUs : 0.001120 kWh. All GPUs Power : 8.167 W\n",
      "[codecarbon INFO @ 15:13:41] Energy consumed for all CPUs : 0.002118 kWh. All CPUs Power : 12.654786873084344 W\n",
      "[codecarbon INFO @ 15:13:41] 0.004029 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:13:42] Energy consumed for RAM : 0.000914 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:13:42] Energy consumed for all GPUs : 0.001277 kWh. All GPUs Power : 8.363 W\n",
      "[codecarbon INFO @ 15:13:42] Energy consumed for all CPUs : 0.002414 kWh. All CPUs Power : 12.666106079856263 W\n",
      "[codecarbon INFO @ 15:13:42] 0.004606 kWh of electricity used since the begining.\n"
     ]
    }
   ],
   "source": [
    "power_layerwise = []\n",
    "for layer in denseNet.layers[:20]:\n",
    "    power_layerwise.append(evaluate_energy_forward(layer, layer.input_shape, 10, 10))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "475d9288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0519271960754195e-07, 9.273276738542768e-08, 2.4386782138555506e-07, 2.3225266968777236e-07, 1.5543853969879891e-07, 1.4613112762408706e-07, 2.1572977179730293e-07, 9.452898760925247e-08, 8.170897535079443e-08, 1.1249184330153498e-07, 1.4776109120596343e-07, 1.0030678829270113e-07, 2.7091976361733723e-07, 1.0169242529941598e-07, 1.2243433842528188e-07, 1.4256755192031993e-07, 1.3661771111640355e-07, 1.1546703497696592e-07, 1.1178944903263979e-07, 2.056327320127565e-07]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 15:13:55] Energy consumed for RAM : 0.001136 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:13:55] Energy consumed for all GPUs : 0.001606 kWh. All GPUs Power : 8.265000000000002 W\n",
      "[codecarbon INFO @ 15:13:55] Energy consumed for all CPUs : 0.002891 kWh. All CPUs Power : 12.711279761945526 W\n",
      "[codecarbon INFO @ 15:13:55] 0.005633 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:13:56] Energy consumed for RAM : 0.000987 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:13:56] Energy consumed for all GPUs : 0.001412 kWh. All GPUs Power : 8.461 W\n",
      "[codecarbon INFO @ 15:13:56] Energy consumed for all CPUs : 0.002580 kWh. All CPUs Power : 12.72207909172899 W\n",
      "[codecarbon INFO @ 15:13:56] 0.004979 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:13:56] Energy consumed for RAM : 0.000815 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:13:56] Energy consumed for all GPUs : 0.001154 kWh. All GPUs Power : 8.068000000000001 W\n",
      "[codecarbon INFO @ 15:13:56] Energy consumed for all CPUs : 0.002171 kWh. All CPUs Power : 12.721603946314541 W\n",
      "[codecarbon INFO @ 15:13:56] 0.004140 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:13:57] Energy consumed for RAM : 0.000939 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:13:57] Energy consumed for all GPUs : 0.001311 kWh. All GPUs Power : 8.265000000000002 W\n",
      "[codecarbon INFO @ 15:13:57] Energy consumed for all CPUs : 0.002467 kWh. All CPUs Power : 12.720827944871095 W\n",
      "[codecarbon INFO @ 15:13:57] 0.004718 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:14:10] Energy consumed for RAM : 0.001161 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:14:10] Energy consumed for all GPUs : 0.001640 kWh. All GPUs Power : 8.265000000000002 W\n",
      "[codecarbon INFO @ 15:14:10] Energy consumed for all CPUs : 0.002944 kWh. All CPUs Power : 12.761511362923581 W\n",
      "[codecarbon INFO @ 15:14:10] 0.005745 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:14:11] Energy consumed for RAM : 0.001012 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:14:11] Energy consumed for all GPUs : 0.001446 kWh. All GPUs Power : 8.167 W\n",
      "[codecarbon INFO @ 15:14:11] Energy consumed for all CPUs : 0.002634 kWh. All CPUs Power : 12.775539468085672 W\n",
      "[codecarbon INFO @ 15:14:11] 0.005091 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:14:11] Energy consumed for RAM : 0.000840 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:14:11] Energy consumed for all GPUs : 0.001188 kWh. All GPUs Power : 8.265000000000002 W\n",
      "[codecarbon INFO @ 15:14:11] Energy consumed for all CPUs : 0.002224 kWh. All CPUs Power : 12.761335132481797 W\n",
      "[codecarbon INFO @ 15:14:11] 0.004253 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:14:12] Energy consumed for RAM : 0.000964 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:14:12] Energy consumed for all GPUs : 0.001346 kWh. All GPUs Power : 8.363 W\n",
      "[codecarbon INFO @ 15:14:12] Energy consumed for all CPUs : 0.002520 kWh. All CPUs Power : 12.755368209089585 W\n",
      "[codecarbon INFO @ 15:14:12] 0.004830 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:14:25] Energy consumed for RAM : 0.001185 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:14:25] Energy consumed for all GPUs : 0.001675 kWh. All GPUs Power : 8.264 W\n",
      "[codecarbon INFO @ 15:14:25] Energy consumed for all CPUs : 0.002998 kWh. All CPUs Power : 12.814944165274179 W\n",
      "[codecarbon INFO @ 15:14:25] 0.005857 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:14:26] Energy consumed for RAM : 0.001036 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:14:26] Energy consumed for all GPUs : 0.001481 kWh. All GPUs Power : 8.56 W\n",
      "[codecarbon INFO @ 15:14:26] Energy consumed for all CPUs : 0.002688 kWh. All CPUs Power : 13.160255256749327 W\n",
      "[codecarbon INFO @ 15:14:26] 0.005206 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:14:26] Energy consumed for RAM : 0.000864 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:14:26] Energy consumed for all GPUs : 0.001222 kWh. All GPUs Power : 8.167 W\n",
      "[codecarbon INFO @ 15:14:26] Energy consumed for all CPUs : 0.002280 kWh. All CPUs Power : 13.263016854734087 W\n",
      "[codecarbon INFO @ 15:14:26] 0.004366 kWh of electricity used since the begining.\n",
      "[codecarbon INFO @ 15:14:27] Energy consumed for RAM : 0.000988 kWh. RAM Power : 6.0 W\n",
      "[codecarbon INFO @ 15:14:27] Energy consumed for all GPUs : 0.001381 kWh. All GPUs Power : 8.363 W\n",
      "[codecarbon INFO @ 15:14:27] Energy consumed for all CPUs : 0.002576 kWh. All CPUs Power : 13.348796441564305 W\n",
      "[codecarbon INFO @ 15:14:27] 0.004946 kWh of electricity used since the begining.\n"
     ]
    }
   ],
   "source": [
    "print(power_layerwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098b68f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
